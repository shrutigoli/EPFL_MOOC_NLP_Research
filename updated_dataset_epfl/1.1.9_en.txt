So, let's now go to reconstruction strategies.
In reconstruction,
I already mentioned that you build your components bottom up.
So you start with your ion channels, you build your neurons, you build your synapses, you connect your neurons with synapses and you get circuits.
You package them into workflows and to workflows and you automate these workflows as much as possible, because as I said, the most important thing in simulation neuroscience is actually to reconstruct, test, validate, find mistakes, reconstruct again and again and again and again until it becomes a digital copy of the tissue.
So here is an example and we will be going over that in over many lectures.
You have your neurons, you find out all your types of neurons and then you work out how to position them together and then you find out how to connect them together and then you add the physiology, how do they behave, every neuron behaves.
And then how every synapse behaves and then you have a circuit.
The last part that we will look at is simulation strategies and of course this involves billions and billions of calculations in order to compute every ion channel opening and there may be tens of thousands of ion channels in a single neuron and then there are currents flowing inside a neuron.
So there are a lot of calculations and Felix is going to give you some ideas of the numbers of calculations and types of calculations that have to be done, but clearly you need a supercomputer.
But sometimes people say
"oh, why didn't you do it on the grid?" or "why didn't you do it on some cluster or whatever?"
The important thing about simulating neural tissue, not building a model,
(INAUDIBLE) simulating your tissue, a digital reconstruction is that...
...the whole simulation will run as slow as or fast as the slowest interaction.
The neurons have too much memory to be on one processor, so each processor has to transmit information to another processor and so when the neurons communicate, they are actually communicating between processes and if you had a grid for example, and just one connection was slow, you would have to wait.
The whole brain, the whole tissue that you have reconstructed has to wait for that transmission to occur before the rest can happen.
So you need a supercomputer, where there is fast interconnect.
So that is why you need a supercomputer, you need to have simulation code, of course that can distribute this problem of all these neurons across many, many processes and so you need the parallel code and in the Blue Brain Project we have...
..worked with the father of one of the most important simulators called NEURON, it is Michael Hines from Yale, and we worked with him to advance this code, so that it can really run very large scale simulations on supercomputers.
So you need parallel code and then there are lots of other challenges.
Supercomputers were designed and built largely for nuclear simulations and for other kinds of applications in physics and in particle physics, where you have a big problem, you ask a question and you get the simple answer back.
It is not as simple. It is a very interesting answer, but you get an answer back and in simulation neuroscience, you want to... you are dealing with a lot of memory and you want to know everything that is happening inside the reconstructed tissue.
So you need data intensive supercomputing and you need efficient algorithms to handle data.
You need to balance the load.
One neuron may be very big another one may be very small, so you need to know how to distribute your neurons across processes and you need to know how to manage all your resources, your computing resources.
One may be going very slowly, one may be going very fast.
So it is a resource management challenge, it is a data management challenge, but principally, you can summarize that as you need data intensive supercomputing and supercomputers are slowly moving in that direction where they can hold a lot of memory.
Now the value of simulations, why do you need a simulation?
Is it just that you get a nice pretty picture?
Well, it is because if you build it, you want to see how it behaves and you want to be able to compare it to a real piece of tissue.
So the way we see the reconstructed tissue is like a virtual brain or virtual piece of tissue and we want that we can visualize it and experiment on it as if it is a real piece of tissue.
Now we look at real pieces of tissues under the microscope.
We stain their cells, we measure them electrically and so we actually do very similar... we build in silico microscopes, in silico recording devices and so on, so that we can directly compare experiments with a virtual tissue.
Here is just an example, where the difference when you have a reconstruction, a detailed reconstruction, compared to the biological tissue is that in the reconstruction, you know everything.
You know every neuron, the name of every neuron, you know every single spike that is occurring, where the neuron is located, you know every synapse and so it gives you an x-ray view into the digital tissue.
This is impossible in experiments.
You can get a tiny small view into what is going on, but you can't get a global view and you can't get a deep view.
So by reconstructing the tissue, if your algorithms are good enough to replicate the tissue, then you have a virtual exploratory environment where you have an x-ray view into all the mechanisms.
And in subsequent lectures, we will see the power of that.
That it can actually give you, take you way beyond what experiments can do.
You can explore mechanisms, you can test hypotheses about how the circuit behaves in ways that are impossible experimentally.
