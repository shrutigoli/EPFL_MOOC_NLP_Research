So there was an old belief in biology that a self-describing program, so to say, is actually not possible.
So the idea, the argument is, if my genetic code captures my full complexity, it must occupy all my space, right?
How could I, where's any space left for me, for myself, for that life form?
So it was actually an argument against some pure mechanism for biology and life.
And that there wasn't a need for divine intervention for life to exist and actually to even procreate.
We know now, of course, particularly in computer science because we have learned this from the start, that this is a silly argument, right?
And if you look at molecular genetics and life, these are machines, right?
There is the DNA that stores our genetic code, right?
And there's transcription of the DNA into messenger RNA to transport our relevant genetic information out of the cell's core to a place where the messenger RNA can be turned into a protein, right?
So that RNA travels to this factory, protein factory, the ribosomes which are themselves collections of proteins, right?
And there, the mRNAs turn the copy it onto a protein.
And these proteins that you produce that way are responsible for all the mechanisms in life including protein construction and transcription and copying and preserving the DNA.
This becomes a self-perpetuating machine.
And that's a machine in addition to the genetic code, of course, right?
And it's computation, it's biological computation here.
So this is not coming as a great surprise to us.
In computer science we're actually used to this.
And you've probably heard of self-replicating programs.
Let's take an example in English first.
Look at this: Write two copies of the following sentence the second in quotes.
And then in quotes,
"Write two copies of the following sentences, the second in quotes."
If you think of interpret executing this, you get the program back as an output.
Or similarly, the next line is such a thing in C.
You get basically a C program that outputs itself, not trying to go into a file system and reading this and so on.
It actually produces itself.
Now there is another term in the context of theory, the notion of a universal Turing machine that really is able to self-integrate in the sense that a Turing machine that can execute description as data on the tape of a Turing machine.
So it's an interpreter for
Turing machine by itself, right?
This is of course an important notion, right?
Obviously this can be done because Turing machines especially in the changeable, let's say C, where we can write such interpretive that write themselves, right?
The important thing is that these Turing machines that are still universal can be made very simple.
If you're not consisting of binary tapes but after I think seven symbols, different ones, then actually there's a two-state universal Turing machine, which is quite crazy to imagine, right?
So you can write that way interpreters for Turing complete languages as well.
Now it's worth thinking about self-interpretation in the context of these paradoxes that you might have heard about, like Russell's paradox, right?
It's meant to be a set theory but the popular description is, you know, the barber shaves everybody who doesn't shave himself.
And the question is, does the barber shave himself?
If you think about this, this leads to a paradox.
Now there's this famous undecidability of the halting problem.
I'm sure you have learned about this in the theory course.
So the halting problem is the question, given a program, can we tell whether this program will terminate in all possible inputs?
Now we can, on these slides, give you complete proof very simple by self-interpretation that shows by contradiction that the halting problem is undecidable.
There cannot be a program that decides the halting problem.
So how do you do this?
So let's assume there exists a procedure "does_halt" function that takes some code and says, yes, it holds all inputs or not.
So let's assume that this procedure exists.
Then let's look at this procedure
I've just written down here, the two-part paradox, and what it does is the following.
It takes some piece of code, it's a string or a file, and it tests if "does_halt", this conjectured method for checking the halting problem, says yes on that code, then loop forever.
Otherwise, exit.
You can actually do that, right?
This is actually a program.
And on some random code, it will do something maybe reasonable.
It's not a very useful program because when it halts, it gets into the infinite loop, but whatever.
Think about the case that a code that it receives is its own code, right?
Well if it's its own code basically, in that case that the halting problem says yes, then it doesn't halt this code, right?
And if it says no, then it halts.
Which is a contradiction, right?
So it means that "does_halt" program must have been incorrect, so it cannot exist.
There cannot be a correct solution for the halting problem.
It's a simple consequence of even very limited programming languages being powerful enough that such questions have become nonsensical, right?
Which is unintuitive at first because you think it is an actually reasonable question. 
It's even useful.
That's the halting problem..
You could avoid code that gets into infinite loops, right?
But no, it doesn't make sense.
And this is self-interpretation, right?
And that was a complete proof actually.
Now the next thing is not about really self-interpretation but it's a step to the following slide which again is, right?
So how about composing translators?
It's compilers, right?
Compilers are obviously functions, right?
They take programs in language A to programs in language B, right?
And functions can be composed.
So if you've got a compiler that compiles from A to B language and a compiler that compiles from language B to C, then together composed they give us a compiler from A to C.
And the same way for interpreters.
You can stack interpreters and that way get any sequence and any composition of interpreters.
And of course that is much easier in a sense then the stacking of virtual machines that you've heard about in the virtual machine module because we can assume that layers between the interpreters are complete.
And they're completely protected from each other.
We don't have to worry about deep down some operation doing something bad.
Now this kind of composition we can use for bootstrapping compilers.
The hesitation is the following, the problem is the following, suppose you've got a new programming language, let's say Scala.
Nobody has ever written any translator or interpreter for Scala.
You've just come up with this design.
How do you make a compiler for it relatively easily?
One thing you could do of course is you could write that compiler in machine code but that sounds like a wasteful effort, right?
What you could do is you could take some compiler another high-level language which via a chain of compilers where it leads down all the way to machine code.
For example, a C compiler.
So you could write your compiler for Scala in C.
Now after a while you might say,
"Well, I want to make better features.
I want to improve the optimizations.
And I want to make this a more powerful compiler but I've got a working compiler written in C."
So what I can do is I can rewrite that compiler in Scala.
Probably less code and easily maintainable and so on because it's more productive.
And then, I can throw away the source code of the first C compiler.
I can take the Scala to Scala compiler compile it with that Scala to C compiler all the way down the machine code.
That way I've got a model as good as the latest implementation of the Scala compiler,
Scala compiler to machine code, and then I can throw away everything I had about that Scala to C compiler, right?
And then in the end, there's only a Scala to Scala compiler.
So nowadays if you look at the Scala reference compiler, it's written in Scala and there's nothing else.
Well, there is still at least one Scala compiler actually that's compiled, right?
But it can be only a binary, right?
So that's this kind of bootstrapping.
At some point, you know, nowadays that's a good practice, to write a compiler for a language in the language itself.
It might be particularly natural.
So how, if you've got a completely new architecture, new CPU or a new whatever, piece of hardware, how do we make a good compiler, code generator, for it?
But probably you don't know the start writing everything including the operating system and tools and so on from scratch in machine code for this architecture.
It's not necessary.
What you want to do is take an existing compiler on a different architecture and just write the code generated packet data that emits machine code.
It's just the last piece at the lowest level of that compiler.
So you can cross-compile.
Then you've got to compile in the machine.
You can also cross-compile an operating system and adaptions and so on, adaptations.
And once you have it on that machine running, you're independent.
You want to write, you're done.
Alright.
And more crazy than that, let's just think that the reference
Scala compiler, that compiles
Scala to Scala, by repeatedly compiling itself and not changing any code, not improving any codes, we can make that compiler better.
Particularly if it has strong optimizations. How could that be, right?
Just imagine you've got an optimization that actually is very expensive and it takes long, if it does more number crunching it produces better code.
The better code might be faster as well, right?
So you spend some time letting the compiler compile itself.
You get the compiler, but it's still based on the same source code.
But by having this number crunching for optimization the compiler is faster and can the next time it compiles itself it gets more quickly to even better compilation.
So you iterate this process.
You don't touch the code at all, right?
And the compiler improves itself.
So that's a possibility.
It's an extreme case.
You cannot expect it normally but it's possible.
