Welcome back to Nature in Code.
We are now in Chapter 6 lecture 6.
In this lecture we are gonna look at the third type of selection, namely that of Disruptive Selection.
So once again, let's go back to this slide, we have to 3 genotypes.
We have to 3 finesses.
And here, we said we get disruptive selection when H is larger than 1, which means that the heterozygote now has actually the lowest fitness.
So this is more like a fitness valley.
So let's look what happens when we implement this.
We have all the code in place now, all we need to do is essentially to change the age in both files.
So let's go over to our code and modified this.
All right, here we are in the code.
I still have these 2 files open.
Let's first go to delta P versus P, so open that file if you haven't, and let's change here the H to something that is larger than 1, so let's change it to 1.5, for example.
And now to save this and let's go to the browser and reload this file so here the tab has delta P versus P, so let's reload this.
And here's what we get, that's quite interesting, isn't it?
Because it seems like it's almost mirrored so what's happening here?
Well, let's take a look, so over here delta P is negative and over here delta P positive and again we seem to have this valley here at delta P zero, so some kind of equilibrium, which is not the treble ones
P equals 1 and P equals zero.
So very interesting, so let's see what happens here.
So let's assume we are somewhere here in this area.
So now I am here at P somebody says 0.2 or so, and the delta P is negative, that means I'm actually moving to the left because I'm reducing my P and it keeps being negative so I keep going over here until I in fact reached zero so I lose the allele, very interesting.
So let's see or hear what happens here let's say I am at 0.3.
So now the delta P is positive.
So that means in the next generation my P slightly increased by moving to the right here, and because delta P keeps being positive in this region.
I just keep moving to the right, to the right, to the right, until, finally, I reached in fact P equals 1, so that's very interesting when I start here,
P goes to succession and when
I start over here P seems to get lost.
So, very interesting dynamics and there is something here at this point, which is probably 0.25,
P doesn't change, but you can already see given what's happening over here, and over here.
Even if I'm exactly at this point, if I could push just a little bit to the left or to the right.
I will immediately go to the other equilibrium, so this doesn't seem like a stable equilibrium, but let's just go ahead and find out with our P versus time code.
So we're gonna go back to the file "P versus time". this is the one and
I'm just gonna set this aspect to 0.1 as we have before.
But here, importantly now
I want to change H to 1.5, so something larger than 1, so that we get disruptive selection.
Now if I save this and go over to the browser and open the "P versus time" and reload this,
Here's what we see.
This is really fascinating, so this seems to confirm our observation that here when we start with P values that are low and lower down, it seems like this 0.25 then we actually go down to zero.
So that means we lose the A1 allele, on the other hand though, if it's a larger than this 0.25 value it seems to go to fixation and here at this value, 0.25, it seems like we're in the stable equilibrium so this confirms what we observed with this other graph.
Now, so you could be tempted to think,
Ok, there are 3 possible outcomes it either goes to zero, it either goes to 1 or it stays at this equilibrium, but the thing is, again as we mentioned before, when we look here at delta P versus P, this equilibrium here is not really stable.
Yes, you could be at the point where you are exactly at delta P zero and then it will indeed be stable but just the tiniest perturbation here would push you to the left or to the right at which point Delta P would not be zero anymore and it would start this process of either going down or going up here, so it is not a stable equilibrium.
Can we somehow show this?
Yes we can, let's actually go back to our code.
So here's our P versus time code and this is where we initialized the initial p-values and so this just seems to be at exactly at 0.01 and going up by 0.01 we know we will probably have a bit of a rounding error but it's mathematically pretty insignificant, but what we could do now is we could say, "you know what?", you know we're gonna have a roughly 
0.01 difference between these initial P values, but we arere just gonna add a tiny bit of random noise just to see what's happening here, so, what I am going to do here is,
I am going to say you know what I want to add some randomness here so I am going to add "math dot random", but that alone, of course, wouldn't be good, because that would be a number between zero and 1 and so the values here would be all over the place, but I am simply now going to multiply this number with something very small, so, 0.000001, for example.
I'm gonna put these here in parentheses just so that it's clear.
So, what is happening now is,
"math random" as you know, a valey between zero and 1 if you know multiply this with his very small value we now get a very small but still random value between zero and this value here and this tiny bit of noise we are then gonna add here to our initial P value, and so if we now save this and go back to the browser and go back top versus time and reload this.
Here's what we see now, so you can see this previouly straight line actually goes up.
That's because we added a little bit of tiny noise you will not be able to see this here, but we're not at 0.25 exactly, but a slightly higher, just a tad bit of random noise that we added here a random value between zero and 0.000001, but that was enough to to give us this visual here.
In fact the did previous one vertix line was straight.
I'm pretty sure that it we weren't exactly at 0.25 but there was some rounding error and this would eventually also have gone up, but it would have taken a very long time, so I wanted to add this this random noise here.
In fact, if you reload this, as you can see this curve is shifting a little bit to the left and right.
Why? Well, because there's a little bit of random noise here and because it's random, it's always as a slight difference between these 2 values.
No two P values here in the beginning are going to be the same between reloads and that's why you get the slight shift here in the curve so it's still flat for a long time.
Why is that?
Well, if you go over to delta P versus P, in fact if you are here, exactly at 0.25, delta P is zero, but if you just a tiny, tiny bit below or above that value, then delta P is not going to be zero, but it's still going to be extremely small for a long time.
And that is why, even though things are actually changing here in P, they're so small, the changes are so small that we cannot visually perceive this here on this scale, but it is happening just very, very slowly, and eventually this hits this spot where it's really starting to take off, so suddenly we are really getting into this area here.
And then, or rather here actually, we're going positive.
And finally, this process will accelerate.
And then, of course, slow down again as we approach 1. so this is disruptive selection and this is to me, kind of the most fascinating type of selection, because we get, even though this is a deterministic model, we get two possible types of outcome.
And this is interesting, isn't it? because we think often of evolution as this deterministic process we now know that this is not true at all, given the effects of drift and of mutation also, which is random, but still here, you would say okay I start with a certain population and certain frequencies are always gonna go in the same direction and that is true, but if as soon as you change the values here it's not true anymore.
It can go either way, either of the extreme ways so this really depends on the initial conditions here and that's a key feature of disruptive selection that you will get very different outcomes.
You will lose one of the alleles, but which one you lose depends completely on where you start.
So what about this value here?
Can we actually calculate where does change happens?
Where, if you're above you're gonna go to fixation if you're below.
We're gonna go to fixation of the other allele and yet turns out this can actually be calculated as well.
So it turns out this point is actually calculated in the exact same way, so it is also calculated as
H minus 1 divided by 2H minus 1. and if we now put in the corresponding value of H equal to 1.5 then what we get here is slightly changed, we get 1.5 minus 1, that's of course 0.5.
We get 2 times 1.5 which is 3 minus 1, which is 2 and so 0.5 divided by 2 is exactly this 
2.5 that we observed in the simulations.
Okay, so this finishes our treatment of the 3 types of selections that saw here in these different graphs. so quite interesting, if we have directional selection we will only ever go in one direction, one of the alleles will be fixed and it's very clear which one
In the case of balancing selection.
None of the alleles goes to fixation, but we will go to some sort of intermediary value.
And in the case of disruptive selection.
One of the alleles will go to fixation, but which one it is, very much depends here on the initial of value of the allele frequencies.
So this now concludes our treatment of these 3 types of selection: directional selection, balancing selection, and disruptive selection. very fascinating, very different outcomes depending on the fitness of the heterozygote.
In the next lecture we'll get to know a new type of selection.
And that is when actually many species start to interact with each other and start to interact with each other's fitnesses.
In this case you have something called coevolution and that's a really fascinating phenomenon as well.
So let's take a look in the next lecture. I'll see you there.
