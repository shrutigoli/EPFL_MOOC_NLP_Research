Okay so let's summarize by looking at caveats.
So the main caveat of course is that there may be critical data that is missing.
Now I did mention that the challenge or the goal, the mission of simulation beuroscience is not to get everything.
It doesn't mean that we shouldn't get as much data as possible but the algorithmic goal is to find what is the minimum data I need to do a complete reconstruction.
And in that search for the minimal data, it may be that there is critical data missing.
If you don't have neuronal morphologies, it is going to be very difficult to build a circuit.
So you have to find a way to get neuronal morphologies.
So we can call them critical data or strategic data.
And that means that one has to go back to lab and one has to do experiments and one has to obtain that critical data.
The other caveat is that biological data has a lot of mistakes.
In fact there are much more mistakes than accurate data.
It is by far more that there are errors than there are correct data.
So we shouldn't be so quick to believe biological experiments,
I am a biological experiment,
I measure lots of things and when you actually look at it and try to use it, you quickly see if it really fits with other data or not.
In fact the best way to find out if your data is right or wrong is to try to use it in the combination of others.
And we will show you examples where this actually does show you precisely where experiments have gone wrong.
But it does make reconstructing difficult when you have this huge discrepancy in the biological data set.
But on the other hand, it turns into a positive because you can curate the data, you can actually identify what is reasonable.
This data is just not reasonable, it cannot fit with all this other data.
And then the other caveat and it is not really a caveat, it just means that we are evolving in the way that we do Neuroscience.
Instead of disciplines being fragmented across many labs and different people, if you do simulation neuroscience, you have to become multidisciplinary.
You have to learn about experiments, analysis of data, informatics computer science, mathematics, algorithmics, computational sciences and so on.
In summary, we looked at approaches.
And it is really experimentation, theory and the third branch of knowledge generation is simulation science. 
Not only in neuroscience, in many of the other sciences.
There are 3 branches of how you advance a knowledge.
The rationale for simulation neuroscience is that it is a big data problem.
It is not going to be solved only with experiments.
It is not going to be solved only with theory.
The principles of simulation neuroscience are fundamentally that you need to build a dense reconstruction from sparse data.
Your challenge is to find the smallest data set that will give you a detailed reconstruction.
You build bottom up.
In other approaches, you start top down.
Iterative reconstruction, you reconstruct, reconstruct and it refines.
It is almost like a fitting algorithm or a gradient descent where gradually the digital reconstruction becomes more and more precise becoming the digital copy of the neuro tissue.
The data strategy is really to establish a hierarchy of data components.
You have to do a lot of very careful data analysis so you get all the parameters.
Informatics strategy.
Find it all.
Bring it all on the table and ask:
"how does it fit together?"
There is some value in every study.
And this is actually very powerful because if you go into the literature and you say
I am only going to find the best work out there, you are going to have a hard time deciding what is the best work and there is going to be contradictions and not but more importantly, you could miss very important little statements, findings in bad papers.
So, our approach is, let's find the gems in any paper.
Some papers may have lots of gems and other papers may only have one and some may have zero but that is fine, you don't know that and you actually have to approach it as if there is a gem and I want to look for it.
That is the informatics strategy that we adopt in simulation neuroscience.
Reconstruction strategy, you build the components, you freeze down and validate up.
You validate the emerging properties.
You never fit to the emerging or you try not to fit to the emerging properties.
You build workflows so you can run this machinery over and over.
You validate against independent data and emerging properties.
And, of course, you need a supercomputer because you need a lot of fast communication and you need a lot of memory and it does simulations and is about allowing you to mimic experimental neuroscience.
