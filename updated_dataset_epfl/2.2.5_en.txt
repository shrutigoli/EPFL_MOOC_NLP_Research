Professor David Bresch has a background in Physics.
More than a decade ago, he joined Swiss Re in Reinsurance, especially to work in Natural Catastrophe Modeling.
More recently, he became professor at ETH-Z, in the context of Weather and Climate Risk.
In this video, Professor Bresch will focus on Catastrophe Modeling related to storms.
Natural catastrophe modeling has many sources where it started from.
One was just the willingness to understand things better.
That's more the scientific part of the story, where people say,
"We would like to understand how these things come about, and what might be a consequence of something happening."
So it's almost the scientific element of natural catastrophe modeling.
And then you have, on the other side, you could say those impacted, be it on the ground or being those who help them, who are impacted, for example, those who provide financial relief, namely insurers, and they wanted to better understand what could all happen, basically, to our clients, and how can we better help them to cope with the situation.
And what we normally do in the natural catastrophe modeling community, you might say, is really to quantify hazard-- how often, and how strong things can hit you?
Second, where are you?
What are your interests, your livelihoods, what matters to you, be it your life, be it your belongings? and then also to quantify vulnerability.
And then we play it all through in a model by basically simulating artificial storms, so storms that haven't yet happened, but could happen, and hit such a place, and then figure,
"Aha, that would be the wind speed a scientist tells me could happen in this place.
That could be the damageability of a building, or that could be the necessity for people to move out temporarily, and come back after the storm," and you can quantify risk using all these tools.
So what you see on this short animation is, first, a layout of exposed assets in Bangladesh, in a map, colored from blue to green, basically where people are, and then basically you see a tropical cyclone coming across, hitting from the coast all these assets, and where the dots turn from yellowish to red, that's where the things are hit by the tropical cyclone.
And that's what's in the center of such a natural catastrophe model.
It now simulates not only one single cyclone-- this was Sidr, in fact, in Bangladesh-- it simulates all kinds of possible cyclones hitting exposure, for example, such as on this picture, and then with that type of an approach, you can quantify risk much more precisely and spatially explicit.
Then you can basically use that model to think about what would happen if people would build differently.
So you change the vulnerability of buildings.
Or what would happen if people were better warned, warned earlier, and could basically evacuate?
You can use these models to quantify these consequences.
On the building side, probably more on the damage in dollar terms, but when it comes to people, in the evacuation and emergency planning, also how many people, how many lives could be saved in such cases, such a kind of event.
And so you can use this engine to place you all kind of risk mitigation options might have, and then figure what would be a reasonable basket, or a reasonable group of things you should implement, in order to strengthen your local resiliency against, for example, tropical cyclones.
Then, interestingly, you can also use that model not only for risk today, you can also put in the model your development plan, and say, over time there will be more people in that place.
Now, if you don't change anything else, so caeteris paribus: more people, same hazard, it will still be more risk, and so you can also put in a model climate change.
You can also say the storms are going to change in intensity and frequency, and also that if that's going to increase, then obviously there is more risk, so the model can show you how much more risk there is.
But, interestingly, it will also tell you that you shape, and people, local communities shape their future.
So if they develop in another direction, take another pathway, it could be, there will be more people, but they will not be more vulnerable.
They might build in a different style.
They may be better informed, better managed on a governance level, and therefore risk can be maintained or even reduced in these places.
And so you can also then use these models to look at the impact side,
"What's the benefit of a specific intervention?" and you can also use the same model to cost that intervention, and say, "How much would it cost me to do so?"
So we use this kind of facts, also, to help local decisionmakers to build an adaptation strategy, and underpin this strategy with an adaptation roadmap: ultimately, a funding plan.
The contribution of science to that was to really very well understand the hazard part of the story.
We're still learning a lot about the other components of the model.
Especially the vulnerability part is not so well understood.
It's also much more difficult because it has a lot to do with social science.
It's culturally extremely different, so there are societies which react differently.
The same speed of wind at the same level of flood, there are different reactions by different communities and constituencies, and that's absolutely fine, it just needs to be understood.
And so there is this element of, on the social science side, to understand how do communities react to these kind of exogenous shocks to their economies and livelihoods.
And then, obviously, the contribution from the financial services sector, you could say, or from the reinsurance and insurance in particular is that they added a certain rigor to these models to really be able to use these models as decision tools.
Not all cultures value the present, the future, and the past with the same relevance, or weight.
So some cultures are more rooted in the past, some more in the present, and for some, the future matters more.
And these models bring that very much on the table.
So for some constituencies, the emphasis we put on the future situation, say 2030--
What would climate change look like by then?
What would your livelihoods look like by then?
Some people they're not so much interested in that.
Ten, twenty years down the road was too long a time scale.
It mattered more what's currently happening.
And let's be honest, most OECD-country companies also operate on, when they say 'strategy,' they mean five years.
So it's pretty human to rather look at the present, and then build it from there.
And let's be honest, many are at least as much guided by the past, rather than by their foresight.
And I think that what we should try, what the modeling community tries to bring to the table, is make better use of all the things we know already.
So in that sense, often we do not need even deeper science, in one of these specific areas, you could also say silos.
What we really need is to connect these things.
The model needs to have a purpose, and a model is not, per se, good or bad.
The question is only is my model fit for the specific purpose?
Now, you could say a model that can accommodate more than one purpose, or a wider purpose, is probably a bit more powerful model.
But still, good or bad is too much a normative kind of a question in that context.
It's more is it fit for purpose?
For example, a global circulation model in a climate space is fit for purpose to determine the climate sensitivity of that weather and climate system.
You ask questions or answer questions,
"Is there human influence, and how could that play out?"
Now, a natural catastrophe impact model is much more on the ground, it's much more specific to say
<i>if</i> a quake is happening,
<i>if</i> a hurricane is happening, what's the physical consequence?
What's the environmental, social consequence?
What's ultimately the economic consequence of things?
And you can always ask what kind of complexity you really need in order to tackle your question.
And then there is probably at this point the simplest model that is fit for purpose has definitely an advantage, just because it's simple to operate, to use, and not least, simple to communicate.
And so that's also an element.
I've often seen too many bells and whistles in these models.
You might get a bit better, a notch better still, but if you engage in community dialogue, and you want models to be embraced by a community, you better err on the simpler side, because that's where there's a higher buy-in, and then over time you can still increase, in specificity or in precision of models.
And, let's be honest, it's quite often also mock precision, because it's not so easy for some of these models to measure their performance, because luckily in many places you haven't seen so many catastrophes, and so these models are used to play possible outcomes through, and they should not so much be used as predictive tools to say that's exactly how it's going to be, it's more to say it helps us understand what we can do about natural catastrophes.
What's really made, I would say, a tremendous change to that endeavor in the past decade or so is that more and more of that data is openly accessible, so a lot of the hazard information you can get for free.
The only thing you need is have the skills to digest that information.
And then also the cat modeling, so the engine which puts hazard, exposure, and vulnerability together, exists now more and more in the open space.
One thing to mention is what I've developed, since five, six years now, is Climada, a natural catastrophe risk assessment model which builds on a wealth of openly accessible data, for example worldwide, all hurricanes, tropical cyclone events, as called in other places, then also, on the earthquake side, the volcano side.
And basically it provides-- to model natural catastrophes in quite high resolution, normally higher resolution than a kilometer, almost all over the planet.
What then users have to put in is their own exposure, so they have to figure where they are and what matters to them.
That's something you cannot impose on people.
So these models need to be open also in the sense to digest additional information that comes from different sources and constituencies.
And again, important is not only that the engine is an open piece, also the interfaces to it are open, and can easily be changed.
That's why this thing is developed in MATLAB, which is an engineering software, which luckily also has an open-source version to it.
So those who are not in a position to pay a MATLAB license, they can use Octave, and Octave is an open-source clone of MATLAB.
So basically anybody who has a laptop can download all of it for free from the internet, and get started, so to say.
But I mentioned, it does need skills, so it's definitely something where people with training in engineering, natural science, and also social science, for the impact side, have an edge, and an advantage.
And I think for those people, what such a model provides is in essence a platform, a platform to bring all these different components together to really quantify risk.
How will natural catastrophe models further develop?
One avenue is clear: still more comprehensive coverage, so more perils, combined perils, for example.
Our models, they do combine tropical cyclone wind, and surge, and the heavy downpour, the excess, the torrential rain, and you can basically look at the combined impact of these things.
One thing you also see is people like to look at consequential events, so series of events.
These models do capture them.
You can make them capture them.
But the question is if a community has been hit once, it will not be the same afterwards.
And if it's hit three times, it starts to adapt.
So an interesting avenue would be agent-based approaches to cat modeling, to say, hey, these people being hit by a storm, they will not sit and wait for the next one.
They act.
Nowadays, the models do not incorporate that.
You basically would play it once, and it would say,
"Aha! That's why people do something differently," but then you would basically not bring that back to the model.
But that would be an interesting avenue.
So one is definitely the resolution game.
Still, it's not over, because still it can get better, going for city, even street resolution; you do learn something from doing that.
It depends, again, what you want to do with the model.
So if the model is built, or should be built, for the purpose to advise city planners, then there is ample ground to improve the quality with that goal in mind.
But if it's more to say how can these models help us better understand how our development pathways, in a pretty turbulent world, could shape out, then probably this other avenue of bringing more, you could say, the socio-economic piece more actively into the modeling, is something I see a lot of potential.
Also, linking it up with economic growth trajectories, development trajectories, and how people shape their own risk landscape, because currently the models are pretty static in that sense.
That's a place where I do think we will see a lot of change in the next decades or so.
