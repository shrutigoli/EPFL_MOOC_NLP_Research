Now I will present theorem 1.1 from the book, which allows us to explain the results in some cases. 
I remind you that the problem is the following: let us consider a function f defined on an interval [a,b] in R. We considered t_j equidistant interpolation points, t_j = a + (b-a)*j/n for j=0,1,...,n. 
These t_j points are equidistant.
Let p_n a polynomial of degree n which coincides with the function f in the points t_j.
So p_n is equal to f in t_j, for j = 0,1,..,n. p_n is a linear combination of the functions phi_0, phi_1, ... phi_n which are the Lagrange basis polynomials of degree n associated to the points t0,t1,...,tn. So p_n of t is f of t0 times phi_0 of t plus f of t_1 times phi_1 of t plus...
 f of t_n times phi_n of t.
Again, phi_0, phi_1, ... phi_n are the 
Lagrange basis polynomials of degree n associated to the points t0, t1, ... tn.
The hypothesis is that f is
(n+1) times continuously differentiable on the interval [a,b] and the conclusion of the theorem is the following:
I am interested in the error, i.e. the difference between the function f and the polynomial p_n of degree n also known as the interpolant of f associated to the points t0,t1,t2, ... tn.
I track this error at all points t, and consider the maximum of the error on the interval [a,b]. I then claim that such this error is upper bounded by 1/(2*(n+1)). times (b-a)/n elevated to the power (n+1). times a term which brings in the (n+1) derivative of the function f on the interval [a,b], in absolute value and consider the maximum of this quantity on the interval [a,b]. Hence the error between the function f and the polynomial is upper bounded by a term which approaches zero as n approaches infinity and another term which uses the derivatives of increasing order.
Let's consider two cases which correspond to both examples done in the java apps.
In the case where f(t)= sin(t)
I know that all derivatives of sin(t) are upper bounded by 1 , this for all t in [a,b] or even R. 
This quantity is bounded by 1, this one approaches 0 as n approaches infinity.
So we must have the limit of the maximum of the error between the function f and the polynomial p_n goes to zero as n goes to infinity. 
In the case when f(t)=1/(1+25*t^2), an explicit formula of the derivative can not be given.
Neverthless I can observe that the (n+1) derivative of f goes to infinity as n goes to infinity.
Hence there is one term which goes to infinity as n goes to infinity, and a second one which goes to zero so no conclusion can be made.
Nevertheless the numerical examples show that the polynomial moves further away from the function f.
At least the maximum of the error goes to infinity when n goes to infinity. The conclusion is the following: choosing equidistant interpolation points is not a recommended when the number of points goes to infinity i.e. when the degree of the polynomial gets higher and higher. 
One method to resolve this issue is by choosing points with adequate spacing on the interval [a,b].
By experimenting with the java app, you can see that by placing more points towards the edges of the interval, things get better. The other solution which I will do next in the course, is interpolation by intervals.
This is what is done in finite element softwares.
