1
00:00:05,700 --> 00:00:10,096
Hi, in this video Mark van den Homberg 
will explain how social media

2
00:00:10,096 --> 00:00:13,996
and artificial intelligence
can be used for emergency response.

3
00:00:14,739 --> 00:00:18,251
Social media is,
in developing countries, on the rise.

4
00:00:18,976 --> 00:00:22,457
It's still very important
to take into account

5
00:00:22,457 --> 00:00:25,137
the penetration of social media.

6
00:00:25,137 --> 00:00:29,507
You always have to think about how many
people are really using social media.

7
00:00:30,099 --> 00:00:35,129
There we can see quite large differences 
between developing countries.

8
00:00:35,129 --> 00:00:38,345
For example, the Philippines is known 
as the "capital of the selfies,"

9
00:00:38,345 --> 00:00:41,177
and the "capital of the text messages."

10
00:00:41,765 --> 00:00:44,890
But Afghanistan,
on the other hand, or Pakistan,

11
00:00:44,890 --> 00:00:48,310
there people use social media much less.

12
00:00:48,310 --> 00:00:51,250
But still the expectation is
that the penetration

13
00:00:51,250 --> 00:00:54,252
of very affordable smartphones

14
00:00:54,252 --> 00:00:59,991
will really continue, and at a rapid pace.

15
00:01:00,532 --> 00:01:04,371
Also people in those countries
that do not use social media right now,

16
00:01:04,371 --> 00:01:07,251
they will start using it
in the future, for sure.

17
00:01:07,758 --> 00:01:11,641
So it's good for the humanitarian 
community to be prepared,

18
00:01:11,641 --> 00:01:16,311
and to identity what they can
take out of social media.

19
00:01:17,081 --> 00:01:20,075
So there is, actually,
a lot of expertise already

20
00:01:20,075 --> 00:01:23,003
in the area of doing
social media analysis.

21
00:01:24,024 --> 00:01:28,876
There are different ways to collect
tweets from Twitter,

22
00:01:28,876 --> 00:01:31,466
or to collect messages from Facebook,

23
00:01:31,466 --> 00:01:37,872
and to use artificial intelligence
for disaster response, AIDR,

24
00:01:37,872 --> 00:01:41,327
to analyze all those tweets, for example.

25
00:01:41,327 --> 00:01:47,750
Artificial intelligence is a very 
important tool that one can use.

26
00:01:48,210 --> 00:01:51,846
And it's actually necessary,
because in social media,

27
00:01:51,846 --> 00:01:55,010
the volume of data
that is created is enormous.

28
00:01:55,867 --> 00:01:59,976
And as you can imagine,
also in times of a disaster

29
00:01:59,976 --> 00:02:04,702
people are not only tweeting
or writing on Facebook about the disaster.

30
00:02:05,261 --> 00:02:10,256
So you will have a haystack of data,
of tweets, of postings on Facebook,

31
00:02:10,256 --> 00:02:12,600
which is enormous,

32
00:02:12,600 --> 00:02:16,530
and it's very hard to identify
the needle in the haystack.

33
00:02:16,530 --> 00:02:20,645
So it's very important to filter the data,

34
00:02:20,645 --> 00:02:24,969
to take out also,
for example, botnet data.

35
00:02:24,969 --> 00:02:28,498
Botnets are artificial tweet accounts,

36
00:02:29,750 --> 00:02:32,774
a kind of robots that are sending,
automatically, messages.

37
00:02:32,774 --> 00:02:36,089
So you can imagine, we really
have to take out that data

38
00:02:36,089 --> 00:02:38,513
before you can make sense of it.

39
00:02:38,513 --> 00:02:41,644
And artificial intelligence
is a way to do so.

40
00:02:41,644 --> 00:02:45,271
One can use text mining and data mining

41
00:02:45,271 --> 00:02:48,281
to automatically filter out those messages

42
00:02:48,281 --> 00:02:51,320
that have no relevance at all
to the disaster.

43
00:02:51,878 --> 00:02:57,608
But the issue or the difficulty is that there are
so many tweets being sent

44
00:02:57,608 --> 00:03:01,586
that it is so very hard
to find the relevant information.

45
00:03:01,586 --> 00:03:04,296
So even with artificial intelligence,

46
00:03:04,296 --> 00:03:09,446
it's not possible to completely filter out

47
00:03:09,446 --> 00:03:11,481
exactly the information you need,

48
00:03:12,277 --> 00:03:14,348
and that actually [led]
to the development also

49
00:03:14,348 --> 00:03:18,357
of a digital volunteerism movement.

50
00:03:19,188 --> 00:03:23,608
We have several organizations
where people are active,

51
00:03:23,608 --> 00:03:27,395
and that are willing to devote
their free time to help

52
00:03:27,395 --> 00:03:30,507
with what is sometimes called
'micro mapping',

53
00:03:30,507 --> 00:03:34,727
or analyzing tweets
at an individual level.

54
00:03:34,727 --> 00:03:36,872
And they can help to complement

55
00:03:36,872 --> 00:03:42,013
the artificial intelligence part
of the analysis.

56
00:03:42,013 --> 00:03:45,830
It's important to realize
that the social media analysis

57
00:03:45,830 --> 00:03:50,793
will give you results that should never
be considered on its own.

58
00:03:50,793 --> 00:03:55,089
It's an add-on to all
the other data sources.

59
00:03:55,089 --> 00:04:01,161
But the additional value of social media
is often that it can be very timely.

60
00:04:02,109 --> 00:04:06,021
It's very fast, so it gives you
a very quick update

61
00:04:06,021 --> 00:04:08,704
about, also, sentiments in a community,

62
00:04:08,704 --> 00:04:13,286
whether they are happy
about the aid or the responders.

63
00:04:13,286 --> 00:04:16,488
And in the case actually of,
for example, the earthquake in Haiti,

64
00:04:16,488 --> 00:04:21,078
it was also really useful to identify
where people were trapped,

65
00:04:21,078 --> 00:04:24,943
so really to know where the first response
was needed the most.

66
00:04:24,943 --> 00:04:27,792
The use of social media--
there are a lot of limitations.

67
00:04:28,621 --> 00:04:32,444
One of the limitations
is related to the fact

68
00:04:32,444 --> 00:04:37,062
that not all people affected by disaster
are using social media, of course,

69
00:04:38,074 --> 00:04:41,768
and also, on top of that,
that we will never have access

70
00:04:41,768 --> 00:04:45,700
to all the tweets that are being sent,
because, for example,

71
00:04:45,700 --> 00:04:50,391
Twitter allows you only to get 1%
of the tweets that are being sent

72
00:04:50,391 --> 00:04:53,750
through what's called their 'fire hose'.

73
00:04:54,769 --> 00:04:57,029
If you want more, you have to pay,

74
00:04:57,029 --> 00:05:00,541
you have to have
a commercial agreement with them,

75
00:05:00,541 --> 00:05:03,750
so often only 1% of the tweets
that are being sent

76
00:05:03,750 --> 00:05:06,750
are really there to analyze.

77
00:05:06,750 --> 00:05:09,547
So if you have 1%
of only 8% of a population

78
00:05:09,547 --> 00:05:11,197
that is using social media at all,

79
00:05:11,197 --> 00:05:14,209
you have, of course,
a very small percentage.

80
00:05:14,209 --> 00:05:17,593
So that's a first important limitation.

81
00:05:19,603 --> 00:05:21,937
Another limitation is that...

82
00:05:24,258 --> 00:05:28,436
that you have to identify
the trustworthiness

83
00:05:28,436 --> 00:05:31,830
of the people that are using social media.

84
00:05:31,830 --> 00:05:34,769
Can you rely on what they are saying?

85
00:05:34,769 --> 00:05:37,931
How do you verify and validate
what they are saying?

86
00:05:37,931 --> 00:05:43,159
So you will need other data sources
to validate what people are saying.

87
00:05:43,159 --> 00:05:47,134
A third limitation...
or well, maybe it's not a limitation,

88
00:05:47,134 --> 00:05:50,926
but it's something that you have
to be careful about

89
00:05:50,926 --> 00:05:57,100
is whether you are dealing
with personally identifiable information,

90
00:05:57,100 --> 00:05:59,220
what is called PII.

91
00:05:59,220 --> 00:06:00,190
If you analyze tweets,

92
00:06:00,190 --> 00:06:05,421
you might also enter
into the privacy spheres of a person,

93
00:06:05,421 --> 00:06:09,099
and if you are analyzing it,
and then conveying that information

94
00:06:09,099 --> 00:06:14,080
to other different stakeholders,
you never know what they can do with it,

95
00:06:14,080 --> 00:06:16,971
and especially in complex emergencies
or conflict settings,

96
00:06:16,971 --> 00:06:20,037
one has to be very careful
about what one is doing

97
00:06:20,037 --> 00:06:22,479
with social media data.

98
00:06:23,904 --> 00:06:26,534
One counter measure is
to aggregate the data,

99
00:06:26,534 --> 00:06:31,341
and to take out
the personally identifiable information,

100
00:06:31,341 --> 00:06:34,535
so that's actually also often done,
to make sure that you have

101
00:06:34,535 --> 00:06:40,248
no identifiable information
left after your analysis.

102
00:06:41,008 --> 00:06:43,295
It's important to realize
that social media is also

103
00:06:43,295 --> 00:06:45,850
very dependent on culture,

104
00:06:45,850 --> 00:06:50,354
so instead of assuming
that everyone will be using Facebook,

105
00:06:50,354 --> 00:06:53,214
one really has to think
about the local context.

106
00:06:53,214 --> 00:06:56,789
For example, in Russia,
people are using VK.

107
00:06:56,789 --> 00:07:02,579
In China, they have also their own kind
of Facebook-type of social media,

108
00:07:02,579 --> 00:07:06,248
so it's very important to understand
from which target audience

109
00:07:06,248 --> 00:07:09,139
you want to have information,
and then to make sure

110
00:07:09,139 --> 00:07:11,930
that you understand
which type of social media

111
00:07:11,930 --> 00:07:14,100
the target audience is using.

112
00:07:14,100 --> 00:07:17,296
For example, among kids
it's now already Snapchat,

113
00:07:17,296 --> 00:07:21,282
or new social media
which the parents have never heard of,

114
00:07:21,282 --> 00:07:23,104
so that's important to check.
