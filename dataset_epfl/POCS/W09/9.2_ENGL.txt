So, to explain the distinction between compilation and interpretation, this is a bit difficult and artificial because the distinction has been changing, and, things have been converging with time.
But from a certain viewpoint,
I could say compilation is bulk translation between languages and execution at the end.
So, that means I statically combine once and then I might, as a whole, execute in that translated form already.
A compiler from A to B, will take an input in language A, produce an output in language B and then we can execute that program in language B whenever we want, as many times as we like.
And interpretation, that's the kind of translation on the fly, we do the translation transaction operation by operation, or statement by statement of the language then immediately execute it, so to say.
It's one viewpoint, of course, you can look at it from a different angle.
In the past, there was a great distinction between compilers and interpreters, but recently we have seen these kind of staged ecosystems, where there are all kinds of hybrids happening and multiple stages of compilation and interpretation happen.
So, this, for example, has become a lot more subtle.
Also, because there might be all kinds of levels of virtualization on all kinds of levels, that might be akin to interpretation or not.
The staging that is just-in-time compiles special occasions on (inaudible) distinction.
So, there are a number of terms that are related.
Simulation, interpretation, emulation and virtualization.
We've heard discussion of emulation and virtualization, right?
Emulation is one of the tasks maybe also virtualization, emulation is of existing real hardware.
While you could say interpretation is for programs.
Simulation essentially captures all of it.
Simulation is typically used, for example, simulating the physical world a biological system or things like that.
So, all these terms it makes sense to talk about.
So, we've seen in the previous module about and heard about virtual machines and virtualization, there are, of course, language virtual machines specifically like the famous
Java virtual machine.
And they have a somewhat different purpose from the typical purposes of virtualization infrastructure.
They're primarily in place to support things like late binding and late compilation: adaptive computation.
And to bring forth portability of code.
For example Java bytecode is a language for which there are virtual machines that can execute this Java bytecode on many different architectures.
So, we can use the same kind binary codes, or pre-compiled codes, loaded code on many different architectures, so it's very portable.
And that's the goal of this virtual machine.
And it's less to virtualize resources.
It's less the task of a language virtual machine.
So, language centric VMs also sometimes don't really feel like machines.
Well, you could argue that a virtual machine for Java bytecode does feel like such a virtual machine, but there's also, for example, relational database managers and career engines, that you can think of as relational algebra virtual machines, right?
Or that (inaudible) some of them are very language-centric, and these languages are distinct from what you would think of as something like a CPU, so that it's reasonable to think of it in different ways.
Let's talk about a few principles of the context of interpretation as a goal itself.
And one is, you know, we want to interpret to realize additional levels of indirection.
So, we can use a virtual machine or interpret a high-level language to be machine-independent, as we said, portability.
The system becomes portable and can be separated from legacy system components.
And Java Virtual Machine is an example.
When we are inlining a compilation result is too big or too costly to build in hardware.
An example would be microcode, to delay a system's becoming legacy.
So, we want to support scripting, right?
On one hand you could write a fixed, monolithic system, adjust that a certain drop.
Or we could make it scriptable, so that it accepts some kind of permit authorization.
Permit authorization could be flexible enough that you can think of it as programmable, first the parameter file, but there is some kind of scripting way to extend the modifier to keep the system fresh.
So, that's a way of really fighting legacy in the sense that you could argue that any system is not scripting at all, is already a legacy system.
Of course there are many examples of scripting.
We've seen many cases and, of course, you can think of scripting languages as domain-specific languages, right, and often enough they are easier to use.
That's why, for example, many first year programming courses nowadays in the US use Python, because you don't have to worry about typing any more, it's relatively easy to use and so on, it's quite robust and so on.
Of course there are things like the UNIX shell and command line tool, which is really getting scripting capabilities in a sense to an operating system.
Or in database query processing, is a set sequel engine.
Or that's maybe contestable, but I could argue that maybe open floor and software-defined networking are a bit like this.
Particularly if it's flexible enough that you can really script them, it's not just some in parameters.
Another principle I already mentioned in some ways, is staged compilation.
Once you have the ability to interpret and make your way from a program in a high-level language, let's say, which you have programmed to the machine code that is executing, if you can make it multiple stages, you have additional potential, for example, for being adaptive and being more efficient.
Classically, we had the choice maybe to take either this kind of high-level host language program and run the interpreter instruction by instruction, apply its kind of template translation and execute that.
Or a compiler could statically take the input code and produce machine code.
And there were things like Java, where you go write Java bytecode, you compile, statically, offline to Java bytecode, and that's what you ship and that's what people see and there's a lower virtual machine that is rather efficient already.
But that machine might have behaved like an interpreter and more recently there was actually a just-in-time compilation,
JITing happening.
Rather than taking the bytecode and executing it instruction by instruction like a machine, we would still have a low-level compilation to real machine code and it's done once and for example you compile the loop once rather than translate it every time you execute for its instructions.
And there's of course potential there, particularly since at that point in time you might actually know quite a lot about your data, and might use this to further do some loop unrolling, or fusions and so on, inlining, to actually make things more efficient.
On the other hand, concretely for Java bytecode, this actually doesn't work so well, because Java bytecode is missing type information that would actually be very important to do useful optimization actually right now they're working on changing the standards here, to actually make more optimization happen by having a typed version of intermediate language.
So, of course, these kind of managed codes that are run in a virtual machine, can buffer for many kinds of protections, memory protections, garbage-collected memory so that you don't have to worry about memory leaks in a sense.
Memory protections, in a sense, that you can't do overflows or writing of protected memory and so on.
Catch alloc-dealloc bugs and so on.
Array bound checking and so on.
Things like that.
So, you can get additional protection and avoid certain bugs, or at least damages resulting from the bugs by such a system.
It does some debugging for you so to say.
Now, some examples of such staging.
As we've already said, Java VM, particularly Java Hotspot.
It's a really now supporting a compilation a static compilation and a virtual machine that does JITing and adaptive optimizations in there.
It's hard.
LLVM is not a very famous framework that is based on the C language, and creating a new C compiler, that actually basically compiles C code in an intermediate, low-level presentation in static single-assignment form.
Something, again, like a bytecode representation, in which there are actually tools for doing all kind of analysis and optimizations, and also just-in-time compilation to run the thing.
LMS, lightweight modular staging, is something that has been developed and lives in the Scala ecosystem, the Java ecosystem.
It's again staged compilation, where you can basically lift any Scala code, you can easily write DSLs, but basically making a superset of the subset of Scala, and adding new operations or new library functions etc.
And you can stage compilation.
Every piece of code can be lifted during presentation and then you can have, multiple stages of translation, optimization, transformation that might go from a lifted version to a lift first, so you can use as many steps as you like and at some point you emit code, or you actually execute it.
So, you can build all kinds of multi-level just-in-time compilers and things like that if you like.
So, there is this myth that high-level languages are necessarily less efficient.
If you write something in C, it will be always faster if you do a good job and if you are competent, than writing it, let's say, in Java or Scala.
Although to some extent this is true if you do a perfectly competent job, but we have already seen, for example, in register allocation that a C compiler nowadays outperforms even the best humans.
So, we won't even try to write assembly code any more, because in the time of your multi-core super Scala, superpipeline processors, it's actually, too hard for a human to do this in practice.
It's impractical; C compilers beat the humans nowadays.
And we're getting to do this somehow, slowly, all the formal high-level language and high-level aspects of compilation.
So, it's not necessary that we're slow.
For example, if you have heavy allocation/deallocation of small objects, continuously changing that, and every time, for example, in C you go through malloc, which has huge overheads as a system code to the writing system and so on, lots of things happen there.
This can actually be much slower than if you actually in bulk allocate a big region of space and then have your own management.
As, for example, the Java virtual machine does it for you.
If you, for example, write heavily dynamic data structure transformations and so on in C++, you won't actually be beaten by Java off the shelf.
Another thing is that the more high-level you are, the more time and cycles you have left, because you spend less time coding, to actually improve and add more intelligence into your code, so to say which then your system can profit from.
A classical example here, is the Singularity operating system, from Microsoft, which is an operating system, written completely in a high-level language, actually a fragment-- a dialect of C#, and that runs in a virtual machine in the CLI, the Common Language Interface.
And they have done all kinds of interesting optimizations and, actually, this operating system beats classical operating systems, even developed, implemented like Linux, very substantially.
For example, process overheads.
Once you start implementing your applications and even in the operating system itself, it is high-level language, which is done in Singularity, you've got the potential for static analysis on this high-level, for example, for merging processes that don't need to be separate.
That you don't put into the process switching all the time in the operating system.
One thing it does is called software isolated processes, which are not isolated processes at (inaudible) any more, but it's compiled and you verify that nothing bad can happen, and then you don't have to do so much process switching between them, which is actually very expensive.
Switching the context in and out and so on, for an operating system.
You can actually get better performance in a high-level language because of modern technology, modern compilers and language technology and because we've got more cycles for doing intelligent optimizations, because it's less code to write.
