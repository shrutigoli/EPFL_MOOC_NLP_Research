1
00:00:04,168 --> 00:00:09,262
So there was an old belief in biology

2
00:00:09,262 --> 00:00:13,156
that a self-describing program,
so to say, is actually not possible.

3
00:00:13,156 --> 00:00:17,233
So the idea, the argument is,
if my genetic code

4
00:00:19,423 --> 00:00:23,563
captures my full complexity,
it must occupy all my space, right?

5
00:00:23,923 --> 00:00:28,256
How could I, where's any space left for me,
for myself, for that life form?

6
00:00:28,256 --> 00:00:32,653
So it was actually an argument
against some pure mechanism

7
00:00:35,463 --> 00:00:36,839
for biology and life.

8
00:00:36,839 --> 00:00:39,671
And that there wasn't a need
for divine intervention

9
00:00:39,671 --> 00:00:43,304
for life to exist
and actually to even procreate.

10
00:00:44,114 --> 00:00:46,499
We know now, of course,
particularly in computer science

11
00:00:46,499 --> 00:00:49,753
because we have learned
this from the start,

12
00:00:49,753 --> 00:00:51,690
that this is a silly argument, right?

13
00:00:51,690 --> 00:00:56,519
And if you look at molecular genetics
and life, these are machines, right?

14
00:00:56,859 --> 00:00:59,739
There is the DNA that stores
our genetic code, right?

15
00:00:59,739 --> 00:01:03,300
And there's transcription
of the DNA into messenger RNA

16
00:01:03,300 --> 00:01:08,815
to transport our relevant genetic
information out of the cell's core

17
00:01:09,275 --> 00:01:15,527
to a place where the messenger RNA
can be turned into a protein, right?

18
00:01:15,957 --> 00:01:20,397
So that RNA travels to this factory,
protein factory, the ribosomes

19
00:01:20,397 --> 00:01:23,400
which are themselves
collections of proteins, right?

20
00:01:23,400 --> 00:01:27,449
And there, the mRNAs
turn the copy it onto a protein.

21
00:01:27,449 --> 00:01:29,500
And these proteins
that you produce that way

22
00:01:29,500 --> 00:01:31,425
are responsible
for all the mechanisms in life

23
00:01:31,425 --> 00:01:36,123
including protein construction
and transcription and copying

24
00:01:36,123 --> 00:01:37,509
and preserving the DNA.

25
00:01:37,509 --> 00:01:39,657
This becomes
a self-perpetuating machine.

26
00:01:39,657 --> 00:01:43,016
And that's a machine in addition
to the genetic code, of course, right?

27
00:01:43,016 --> 00:01:45,713
And it's computation,
it's biological computation here.

28
00:01:45,713 --> 00:01:48,049
So this is not coming
as a great surprise to us.

29
00:01:48,049 --> 00:01:50,292
In computer science
we're actually used to this.

30
00:01:50,292 --> 00:01:53,534
And you've probably heard
of self-replicating programs.

31
00:01:53,534 --> 00:01:55,232
Let's take an example in English first.

32
00:01:55,232 --> 00:01:59,084
Look at this: Write two copies of the 
following sentence the second in quotes.

33
00:01:59,084 --> 00:02:00,359
And then in quotes,
"Write two copies

34
00:02:00,359 --> 00:02:02,421
of the following sentences,
the second in quotes."

35
00:02:02,421 --> 00:02:07,568
If you think of interpret executing this,
you get the program back as an output.

36
00:02:08,208 --> 00:02:11,408
Or similarly, the next line
is such a thing in C.

37
00:02:11,408 --> 00:02:15,299
You get basically a C program
that outputs itself,

38
00:02:16,469 --> 00:02:19,954
not trying to go into a file system
and reading this and so on.

39
00:02:19,954 --> 00:02:21,866
It actually produces itself.

40
00:02:22,806 --> 00:02:27,690
Now there is another term
in the context of theory,

41
00:02:27,690 --> 00:02:31,297
the notion of a universal Turing machine
that really is able to self-integrate

42
00:02:31,297 --> 00:02:35,496
in the sense that a Turing machine
that can execute description as data

43
00:02:35,496 --> 00:02:37,231
on the tape of a Turing machine.

44
00:02:37,231 --> 00:02:40,034
So it's an interpreter for
Turing machine by itself, right?

45
00:02:40,454 --> 00:02:42,101
This is of course an important
notion, right?

46
00:02:42,101 --> 00:02:44,027
Obviously this can be done
because Turing machines

47
00:02:44,027 --> 00:02:45,765
especially in the changeable, let's say C,

48
00:02:45,765 --> 00:02:49,293
where we can write such interpretive
that write themselves, right?

49
00:02:49,293 --> 00:02:51,504
The important thing is that
these Turing machines

50
00:02:51,504 --> 00:02:54,093
that are still universal
can be made very simple.

51
00:02:54,793 --> 00:02:59,966
If you're not consisting of binary tapes
but after I think seven symbols,

52
00:02:59,966 --> 00:03:03,486
different ones, then actually there's
a two-state universal Turing machine,

53
00:03:03,486 --> 00:03:06,301
which is quite crazy to imagine, right?

54
00:03:06,301 --> 00:03:11,480
So you can write that way interpreters
for Turing complete languages as well.

55
00:03:12,810 --> 00:03:15,123
Now it's worth thinking about
self-interpretation

56
00:03:15,123 --> 00:03:17,837
in the context of these paradoxes
that you might have heard about,

57
00:03:17,837 --> 00:03:20,194
like Russell's paradox, right?

58
00:03:20,194 --> 00:03:25,276
It's meant to be a set theory
but the popular description is, you know,

59
00:03:25,276 --> 00:03:30,007
the barber shaves everybody
who doesn't shave himself.

60
00:03:30,007 --> 00:03:32,761
And the question is,
does the barber shave himself?

61
00:03:32,761 --> 00:03:36,015
If you think about this,
this leads to a paradox.

62
00:03:36,875 --> 00:03:39,692
Now there's this famous
undecidability of the halting problem.

63
00:03:39,692 --> 00:03:41,731
I'm sure you have learned about this
in the theory course.

64
00:03:41,951 --> 00:03:43,444
So the halting problem is the question,

65
00:03:43,444 --> 00:03:46,794
given a program,
can we tell whether this program

66
00:03:46,794 --> 00:03:49,313
will terminate in all possible inputs?

67
00:03:50,053 --> 00:03:53,733
Now we can, on these slides,
give you complete proof very simple

68
00:03:53,733 --> 00:03:57,477
by self-interpretation
that shows by contradiction

69
00:03:57,477 --> 00:03:59,110
that the halting problem is undecidable.

70
00:03:59,110 --> 00:04:02,793
There cannot be a program
that decides the halting problem.

71
00:04:03,053 --> 00:04:04,724
So how do you do this?

72
00:04:04,724 --> 00:04:08,710
So let's assume there exists
a procedure "does_halt" function

73
00:04:08,810 --> 00:04:12,320
that takes some code and says,
yes, it holds all inputs or not.

74
00:04:13,600 --> 00:04:16,641
So let's assume
that this procedure exists.

75
00:04:16,641 --> 00:04:19,177
Then let's look at this procedure
I've just written down here,

76
00:04:19,177 --> 00:04:21,425
the two-part paradox,
and what it does is the following.

77
00:04:21,425 --> 00:04:24,205
It takes some piece of code,
it's a string or a file,

78
00:04:25,135 --> 00:04:29,724
and it tests if "does_halt",
this conjectured method

79
00:04:29,724 --> 00:04:34,336
for checking the halting problem,
says yes on that code, then loop forever.

80
00:04:34,336 --> 00:04:36,282
Otherwise, exit.

81
00:04:36,972 --> 00:04:39,724
You can actually do that, right?
This is actually a program.

82
00:04:39,724 --> 00:04:43,362
And on some random code,
it will do something maybe reasonable.

83
00:04:44,292 --> 00:04:47,084
It's not a very useful program
because when it halts,

84
00:04:47,084 --> 00:04:49,480
it gets into the infinite loop,
but whatever.

85
00:04:49,480 --> 00:04:54,765
Think about the case that a code
that it receives is its own code, right?

86
00:04:57,035 --> 00:05:00,746
Well if it's its own code basically,
in that case that the halting problem

87
00:05:00,746 --> 00:05:03,398
says yes, then it doesn't
halt this code, right?

88
00:05:03,718 --> 00:05:05,578
And if it says no, then it halts.

89
00:05:05,578 --> 00:05:07,355
Which is a contradiction, right?

90
00:05:07,355 --> 00:05:10,247
So it means that "does_halt" program
must have been incorrect,

91
00:05:10,497 --> 00:05:11,981
so it cannot exist.

92
00:05:11,981 --> 00:05:14,374
There cannot be a correct solution
for the halting problem.

93
00:05:14,374 --> 00:05:16,863
It's a simple consequence of
even very limited programming languages

94
00:05:16,863 --> 00:05:21,034
being powerful enough that such questions
have become nonsensical, right?

95
00:05:21,034 --> 00:05:24,088
Which is unintuitive at first
because you think it is an actually

96
00:05:24,088 --> 00:05:26,368
reasonable question. 
It's even useful.

97
00:05:26,868 --> 00:05:28,178
That's the halting problem..

98
00:05:28,178 --> 00:05:31,108
You could avoid code that
gets into infinite loops, right?

99
00:05:31,108 --> 00:05:32,908
But no, it doesn't make sense.

100
00:05:32,908 --> 00:05:34,818
And this is self-interpretation, right?

101
00:05:34,818 --> 00:05:36,538
And that was a complete proof actually.

102
00:05:36,538 --> 00:05:39,128
Now the next thing is not about really
self-interpretation

103
00:05:39,128 --> 00:05:42,638
but it's a step to the following slide
which again is, right?

104
00:05:42,638 --> 00:05:45,338
So how about composing translators?
It's compilers, right?

105
00:05:45,351 --> 00:05:46,951
Compilers are obviously functions, right?

106
00:05:46,951 --> 00:05:51,151
They take programs in language A
to programs in language B, right?

107
00:05:52,091 --> 00:05:53,741
And functions can be composed.

108
00:05:53,741 --> 00:05:56,741
So if you've got a compiler
that compiles from A to B language

109
00:05:57,111 --> 00:05:59,001
and a compiler that compiles
from language B to C,

110
00:05:59,001 --> 00:06:02,581
then together composed they give us
a compiler from A to C.

111
00:06:02,581 --> 00:06:04,351
And the same way for interpreters.

112
00:06:04,351 --> 00:06:08,021
You can stack interpreters
and that way get any sequence

113
00:06:09,081 --> 00:06:11,171
and any composition of interpreters.

114
00:06:11,171 --> 00:06:14,641
And of course that is much easier
in a sense then the stacking

115
00:06:14,641 --> 00:06:19,431
of virtual machines that you've heard
about in the virtual machine module

116
00:06:19,621 --> 00:06:23,691
because we can assume that layers
between the interpreters are complete.

117
00:06:23,691 --> 00:06:25,741
And they're completely protected
from each other.

118
00:06:25,741 --> 00:06:31,949
We don't have to worry about deep down
some operation doing something bad.

119
00:06:34,079 --> 00:06:37,909
Now this kind of composition
we can use for bootstrapping compilers.

120
00:06:38,159 --> 00:06:40,429
The hesitation is the following,
the problem is the following,

121
00:06:40,429 --> 00:06:43,029
suppose you've got a new programming
language, let's say Scala.

122
00:06:43,029 --> 00:06:45,969
Nobody has ever written any translator
or interpreter for Scala.

123
00:06:46,209 --> 00:06:47,959
You've just come up with this design.

124
00:06:47,959 --> 00:06:50,959
How do you make a compiler
for it relatively easily?

125
00:06:51,419 --> 00:06:54,569
One thing you could do of course
is you could write that compiler

126
00:06:54,569 --> 00:06:57,689
in machine code but that
sounds like a wasteful effort, right?

127
00:06:58,038 --> 00:07:00,048
What you could do
is you could take some compiler

128
00:07:00,048 --> 00:07:02,768
another high-level language
which via a chain of compilers

129
00:07:02,768 --> 00:07:05,078
where it leads down
all the way to machine code.

130
00:07:05,078 --> 00:07:06,318
For example, a C compiler.

131
00:07:06,318 --> 00:07:09,998
So you could write your compiler
for Scala in C.

132
00:07:10,868 --> 00:07:14,428
Now after a while you might say,

133
00:07:14,428 --> 00:07:18,318
"Well, I want to make better features.
I want to improve the optimizations.

134
00:07:18,318 --> 00:07:20,628
And I want to make this a more
powerful compiler

135
00:07:20,628 --> 00:07:22,748
but I've got a working
compiler written in C."

136
00:07:22,748 --> 00:07:28,398
So what I can do is I can
rewrite that compiler in Scala.

137
00:07:28,648 --> 00:07:30,688
Probably less code and easily
maintainable and so on

138
00:07:30,688 --> 00:07:32,788
because it's more productive.

139
00:07:32,788 --> 00:07:36,698
And then, I can throw away
the source code of the first C compiler.

140
00:07:36,958 --> 00:07:40,697
I can take the Scala to Scala compiler

141
00:07:40,697 --> 00:07:45,056
compile it with that Scala to C compiler

142
00:07:45,056 --> 00:07:46,846
all the way down the machine code.

143
00:07:46,846 --> 00:07:50,036
That way I've got a model
as good as the latest implementation

144
00:07:50,036 --> 00:07:51,506
of the Scala compiler,

145
00:07:51,506 --> 00:07:53,046
Scala compiler to machine code,

146
00:07:53,046 --> 00:07:55,106
and then I can throw away
everything I had

147
00:07:55,106 --> 00:07:57,766
about that Scala to C compiler, right?

148
00:07:57,766 --> 00:08:00,046
And then in the end,
there's only a Scala to Scala compiler.

149
00:08:00,046 --> 00:08:02,126
So nowadays if you look at the Scala
reference compiler,

150
00:08:02,126 --> 00:08:04,176
it's written in Scala
and there's nothing else.

151
00:08:04,374 --> 00:08:08,024
Well, there is still at least one Scala
compiler actually that's compiled, right?

152
00:08:08,024 --> 00:08:10,714
But it can be only a binary, right?

153
00:08:10,714 --> 00:08:12,434
So that's this kind of bootstrapping.

154
00:08:12,434 --> 00:08:15,524
At some point, you know, nowadays
that's a good practice,

155
00:08:15,524 --> 00:08:18,384
to write a compiler for a language
in the language itself.

156
00:08:20,034 --> 00:08:21,834
It might be particularly natural.

157
00:08:23,728 --> 00:08:26,708
So how, if you've got a completely
new architecture, new CPU

158
00:08:26,708 --> 00:08:29,198
or a new whatever, piece of hardware,

159
00:08:29,198 --> 00:08:31,888
how do we make a good compiler,
code generator, for it?

160
00:08:31,888 --> 00:08:34,111
But probably you don't know the start
writing everything including

161
00:08:34,111 --> 00:08:36,774
the operating system and tools
and so on from scratch

162
00:08:36,774 --> 00:08:38,838
in machine code for this architecture.
It's not necessary.

163
00:08:38,838 --> 00:08:41,248
What you want to do
is take an existing compiler

164
00:08:41,248 --> 00:08:42,568
on a different architecture

165
00:08:42,568 --> 00:08:45,958
and just write the code generated
packet data that emits machine code.

166
00:08:45,958 --> 00:08:49,208
It's just the last piece at the lowest
level of that compiler.

167
00:08:49,208 --> 00:08:51,688
So you can cross-compile.
Then you've got to compile in the machine.

168
00:08:51,688 --> 00:08:53,718
You can also cross-compile
an operating system

169
00:08:53,718 --> 00:08:56,008
and adaptions and so on, adaptations.

170
00:08:56,633 --> 00:09:00,363
And once you have it on that
machine running, you're independent.

171
00:09:00,595 --> 00:09:04,595
You want to write, you're done.
Alright.

172
00:09:05,471 --> 00:09:10,231
And more crazy than that,
let's just think that the reference

173
00:09:10,231 --> 00:09:13,001
Scala compiler, that compiles
Scala to Scala,

174
00:09:13,502 --> 00:09:17,362
by repeatedly compiling itself
and not changing any code,

175
00:09:17,362 --> 00:09:20,012
not improving any codes,
we can make that compiler better.

176
00:09:20,012 --> 00:09:22,802
Particularly if it has strong 
optimizations. How could that be, right?

177
00:09:22,802 --> 00:09:25,172
Just imagine you've got an optimization
that actually is very expensive

178
00:09:25,172 --> 00:09:28,432
and it takes long, if it does more 
number crunching it produces better code.

179
00:09:29,372 --> 00:09:32,392
The better code might be faster
as well, right?

180
00:09:32,392 --> 00:09:35,782
So you spend some time
letting the compiler compile itself.

181
00:09:36,623 --> 00:09:40,873
You get the compiler, but it's still 
based on the same source code.

182
00:09:40,943 --> 00:09:43,983
But by having this number
crunching for optimization

183
00:09:43,983 --> 00:09:46,743
the compiler is faster
and can the next time it compiles itself

184
00:09:47,113 --> 00:09:49,733
it gets more quickly
to even better compilation.

185
00:09:50,496 --> 00:09:54,246
So you iterate this process.
You don't touch the code at all, right?

186
00:09:54,336 --> 00:09:56,406
And the compiler improves itself.
So that's a possibility.

187
00:09:56,406 --> 00:09:57,646
It's an extreme case.

188
00:09:57,646 --> 00:10:00,706
You cannot expect it normally
but it's possible.
