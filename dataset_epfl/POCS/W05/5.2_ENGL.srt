1
00:00:05,511 --> 00:00:08,351
We've defined the gold standard
for the semantics of transactions

2
00:00:08,351 --> 00:00:10,299
to be serializability.

3
00:00:10,299 --> 00:00:13,955
That means given
a schedule of transactions,

4
00:00:15,076 --> 00:00:18,313
if you can say, and show,
and understand

5
00:00:18,313 --> 00:00:23,011
that this schedule is equivalent
to a serial execution of the transactions,

6
00:00:23,011 --> 00:00:26,239
where transactions
don't execute concurrently,

7
00:00:26,239 --> 00:00:28,226
but one after the other, completely,

8
00:00:28,226 --> 00:00:31,600
then such transactions are called
serializable--that's what we desire.

9
00:00:32,119 --> 00:00:36,180
Now, in this video, we're going to talk
about one family of techniques,

10
00:00:36,180 --> 00:00:39,077
based on locking,
for achieving serializability.

11
00:00:40,248 --> 00:00:43,411
Specifically, we're going to now introduce

12
00:00:43,411 --> 00:00:46,139
the notion of <i>conflict serializability</i>.

13
00:00:46,139 --> 00:00:48,035
That's a special case of serializability.

14
00:00:48,035 --> 00:00:50,583
Whenever a schedule
is conflict serializable,

15
00:00:50,583 --> 00:00:53,973
it's also serializable,
but not necessarily vice versa.

16
00:00:54,848 --> 00:00:58,861
So two schedules are conflict equivalent

17
00:00:58,861 --> 00:01:01,825
if they invoke the same actions
of the same transactions,

18
00:01:01,825 --> 00:01:06,140
and every pair of conflicting actions
is ordered in the same way.

19
00:01:07,174 --> 00:01:09,809
We're going to see by example
what that means, exactly.

20
00:01:09,809 --> 00:01:13,551
We can actually formalize this via
the notion of the dependency graphs.

21
00:01:13,961 --> 00:01:18,360
In any case, conflict equivalence
implies equivalence.

22
00:01:18,360 --> 00:01:21,254
It's a special case, I would say
a stronger condition.

23
00:01:21,254 --> 00:01:26,281
And if a schedule is conflict equivalent
to a serial schedule,

24
00:01:26,281 --> 00:01:28,209
then we call it <i>conflict serializable</i>.

25
00:01:28,758 --> 00:01:33,779
So just like serializability
means that a schedule

26
00:01:33,779 --> 00:01:38,414
is equivalent to a serial schedule,
<i>conflict serializability</i> means

27
00:01:38,414 --> 00:01:41,156
it's conflict equivalent
to a serial schedule.

28
00:01:42,027 --> 00:01:45,814
Now, how do we decide when
a schedule is conflict equivalent?

29
00:01:46,034 --> 00:01:47,300
Let's look at this example.

30
00:01:47,300 --> 00:01:51,208
There's two transactions, again,
shown by this timeline.

31
00:01:51,208 --> 00:01:53,519
And we can build a dependency graph

32
00:01:53,519 --> 00:01:57,291
where each node, or each transaction
has a node for itself,

33
00:01:57,641 --> 00:02:01,145
and the enter edge from
one transaction to another transaction.

34
00:02:01,635 --> 00:02:06,249
If there is a dependency
in the schedule of the following form

35
00:02:06,249 --> 00:02:10,503
that either one transaction
writes one particular object

36
00:02:10,503 --> 00:02:13,039
that another transaction afterwards reads,

37
00:02:13,039 --> 00:02:15,607
that means a write-read
conflict so to say,

38
00:02:15,607 --> 00:02:18,291
that would mean for that object
you might get an error

39
00:02:18,291 --> 00:02:20,966
from the writing transaction
to the reading transaction.

40
00:02:21,223 --> 00:02:24,843
Also, if one transaction first reads,
and the other one afterwards writes,

41
00:02:24,843 --> 00:02:26,515
we've got a read-write conflict,

42
00:02:26,515 --> 00:02:29,804
and you would make a dependency edge
in the dependency graph.

43
00:02:29,804 --> 00:02:31,878
And similarly, if you've got
a write-write conflict.

44
00:02:32,473 --> 00:02:34,118
There are three kinds of anomalies.

45
00:02:34,667 --> 00:02:36,286
If one transaction first writes,

46
00:02:36,286 --> 00:02:38,816
and the other one afterwards
reads the same object again,

47
00:02:38,816 --> 00:02:41,705
then we will enter an edge
from the first to the second transaction.

48
00:02:42,541 --> 00:02:44,388
We will also usually label these edges

49
00:02:44,388 --> 00:02:47,698
with the kind of object
that was the culprit, so to say,

50
00:02:47,698 --> 00:02:49,625
which was responsible
for the dependency.

51
00:02:50,725 --> 00:02:52,836
Remember, there is no read-read conflicts.

52
00:02:52,836 --> 00:02:56,024
If all transactions only read, there's
no change to the database, in a sense,

53
00:02:56,024 --> 00:02:59,795
then we don't have to worry about
concurrency and about changes,

54
00:02:59,795 --> 00:03:02,412
because there are no changes,
and nothing bad can happen.

55
00:03:02,412 --> 00:03:04,746
Everybody will read
the same version of the database,

56
00:03:04,746 --> 00:03:06,990
and nothing's getting changed,
and everything is safe.

57
00:03:07,097 --> 00:03:09,482
So we have write-read, read-write,

58
00:03:09,482 --> 00:03:11,033
and write-write conflicts.

59
00:03:11,532 --> 00:03:14,419
Now, we built this
dependency graph that way.

60
00:03:14,419 --> 00:03:19,388
In this example we've got an edge
from T1 to T2 labeled A,

61
00:03:19,388 --> 00:03:23,353
because T1 first writes A,
and T2 afterwards reads A.

62
00:03:23,577 --> 00:03:26,450
And we've got an edge
from T2 to T1 labeled B,

63
00:03:26,450 --> 00:03:30,279
because T2 first writes B,
and then T1 reads B.

64
00:03:30,665 --> 00:03:32,944
You can see that there's
a cycle in this dependency graph,

65
00:03:32,944 --> 00:03:35,779
and that cycle evidences the problem.

66
00:03:36,424 --> 00:03:39,837
The edge from T1 to T2, labeled A,

67
00:03:40,607 --> 00:03:44,147
shows that there is a write-read
conflict between T1 and T2,

68
00:03:44,147 --> 00:03:49,171
and to make this serializable
you would really need a serialization

69
00:03:49,171 --> 00:03:52,033
where T1 is actually going to be for T2,

70
00:03:52,033 --> 00:03:54,605
and vice versa: the edge from T2 to T1

71
00:03:55,344 --> 00:03:57,875
says that basically,
to make this serializable,

72
00:03:57,875 --> 00:04:01,463
we would have to show that
it's equivalent to serial schedule

73
00:04:01,463 --> 00:04:04,201
where T2 is completely executed before T1.

74
00:04:04,201 --> 00:04:07,128
So there is this kind of mutual conflict:
T1 has to be before T2,

75
00:04:07,128 --> 00:04:09,049
and T2 has to be before T1,

76
00:04:09,049 --> 00:04:10,641
and that's of course not both possible.

77
00:04:10,641 --> 00:04:13,079
That means whenever we've got
a cycle in this dependency graph

78
00:04:13,841 --> 00:04:16,995
then it is not conflict serializable,
and thus also not,

79
00:04:18,995 --> 00:04:20,775
in general, not serializable.

80
00:04:21,146 --> 00:04:22,502
So let me repeat:

81
00:04:22,827 --> 00:04:25,412
we can construct
a dependency graph as follows.

82
00:04:25,412 --> 00:04:27,237
There is one node for each transaction,

83
00:04:27,237 --> 00:04:30,423
and there is an edge from the first
to the second transaction,

84
00:04:30,423 --> 00:04:35,850
but the second transaction never depends
on the first by a particular object--

85
00:04:35,850 --> 00:04:38,510
and depends means there's either
write-read, a read-write,

86
00:04:38,510 --> 00:04:40,086
or a write-write conflict.

87
00:04:40,405 --> 00:04:44,603
And this dependency graph
completely determines, via cyclicity,

88
00:04:44,603 --> 00:04:47,750
whether a schedule
is conflict serializable.

89
00:04:47,750 --> 00:04:50,557
That means a schedule
is conflict serializable

90
00:04:50,557 --> 00:04:53,503
if an only if its dependency
graph is acyclic.

91
00:04:56,739 --> 00:04:59,106
Now there is a nice general technique

92
00:04:59,106 --> 00:05:02,444
for determining conflict serializability,

93
00:05:02,444 --> 00:05:05,742
or to actually guaranteeing
serializable schedules

94
00:05:06,334 --> 00:05:09,710
that are also conflict serializable,
using locking.

95
00:05:11,293 --> 00:05:14,651
For that I'll introduce you to
the <i>Two-Phase Locking Protocol</i>.

96
00:05:15,576 --> 00:05:17,224
It works as follows--

97
00:05:17,350 --> 00:05:20,121
Each transaction must obtain a read lock,

98
00:05:20,121 --> 00:05:23,012
or so-called <i>shared</i> lock
on an object before it can read,

99
00:05:23,203 --> 00:05:27,007
and then an <i>exclusive</i>, or write lock
on an object before it can write.

100
00:05:27,471 --> 00:05:30,593
So the read lock is called <i>shared lock</i>

101
00:05:30,593 --> 00:05:33,399
because if one transaction
has a read lock,

102
00:05:33,399 --> 00:05:36,764
then a second transaction
can also get a read lock,

103
00:05:36,764 --> 00:05:40,051
but if anybody has a read lock,
then nobody can get a write lock.

104
00:05:40,051 --> 00:05:43,035
And if somebody gets a write lock
on something that is purposely unlocked,

105
00:05:43,035 --> 00:05:46,935
an <i>exclusive lock</i>, it's exclusive,
and nobody else can read or write.

106
00:05:48,060 --> 00:05:51,329
So these kinds of locks
basically will guarantee us

107
00:05:51,329 --> 00:05:56,602
to avoid these write-write, read-write,
and write-read conflicts.

108
00:05:57,350 --> 00:06:01,595
And the notion of shared lock
basically enables us

109
00:06:01,595 --> 00:06:04,864
to have concurrent reads,
which are by themselves innocuous.

110
00:06:06,100 --> 00:06:09,879
A transaction will have
a certain kind of lock grow phase,

111
00:06:09,879 --> 00:06:12,237
where initially it can get
more and more locks,

112
00:06:12,928 --> 00:06:16,190
up to a point where it decides
to do some more work,

113
00:06:16,190 --> 00:06:17,819
and then maybe starts releasing locks,

114
00:06:17,819 --> 00:06:19,659
but once it has released a single lock

115
00:06:19,659 --> 00:06:22,072
it cannot get another lock.

116
00:06:22,490 --> 00:06:25,221
For that reason you've got
so-called <i>two-phases</i>,

117
00:06:25,221 --> 00:06:29,046
a first growth phase, where we only
monotonously add more locks,

118
00:06:29,046 --> 00:06:30,844
but not remove any,

119
00:06:30,844 --> 00:06:33,954
and later a release phase,
where we can only release locks,

120
00:06:33,954 --> 00:06:35,790
but cannot get any further locks.

121
00:06:37,062 --> 00:06:40,275
The <i>Two-Phase Locking Protocol</i>
is also abbreviated by 2PL,

122
00:06:40,275 --> 00:06:42,222
we sometimes call it just 2PL.

123
00:06:42,222 --> 00:06:46,204
There's an important modified version
of the <i>Two-Phase Locking Protocol</i>

124
00:06:46,204 --> 00:06:48,444
called a <i>Strict Two-Phase
Locking Protocol</i>,

125
00:06:48,444 --> 00:06:52,634
that works like 2PL, but in addition,
there's an additional constraint

126
00:06:52,634 --> 00:06:56,336
that says that all locks
held by a transaction

127
00:06:56,336 --> 00:07:00,108
are released all together at the time
the transaction completes.

128
00:07:00,108 --> 00:07:02,475
That means the second phase,

129
00:07:02,475 --> 00:07:05,880
of the release phase of
the <i>Two-Phase Locking Protocol</i>,

130
00:07:05,880 --> 00:07:08,457
happens all of a sudden, at once.

131
00:07:08,457 --> 00:07:11,782
So in a sense you don't need
a specific free-lock command,

132
00:07:11,782 --> 00:07:15,394
but you can allocate more locks,
more locks, more locks,

133
00:07:15,394 --> 00:07:18,293
you can do work, and at the point
you commit or abort,

134
00:07:18,293 --> 00:07:20,269
all locks are automatically released.

135
00:07:20,269 --> 00:07:21,963
And you don't do this by hand,

136
00:07:21,963 --> 00:07:24,613
all of them are released
at the same point in time.

137
00:07:26,113 --> 00:07:29,268
Now already the first protocol,
the 2PL protocol,

138
00:07:29,689 --> 00:07:32,985
allows only schedules whose
precedence graph,

139
00:07:32,985 --> 00:07:34,629
the dependency graph, is acyclic.

140
00:07:34,629 --> 00:07:37,151
That means they're conflict
serializable and thus serializable.

141
00:07:37,151 --> 00:07:40,004
So this locking protocol
guarantees serializability,

142
00:07:40,325 --> 00:07:42,213
which is what we want, after all.

143
00:07:43,669 --> 00:07:46,327
There is a reason for having
the strict two-phase locking protocol,

144
00:07:46,603 --> 00:07:49,291
and that's it simplifies
transaction aborts.

145
00:07:49,291 --> 00:07:52,016
So remember this notion
of cascading aborts.

146
00:07:53,330 --> 00:07:57,086
If I have just two-phase locking,
not strict two-phase locking,

147
00:07:57,086 --> 00:08:00,233
I might start releasing some locks
before I'm committing,

148
00:08:00,233 --> 00:08:02,847
maybe long before I'm committing,
and during this time--

149
00:08:02,847 --> 00:08:05,740
from the time I release my first lock
to the time I commit,

150
00:08:05,740 --> 00:08:09,251
another transaction might
obtain that lock on this object,

151
00:08:09,541 --> 00:08:13,348
and it might start, for example,
reading a value that I've already written.

152
00:08:13,611 --> 00:08:14,965
So if I'm late to abort,

153
00:08:15,685 --> 00:08:18,768
I would cause and force
the second transaction--

154
00:08:18,768 --> 00:08:21,640
it hasn't read my value,
because I released the lock--

155
00:08:21,640 --> 00:08:24,234
also to abort, so I can cause
cascading aborts.

156
00:08:24,529 --> 00:08:26,640
On the other hand,
in strict two-phase locking,

157
00:08:26,640 --> 00:08:28,395
there is no need for cascading aborts,

158
00:08:28,951 --> 00:08:31,832
so handling aborts is much easier.

159
00:08:33,169 --> 00:08:35,151
There is one thing to mention, though,

160
00:08:35,151 --> 00:08:38,062
that in both cases,
even for strict two-phase locking,

161
00:08:38,062 --> 00:08:40,137
but also for classical two-phase locking,

162
00:08:40,137 --> 00:08:41,764
bad locks are possible,

163
00:08:41,764 --> 00:08:44,977
because the growth phase,
where we allocate locks,

164
00:08:45,311 --> 00:08:48,470
is not happening atomically,
at one point in time

165
00:08:48,470 --> 00:08:50,682
like the release phase is
in strict two-phase locking.

166
00:08:50,682 --> 00:08:53,384
That means, for example,
I might have two transactions,

167
00:08:54,417 --> 00:08:57,585
where both try to allocate
two resources, A and B,

168
00:08:57,585 --> 00:08:59,467
but the first transaction
allocates A first,

169
00:08:59,467 --> 00:09:00,947
and then tries to allocate B,

170
00:09:00,947 --> 00:09:04,878
and the second tries to allocate B first,
and then tries to allocate A.

171
00:09:04,878 --> 00:09:09,390
So it could happen that both transactions
each have one object,

172
00:09:09,390 --> 00:09:13,374
and try to wait for the other object,
which cannot be released

173
00:09:13,374 --> 00:09:15,898
because these two transactions
wait individually for each other.

174
00:09:15,898 --> 00:09:19,501
That means I've got kind of
the dining philosopher's problem here,

175
00:09:19,501 --> 00:09:21,013
and I get a deadlock.

176
00:09:21,013 --> 00:09:23,556
So we have to deal
with deadlocks separately,

177
00:09:23,556 --> 00:09:25,842
and neither of these
two protocols avoids them.

178
00:09:29,352 --> 00:09:31,943
There is basically two
important ways of doing this.

179
00:09:32,536 --> 00:09:35,725
One is deadline detection,
the other one is deadlock prevention.

180
00:09:36,641 --> 00:09:40,747
Deadlock detection, I can basically obtain
by yet another dependency graph.

181
00:09:40,747 --> 00:09:45,018
So what I'm going to do is basically
I'm going to have, again,

182
00:09:45,018 --> 00:09:47,339
a dependency graph with
the nodes and transactions,

183
00:09:47,339 --> 00:09:50,457
and I'm going to have an edge
whenever one transaction

184
00:09:50,457 --> 00:09:54,422
waits for an object that another
transaction already has allocated.

185
00:09:54,422 --> 00:09:58,921
That means I'm going to draw an edge
from transaction T1 to transaction T2,

186
00:09:58,921 --> 00:10:01,499
if T2 owns an object,
has a lock-in object,

187
00:10:01,499 --> 00:10:03,532
that T1 also wants.

188
00:10:03,832 --> 00:10:06,319
So I can put again a label on it,
for this object,

189
00:10:06,319 --> 00:10:08,913
and that means basically
T1 will be blocked

190
00:10:08,913 --> 00:10:10,817
until T2 releases this lock.

191
00:10:11,010 --> 00:10:14,469
And of course, if I get a cycling,
only if I get a cycling in this graph,

192
00:10:14,469 --> 00:10:15,774
I've got a deadlock.

193
00:10:16,279 --> 00:10:20,677
So I can easily, while I lock,
create this dependency graph,

194
00:10:20,677 --> 00:10:23,690
and then I get a cycle, I know
I have to do something about this.

195
00:10:23,690 --> 00:10:25,772
What can I do?
Well, I could kill a transaction.

196
00:10:26,231 --> 00:10:28,365
The idea is simple,
but let's look at an example.

197
00:10:28,941 --> 00:10:31,350
This actually is slightly a big example,

198
00:10:31,350 --> 00:10:34,473
illustrates maybe some other ideas,
as well, that we've discussed so far.

199
00:10:35,121 --> 00:10:37,239
So we've got four transactions here,

200
00:10:37,239 --> 00:10:39,627
and what you see is, again,
the read and write commands,

201
00:10:39,627 --> 00:10:43,633
but now we've also explicitly
denoted locking commands.

202
00:10:43,633 --> 00:10:46,163
There is the S of A, for example, in T1,

203
00:10:46,163 --> 00:10:48,393
that actually creates a shared lock on A.

204
00:10:48,393 --> 00:10:51,523
And the X of B in T2 creates
an exclusive lock on B.

205
00:10:51,918 --> 00:10:53,963
Of course we have to assume
that these are possible,

206
00:10:53,963 --> 00:10:55,537
otherwise they would not be executed,

207
00:10:55,537 --> 00:10:57,403
or the transaction would have to fail.

208
00:10:57,403 --> 00:11:01,553
So we see that we are creating
a shared lock for A, reading A in T1,

209
00:11:01,553 --> 00:11:04,255
then we create an exclusive lock
for B to write,

210
00:11:04,255 --> 00:11:06,731
and write, actually, in T2, for B.

211
00:11:06,731 --> 00:11:11,228
Then we are going to shared lock
for C, in T3, and read C,

212
00:11:11,678 --> 00:11:15,983
and next I will need to try to get
an exclusive lock on C in T2,

213
00:11:15,983 --> 00:11:17,696
that means we plan to write.

214
00:11:18,406 --> 00:11:22,624
Then we're going to try to get
an exclusive lock for B in T4,

215
00:11:23,117 --> 00:11:25,766
and, finally, an exclusive
lock for A in T3.

216
00:11:26,041 --> 00:11:29,255
So the dependency graph,
I'll show it to you first,

217
00:11:29,255 --> 00:11:32,762
before we do this final operation
of getting exclusivity lock on A.

218
00:11:32,762 --> 00:11:34,696
And what you see
is we'll have three edges.

219
00:11:34,696 --> 00:11:36,613
There is an edge from T1 to T2,

220
00:11:36,973 --> 00:11:42,186
because at the time we created
a shared lock for B in T1,

221
00:11:42,186 --> 00:11:44,777
there was already an exclusive lock for B.

222
00:11:44,777 --> 00:11:46,974
That means T1 would have to wait for T2.

223
00:11:46,974 --> 00:11:48,706
So we make an arrow from T1 to T2,

224
00:11:48,706 --> 00:11:51,276
because T1 has to wait for T2,
because of B,

225
00:11:51,276 --> 00:11:53,477
it wants a lock at B,
but it cannot get it,

226
00:11:53,477 --> 00:11:56,708
because right now T2 has a lock on B.

227
00:11:56,708 --> 00:11:58,716
So T1 is right now blocked, basically,

228
00:11:58,716 --> 00:12:03,482
until T2 releases the lock.

229
00:12:03,932 --> 00:12:06,818
Now we also have an edge from T2 to T3,

230
00:12:06,818 --> 00:12:09,479
because T2 tries to get
an exclusive lock on C

231
00:12:09,479 --> 00:12:11,608
while T3 already has a shared lock on C.

232
00:12:11,608 --> 00:12:14,386
That means T2 now gets blocked

233
00:12:14,386 --> 00:12:17,667
until T3 releases the lock on C.

234
00:12:18,552 --> 00:12:22,005
And then, in transaction T4
we tried to get an exclusive lock on B,

235
00:12:22,005 --> 00:12:25,734
but T2 already has a lock on B,
actually an exclusive lock,

236
00:12:25,734 --> 00:12:28,518
that means T4 is not blocked,
and waits for T2.

237
00:12:28,662 --> 00:12:31,790
We have not reached a deadlock yet,
because T3 can still execute.

238
00:12:32,167 --> 00:12:34,600
But now let's execute
this final operation,

239
00:12:34,955 --> 00:12:37,612
trying to obtain
an exclusive lock on A in T3.

240
00:12:37,842 --> 00:12:41,522
This will now make T3 wait for T1,

241
00:12:41,726 --> 00:12:44,275
because T1 has a lock on A,

242
00:12:44,851 --> 00:12:47,684
which means now that we've got
a cycle in the dependency graph:

243
00:12:47,684 --> 00:12:50,832
T3 waits for T1, T1 waits for T2,
and T2 waits for T3,

244
00:12:50,832 --> 00:12:53,819
and that's a deadlock,
so we have to do something.

245
00:12:53,819 --> 00:12:56,638
We'll have to kill a transaction
to be able to continue.

246
00:12:59,909 --> 00:13:04,479
There is also the possibility of avoiding
deadlocks, preventing deadlocks,

247
00:13:04,479 --> 00:13:06,911
by using timestamps on transactions.

248
00:13:07,145 --> 00:13:10,315
That means we could create,
at a time any transaction starts,

249
00:13:10,315 --> 00:13:12,937
a timestamp, a start timestamp
for the transaction,

250
00:13:12,937 --> 00:13:15,509
recording when it starts,
how old the transaction is,

251
00:13:15,509 --> 00:13:18,500
and then essentially using this timestamp

252
00:13:19,500 --> 00:13:21,766
to bring a greater notion
of fairness to transactions,

253
00:13:21,766 --> 00:13:23,114
to avoid starvation.

254
00:13:23,464 --> 00:13:26,509
A transaction that is older
might have higher priority than others,

255
00:13:26,509 --> 00:13:28,726
and a transaction that is older
might get priority

256
00:13:28,726 --> 00:13:33,207
to continue and finish
over other transactions.

257
00:13:33,597 --> 00:13:34,986
There might be several strategies

258
00:13:34,986 --> 00:13:37,327
that we could now enforce
to deal with this.

259
00:13:37,619 --> 00:13:40,213
So let's assume that we've got
timestamps for each transaction,

260
00:13:40,766 --> 00:13:43,557
noting down essentially the time,
logical or physical,

261
00:13:43,557 --> 00:13:45,360
when the transaction started.

262
00:13:45,360 --> 00:13:48,565
And this totally old transactions, 
let's assume that.

263
00:13:49,153 --> 00:13:54,010
First priority will be that
if Ti, transaction Ti,

264
00:13:54,010 --> 00:13:55,919
has a higher priority, is maybe older,

265
00:13:55,919 --> 00:13:59,227
then Ti will wait for Tj,
if Tj has a lock.

266
00:13:59,944 --> 00:14:01,524
Otherwise, Ti would abort.

267
00:14:01,524 --> 00:14:03,887
That means a high priority,
an older transaction,

268
00:14:03,887 --> 00:14:06,178
will wait to get a lock,

269
00:14:06,178 --> 00:14:08,415
while if a new transaction
tries to obtain a lock

270
00:14:08,415 --> 00:14:10,305
that an older transaction already has,

271
00:14:10,305 --> 00:14:13,514
it will get killed, so there will be
no blocking for that reason.

272
00:14:14,443 --> 00:14:19,123
So that way, at some point
old transactions get really executed,

273
00:14:19,123 --> 00:14:21,572
and don't get killed all the time
that a new transaction comes

274
00:14:21,572 --> 00:14:23,342
and wants something from them.

275
00:14:24,105 --> 00:14:26,021
The alternative would be
the second strategy,

276
00:14:26,021 --> 00:14:29,885
where if Ti has a higher priority,
then Tj aborts,

277
00:14:30,668 --> 00:14:32,391
and otherwise Ti waits.

278
00:14:32,969 --> 00:14:36,074
So that means sometimes
we start transactions, they have to--

279
00:14:36,074 --> 00:14:38,161
again, from scratch--
continue doing everything

280
00:14:38,161 --> 00:14:40,999
as they did before,
in the same order, basically,

281
00:14:40,999 --> 00:14:44,163
as they've executed so far,
and just the order in which

282
00:14:44,163 --> 00:14:47,026
locks are trying
to be obtained is different,

283
00:14:47,026 --> 00:14:49,286
and ultimately,
everybody gets their turn,

284
00:14:49,286 --> 00:14:51,897
and the highest priority
transactions, so to say,

285
00:14:52,802 --> 00:14:56,710
are sure to ultimately finish and succeed.

286
00:14:57,896 --> 00:14:59,317
Now here's a problem.

287
00:14:59,964 --> 00:15:03,338
If we relax the assumption
that the database is just static,

288
00:15:03,338 --> 00:15:05,774
and a fixed collection of objects
that never change,

289
00:15:05,774 --> 00:15:08,352
then two-phase locking,
even strict two-phase locking

290
00:15:08,352 --> 00:15:11,703
do not ensure serializability.

291
00:15:12,081 --> 00:15:16,245
So if you allow to insert new items,
or delete items,

292
00:15:16,245 --> 00:15:18,317
then we are getting into trouble.

293
00:15:18,317 --> 00:15:20,445
And to illustrate this,
here's an example.

294
00:15:20,445 --> 00:15:22,604
Let's look at the schedule
at the bottom of this slide.

295
00:15:22,604 --> 00:15:25,408
First, let's ignore
these little stars and primes.

296
00:15:26,165 --> 00:15:28,824
So in that sense
it's a classical schedule.

297
00:15:29,279 --> 00:15:33,211
Think of this I of A and D of B, which
are going to be insertions and deletions,

298
00:15:33,211 --> 00:15:35,916
just as writes, for now.
So what happens?

299
00:15:35,916 --> 00:15:40,188
We are trying to get a shared read lock
and read A, in transaction T1,

300
00:15:40,188 --> 00:15:42,932
then I'm trying to write A and write B.

301
00:15:42,932 --> 00:15:47,195
And then, again, we want to read B in T1,

302
00:15:47,195 --> 00:15:49,728
and, finally, write C in T1.

303
00:15:51,108 --> 00:15:54,868
We have a read-write
dependency from T1 to T2,

304
00:15:54,868 --> 00:15:57,898
and a write-read dependency
from T2 to T1.

305
00:15:58,976 --> 00:16:00,976
And I just added this write C in T1

306
00:16:00,976 --> 00:16:03,557
to make it not a completely
read-only transaction.

307
00:16:03,838 --> 00:16:08,276
Well, obviously that's one of these
classical and nested scenarios,

308
00:16:08,276 --> 00:16:11,917
where there is no serial schedule
that's equivalent.

309
00:16:11,917 --> 00:16:16,393
We cannot move T2 first, because of
that read-write dependency on A,

310
00:16:16,393 --> 00:16:22,152
and we cannot move T1 first, because of
that write-read dependency on B.

311
00:16:22,812 --> 00:16:26,957
So this is obviously not conflict
serializable, and thus not serializable.

312
00:16:26,957 --> 00:16:28,886
We will detect this using locking.

313
00:16:28,886 --> 00:16:32,173
But now what happens if we are not
doing any more writes in T2,

314
00:16:32,173 --> 00:16:34,272
but we're actually doing
insertions and deletions?

315
00:16:34,939 --> 00:16:36,913
Now here's the example.

316
00:16:36,913 --> 00:16:39,214
In this example I use a database schema

317
00:16:39,214 --> 00:16:43,259
where we've got the database
of a sailing club,

318
00:16:43,259 --> 00:16:47,032
and in this database we have
records for each sailor in the club,

319
00:16:47,032 --> 00:16:51,317
and each sailor has an age,
among the things that are stored of him,

320
00:16:51,317 --> 00:16:54,709
and the rating--how good a sailor he is,
or something like that.

321
00:16:55,308 --> 00:16:57,782
So now let's try to do
the following thing.

322
00:16:57,782 --> 00:17:01,539
T1 tries to lock all the pages
containing sailor records

323
00:17:02,382 --> 00:17:04,253
with a shared lock, a read lock,

324
00:17:04,253 --> 00:17:06,496
just to find the oldest
sailor of rating = 1.

325
00:17:07,153 --> 00:17:11,832
So what I'm doing is basically with
this A* in my schedule below

326
00:17:11,832 --> 00:17:14,642
is I'm trying to lock all the A records,
the A records being

327
00:17:14,642 --> 00:17:16,878
the sailors with rating = 1.

328
00:17:16,878 --> 00:17:18,928
I do this just to be able
to read them, to find out

329
00:17:18,928 --> 00:17:21,862
who's the oldest sailor
among those with rating = 1.

330
00:17:22,453 --> 00:17:26,195
Next, we're going to insert
a new sailor of rating = 1,

331
00:17:26,195 --> 00:17:28,614
an even older one, in T2.

332
00:17:28,614 --> 00:17:30,693
So this sailor should have been the winner

333
00:17:30,693 --> 00:17:33,339
if T2 had happened before T1.

334
00:17:33,339 --> 00:17:38,882
But since T1 happens before T2, initially,
we'll not find this oldest sailor,

335
00:17:38,882 --> 00:17:40,797
we find only the second-oldest sailor,

336
00:17:40,797 --> 00:17:44,054
the oldest sailor that was already
in the database before this new insert.

337
00:17:44,404 --> 00:17:48,292
The next step is that T2 also tries
to delete the oldest sailor of rating = 2,

338
00:17:49,260 --> 00:17:52,496
and we call this oldest sailor
of rating = 2 "B".

339
00:17:53,483 --> 00:17:58,011
After that T1 tries to lock
all the pages, all the B pages,

340
00:17:58,011 --> 00:18:01,628
all the pages that are rating = 2,
and find the oldest sailor.

341
00:18:01,628 --> 00:18:04,197
Well, you'll find only
the second-oldest sailor,

342
00:18:04,197 --> 00:18:07,342
because the oldest sailor of rating = 2
has just been deleted.

343
00:18:07,729 --> 00:18:08,951
So we have these dependencies,

344
00:18:08,951 --> 00:18:10,886
just like we have classical
read-write conflicts,

345
00:18:10,886 --> 00:18:14,005
although there are no objects
appearing/disappearing.

346
00:18:14,717 --> 00:18:16,908
So that's a problem, because we cannot

347
00:18:16,908 --> 00:18:20,015
easily modify our technique
so far to deal with this.

348
00:18:24,188 --> 00:18:27,292
There are a number of techniques
to deal with this in database systems,

349
00:18:27,292 --> 00:18:30,604
and I'll just mention them briefly,
the two main techniques.

350
00:18:30,604 --> 00:18:32,099
The first one is <i>index locking</i>.

351
00:18:32,099 --> 00:18:36,792
Just imagine you've got
an index structure over these items,

352
00:18:36,792 --> 00:18:42,505
particularly an index structure
that finds the sailors by rating,

353
00:18:42,505 --> 00:18:46,662
and maybe even sorted
by age within the rating.

354
00:18:47,278 --> 00:18:50,188
And it's a dense index, like a B-tree,

355
00:18:50,418 --> 00:18:55,737
such that it covers
all the values in our database.

356
00:18:56,038 --> 00:19:01,894
So I can, for example,
then lock a node in that tree index,

357
00:19:02,594 --> 00:19:05,742
and if I force my database system
to always access the data

358
00:19:05,742 --> 00:19:08,194
through this index, 
and no other way,

359
00:19:08,194 --> 00:19:09,956
that means if anybody
wants to see the data

360
00:19:09,956 --> 00:19:12,476
they have to search the values
through that index--

361
00:19:13,158 --> 00:19:16,456
locking a node that basically
locks an entire range of values,

362
00:19:17,198 --> 00:19:20,196
maybe all the values that correspond
to that particular rating,

363
00:19:21,150 --> 00:19:27,147
guarantees us
that entire range of ratings,

364
00:19:27,147 --> 00:19:29,148
also future values of that rating,

365
00:19:29,148 --> 00:19:31,665
which would have to be inserted
in this B-tree at this point,

366
00:19:31,665 --> 00:19:33,561
if we would insert them, are locked.

367
00:19:34,334 --> 00:19:39,121
So using an index structure I can
lock a particular predicate, so to say,

368
00:19:39,121 --> 00:19:42,229
and all future tuples
that are not in there yet either.

369
00:19:43,066 --> 00:19:44,985
So that's one way of doing this,

370
00:19:44,985 --> 00:19:47,697
but it of course requires that
there is a suitable index structure,

371
00:19:48,312 --> 00:19:51,483
and that it's used as
the only way to access the data

372
00:19:51,483 --> 00:19:53,055
so that you don't do anything wrong,

373
00:19:53,055 --> 00:19:55,172
because then you're going
to lock the index structure,

374
00:19:55,172 --> 00:19:58,107
or part of the index structure,
right in the data itself.

375
00:20:00,091 --> 00:20:02,019
The alternative would be
<i>predicate locking</i>.

376
00:20:02,019 --> 00:20:04,904
That means basically we're going
to have some kind of store

377
00:20:04,904 --> 00:20:08,513
that remembers which kind
of conditions are on the data

378
00:20:08,513 --> 00:20:10,845
we have used to search for,
for example--

379
00:20:10,845 --> 00:20:13,267
For example, if we remember
that somebody looked

380
00:20:13,267 --> 00:20:16,510
for all of the people of rating = 1,

381
00:20:16,870 --> 00:20:19,638
and if I now want to insert
somebody of rating = 1

382
00:20:19,638 --> 00:20:23,094
I will be locked until
that first transaction is finished.

383
00:20:23,541 --> 00:20:25,627
This of course is complicated,
because it means--

384
00:20:25,627 --> 00:20:28,750
it requires every time
a static analysis of the queries.

385
00:20:29,401 --> 00:20:32,292
And that has a certain kind
of complexity, of course,

386
00:20:32,292 --> 00:20:34,391
and challenges associated with it.

387
00:20:37,700 --> 00:20:43,140
To finalize this video,
just to make you remember

388
00:20:43,140 --> 00:20:48,299
that conflict serializability
is not the same as serializability.

389
00:20:48,599 --> 00:20:51,811
Whenever a schedule
is conflict serializable,

390
00:20:51,811 --> 00:20:53,953
it is also serializable, 
so we are safe.

391
00:20:53,953 --> 00:20:58,611
But there are serializable schedules
that we don't find conflict serializable.

392
00:20:59,061 --> 00:21:02,117
That means there are schedules
that we might lock up,

393
00:21:02,117 --> 00:21:05,301
and say they are bad,
but they're actually okay.

394
00:21:05,301 --> 00:21:07,867
Nothing bad can happen.
Why is that?

395
00:21:07,867 --> 00:21:10,788
Well, in general, serializability
is an undecidable condition

396
00:21:10,788 --> 00:21:12,695
of sets of transactional programs,

397
00:21:13,255 --> 00:21:16,414
and we have no chance of doing this
automatically, finding it out.

398
00:21:17,263 --> 00:21:20,561
And conflict serializability
is a very easy syntactic condition,

399
00:21:21,830 --> 00:21:24,862
so there is no chance, 
there is no hope

400
00:21:24,862 --> 00:21:28,924
that conflict serializability guarantees
or covers all of serializability.

401
00:21:30,764 --> 00:21:37,165
That said, here's a notion of
a special class of serializable schedules

402
00:21:37,748 --> 00:21:41,074
that is more general
than conflict serializability,

403
00:21:41,456 --> 00:21:43,838
but it's actually still not
all of serializability.

404
00:21:43,838 --> 00:21:46,364
This condition, it's a semantic condition,

405
00:21:46,364 --> 00:21:48,800
it's more complicated,
more difficult to check,

406
00:21:48,800 --> 00:21:52,104
more computationally expensive
to check than conflict serializability,

407
00:21:52,104 --> 00:21:54,877
but it is actually still decidable,
I think it is NP-complete.

408
00:21:55,577 --> 00:21:58,855
So this is not covering serializability,
it's a class strictly in between.

409
00:21:59,699 --> 00:22:03,830
Everything that is view serializable
is also serializable,

410
00:22:04,176 --> 00:22:05,935
and everything that
is conflict serializable

411
00:22:05,935 --> 00:22:07,374
is also view serializable.

412
00:22:07,374 --> 00:22:10,412
But there are view serializable problems
which are not conflict serializable,

413
00:22:10,412 --> 00:22:13,105
and there are serializable problems
which are not view serializable.

414
00:22:13,560 --> 00:22:15,448
So how does it work?

415
00:22:15,448 --> 00:22:19,571
Well, I can talk about two schedules
being view equivalent,

416
00:22:19,571 --> 00:22:23,343
which implies equivalence,
but not conflict equivalence.

417
00:22:23,343 --> 00:22:30,635
If whenever some transaction Ti
reads the initial value of A in S1,

418
00:22:31,000 --> 00:22:35,746
then Ti also reads the initial value of A,
some object A, in S2.

419
00:22:36,394 --> 00:22:41,399
That means the initial values
of each object

420
00:22:41,399 --> 00:22:44,900
are read by the same guys,
in both schedules.

421
00:22:45,243 --> 00:22:46,700
What does initial value mean?

422
00:22:46,700 --> 00:22:49,654
Well we imagine that there is
some consistent database,

423
00:22:50,251 --> 00:22:54,194
there are no transactions running yet,
and now the schedule starts,

424
00:22:54,194 --> 00:22:56,470
and several transactions
start in some order,

425
00:22:56,470 --> 00:22:59,225
and initial value means
the state of the database

426
00:22:59,225 --> 00:23:01,360
just before any
of these transactions started.

427
00:23:02,334 --> 00:23:05,797
Now the second condition
is one of something classical--

428
00:23:06,791 --> 00:23:12,523
if Ti reads the value of some object A
written by Tj before, in S1,

429
00:23:12,523 --> 00:23:16,542
then Ti also reads the value
written by Tj in S2.

430
00:23:17,319 --> 00:23:22,047
And finally, the corresponding
condition for final values,

431
00:23:22,487 --> 00:23:26,154
final values being the values
that you will have in the database

432
00:23:26,154 --> 00:23:28,670
after all these transactions commit,

433
00:23:29,621 --> 00:23:34,505
so if Ti writes--transaction Ti writes
the final value of A in S1,

434
00:23:34,505 --> 00:23:37,355
then it also writes
the final value of A in S2,

435
00:23:37,355 --> 00:23:39,863
and not somebody else,
not another transaction.

436
00:23:40,708 --> 00:23:43,875
So let's understand this...
Here are two examples, below.

437
00:23:43,875 --> 00:23:47,506
The left schedule has three transactions,

438
00:23:47,506 --> 00:23:50,911
T1 reading A,
T2 writing A,

439
00:23:50,911 --> 00:23:52,695
and then T1 reading A again.

440
00:23:52,695 --> 00:23:54,562
And, finally, T3 writing A.

441
00:23:55,318 --> 00:23:57,156
Now, if we look at this,

442
00:23:57,923 --> 00:24:00,627
this schedule is not
conflict serializable,

443
00:24:01,883 --> 00:24:04,200
because obviously,
if I just look at T1 and T2,

444
00:24:04,200 --> 00:24:06,497
there is a read-write conflict
from T1 to T2,

445
00:24:06,497 --> 00:24:09,183
and a write-write conflict from T2 to T1.

446
00:24:09,982 --> 00:24:12,153
So there's a cycle of dependency graph,

447
00:24:12,153 --> 00:24:14,454
so this one is not conflict serializable.

448
00:24:15,093 --> 00:24:18,482
Now if we look at this
entire schedule, though,

449
00:24:18,997 --> 00:24:23,694
it is equivalent to the schedule
on the right side.

450
00:24:23,694 --> 00:24:25,798
Look at the schedule on
the right, it's the same,

451
00:24:25,798 --> 00:24:28,577
just that these two writes,
of A in T1 and T2

452
00:24:28,577 --> 00:24:29,832
have been reordered,

453
00:24:29,832 --> 00:24:31,874
and now it's actually
a completely serial schedule.

454
00:24:31,874 --> 00:24:35,530
T1, as given, finishes before T2 starts,

455
00:24:35,530 --> 00:24:37,943
T2 finishes before T3 starts.

456
00:24:38,506 --> 00:24:43,009
So this right schedule is serial,
and that's also serializable.

457
00:24:43,722 --> 00:24:46,741
The left schedule
is equivalent to it...why?

458
00:24:46,741 --> 00:24:50,648
Well, yes, if I would look
only into section T1-T2

459
00:24:50,878 --> 00:24:52,244
it wouldn't be equivalent,

460
00:24:52,244 --> 00:24:58,192
but we are reordering
this write of A of T1 and T2,

461
00:24:58,192 --> 00:25:00,057
but what we write is anyway unimportant,

462
00:25:00,057 --> 00:25:02,524
because T3 will overwrite it, in the end.

463
00:25:02,524 --> 00:25:08,130
In both schedules, the final write
of object A is done by T3,

464
00:25:08,320 --> 00:25:11,246
and that means whoever
wrote, in which order

465
00:25:11,246 --> 00:25:14,355
before this particular value,
it doesn't matter.

466
00:25:14,355 --> 00:25:15,819
So that connects basically

467
00:25:15,819 --> 00:25:18,380
the second and the third condition
of this definition.

468
00:25:18,380 --> 00:25:21,887
That means if the schedule consisted only

469
00:25:21,887 --> 00:25:24,879
of the first and the second transactions,
but not of the third,

470
00:25:25,723 --> 00:25:28,692
then we would indeed
have a non-serializable schedule,

471
00:25:29,440 --> 00:25:32,164
but adding another transaction,

472
00:25:32,164 --> 00:25:34,889
that basically makes certain
write orders unimportant,

473
00:25:36,289 --> 00:25:38,253
enables us to see

474
00:25:39,043 --> 00:25:42,817
that this particular
schedule on the left-hand side

475
00:25:42,817 --> 00:25:46,081
is equivalent to a serial schedule,
the one given on the right-hand side.

476
00:25:46,081 --> 00:25:49,697
And we can find this using this view
equivalent definitions in this case.

477
00:25:50,742 --> 00:25:54,711
So this is indeed a more general
condition, a conflict serializable.

478
00:25:54,711 --> 00:25:57,528
Serializability needs and it still
guaranteed serializability.

479
00:25:57,528 --> 00:26:01,344
But remember, there are
yet other serializable transactions

480
00:26:01,344 --> 00:26:04,034
that are not covered
by view serializability.

481
00:26:04,669 --> 00:26:06,144
That concludes this video,

482
00:26:06,144 --> 00:26:08,477
and what we've done, in summary,

483
00:26:08,477 --> 00:26:13,259
is we have talked about locking techniques
for ensuring serializability.

484
00:26:13,259 --> 00:26:16,416
So locking is a very natural way
to do this in systems, obviously,

485
00:26:16,416 --> 00:26:19,220
and we're familiar with locking from
basic systems programming courses,

486
00:26:19,910 --> 00:26:21,827
and there's no magic to it.

487
00:26:22,943 --> 00:26:26,097
But one thing to keep in mind
is there are also other techniques

488
00:26:26,097 --> 00:26:27,766
that are not based on locking.

489
00:26:27,766 --> 00:26:31,022
Actually nowadays, in current, modern
database management systems,

490
00:26:31,022 --> 00:26:33,387
locking is not the default technique

491
00:26:33,387 --> 00:26:37,879
for achieving what people usually
use in concurrency control,

492
00:26:37,879 --> 00:26:40,997
and I'll go over this
in more detail in a different video.

493
00:26:42,399 --> 00:26:44,578
But locking, in a strong sense,

494
00:26:44,578 --> 00:26:46,796
connects to conflict serializability,

495
00:26:46,796 --> 00:26:48,182
which is an important definition,

496
00:26:48,182 --> 00:26:51,406
purely syntactically enforceable
by a dependency graph.

497
00:26:51,406 --> 00:26:54,501
And you've also seen that
it is not all of serializability,

498
00:26:54,501 --> 00:26:56,201
there is more to it.
