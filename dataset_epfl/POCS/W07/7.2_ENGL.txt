Welcome back, now we're ready to talk about virtual machines.
We're actually going to start to talk about it from a historical perspective.
So a virtual machine is an abstraction, it's the abstraction of a computer.
Think of a desktop, think of a laptop, think of a server, but rather than being implemented in hardware it is an abstraction that is implemented on top of that same hardware and can be multiplexed, multiple times.
(Edouard) The formal definition of a virtual machine that is universally accepted today actually goes back to 1974.
Virtual machines actually predate 1974 by well over a decade but this definition from 1974 is the one that we refer to today.
And this is actually a definition from the paper that you'll be reading this week.
And what Popek and Goldberg have defined is a virtual machine to be the efficient, isolated duplicate of a real machine.
So in this diagram we have two virtual machines, each virtual machine has a CPU, memory, and NIC and has some disk.
Each virtual machine is running an operating system, and each virtual machine is running multiple applications although we only show one application in this slide.
And the key second part of the definition from Popek and Golberg is the definition of the piece of software that creates the abstraction of the virtual machine which is called the virtual machine monitor.
And the virtual machine monitor must have two important characteristics: it must be in complete control of the system.
So the operating system is unable to actually control the system entirely, it can only control the virtual hardware of its virtual machine.
And the second key attribute is that the virtual machine monitor must use the underlying hardware so that the programs running in the virtual machine show, at worst, a minor decrease in speed.
So Popek and Goldberg made that definition in an era where operating systems were already universal.
So we assume that an application is running on top of an operating system and the performance requirement is that applications running on top of an operating system inside a virtual machine run more or less at the same speed as the same application running directly on an operating system in the absence of a virtual machine monitor.
A critical definition from Popek and Goldberg back in 1974.
So this definition comes from 1974.
What's important to realize is by 1974, virtual machines were actually already somewhat on their way out.
So now let me even go back earlier before 1974 and give you a little bit of perspective as to where we are coming from.
And specifically we need to go back to the early mainframe era.
Now in that era, and by that I mean the 1960s. there were very few platforms.
A computer was extremely expensive, it took a huge amount of space, they were extremely few of them and having the abstraction of a virtual machine was actually a very convenient tool that allowed the sharing of resources.
If you could not afford your own computer, at the very least you could have your own virtual machine part of the time.
And that was compounded by the fact that the operating systems of the time were very limited in their capabilities.
The concept of time sharing of multi-users was not even available and so having a virtual machine allowed people to rapidly innovate within and among different forms of operating systems.
You could have different operating systems running in different virtual machines and that was a form of great efficiency.
Now at the time, actually people went out of their way to make it efficient to create virtual machine monitors and there was hardware support for virtualization.
As a matter of fact, the paper that you're reading this week from Popek and Goldberg actually is the formalization of a set of engineering principles that were by that point relatively well understood from an engineering perspective and were formalized and proven in their paper.
Now what's interesting about that era is that very quickly we transition into a phase where virtual machines were rejected.
And they were rejected in favor specifically of operating systems.
And that is because companies realized that there was tremendous innovation potential within the operating system itself and it was actually more interesting to innovate within an operating system than add the virtual machine monitor layer.
And this actually gave us the rise of the modern operating system that we understand today.
Now because virtual machines were less important as people build new generation of hardware, people start building hardware that actually didn't even have architectural support for virtualization.
And by the mid 1990s virtual machines were completely viewed as a relic of the past.
There was no good reason to even get interested in virtual machines at the time.
So I actually start to get involved, personally, in virtual machines around 1996 and at the time this was viewed an absolutely crazy research proposition.
There had been no research done in the field of virtual machines for well over a decade.
There were no new commercial products using virtual machines.
And outside of the mainframe world nobody even understood or appreciated what you could actually do with virtual machines.
Now our motivation at the time was that, there was actually a case to be made for the return of virtual machines simply when the operating system fails.
And we were living at the time in an era where there was an assumption that the operating system could actually do its job properly.
It could actually succeed in managing resources and abstracting hardware.
And the work of my advisor at Stanford at the time, the prior work, was a system called Hive which was an operating system for a very large scale machine called Flash.
And Hive was largely a negative result.
Now of course it was a functional system, it actually did what it was supposed to do, it had some interesting research result.
The real take away from the work in Hive was that the changes required to the underlying operating system, which was UNIX, were way too extensive for an approach like Hive to make any sense and to be maintainable and to actually make it into a production level type of solution.
And that is simply because the operating systems by that time already had gotten to be so big and so complex it was extremely difficult to innovate within the operating system.
So there's a case for virtual machines to be made when the operating system fails because either it misses some appropriate functionality or simply because it is in practice too slow to innovate within an operating system.
There's actually another reason why virtual machines might make sense and that actually rationale made sense in the '60s and it actually makes sense today in a very fundamental way in the context of cloud computing.
And that is because the operating system is special.
First, there can only be one operating system per machine and it can only be one administrator of that operating system per machine.
Now because the operating system is special, there tends to be kind of a monolithic culture around operating system and you have a lot of monopolies and because you have monopolies sometimes the operating systems actually fail to innovate at the speed in which they should if there was a little bit more competition.
So two issues with respect to operating system being special, one is there can only be one leading to new monopolies and the second one is the fact that it is impossible to have two independent entities both be administrators of an operating system.
And so the introduction of the layering through the use of virtual machine actually solves both these problems.
So this wraps up our module on a short history of virtual machines.
Next up we'll go into the details of how you actually can build a virtual machine monitor.
See you then.
