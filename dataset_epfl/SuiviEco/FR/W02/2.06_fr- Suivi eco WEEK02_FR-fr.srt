1
00:00:09,577 --> 00:00:11,277
Rappelons que la base
de notre travail

2
00:00:11,477 --> 00:00:13,352
est d'utiliser la distribution
d'une variable statistique

3
00:00:13,552 --> 00:00:15,078
au niveau d'un échantillon aléatoire

4
00:00:15,278 --> 00:00:17,634
afin de comprendre
la répartition de cette variable

5
00:00:17,834 --> 00:00:18,826
au niveau de la population.

6
00:00:19,026 --> 00:00:22,800
Si nous connaissons le modèle
de distribution de la population

7
00:00:23,000 --> 00:00:25,686
nous pouvons calculer
tout ce que nous voulons savoir

8
00:00:25,886 --> 00:00:26,723
sur la population

9
00:00:26,923 --> 00:00:31,094
à condition de connaitre la valeur
du paramètre dont dépend ce modèle.

10
00:00:31,294 --> 00:00:34,018
On se pose donc naturellement
la question suivante

11
00:00:34,218 --> 00:00:37,269
comment utiliser la distribution
de l'échantillon

12
00:00:37,469 --> 00:00:39,927
afin de déduire le paramètre inconnu

13
00:00:40,127 --> 00:00:41,295
du modèle de la population ?

14
00:00:41,495 --> 00:00:44,447
C'est ce qu'on appelle
l'estimation ponctuelle.

15
00:00:45,793 --> 00:00:48,937
Supposons donc que nous ayons
un modèle de F(x;θ)

16
00:00:49,137 --> 00:00:50,701
décrivant notre population

17
00:00:50,901 --> 00:00:53,596
et que ce modèle s'écrive
selon une formule explicite

18
00:00:53,796 --> 00:00:55,184
que nous omettons pour le moment.

19
00:00:55,384 --> 00:00:58,394
Bien que nous connaissions
la formule du modèle

20
00:00:58,594 --> 00:01:01,551
nous ne connaissons pas
la valeur réelle du paramètre θ.

21
00:01:01,751 --> 00:01:04,966
Par exemple, imaginons
que le modèle est exponentiel

22
00:01:05,166 --> 00:01:06,076
de paramètre θ

23
00:01:06,276 --> 00:01:09,195
mais que nous ne connaissons
pas la valeur précise de ce paramètre.

24
00:01:09,395 --> 00:01:11,550
Nous avons à notre disposition

25
00:01:11,750 --> 00:01:14,729
un échantillon x1, x2, jusqu'à xn

26
00:01:14,929 --> 00:01:16,435
qui est issu de la population.

27
00:01:16,635 --> 00:01:19,506
Pour exprimer le paramètre inconnu θ

28
00:01:19,706 --> 00:01:21,634
on construit un estimateur

29
00:01:21,834 --> 00:01:24,106
une fonction θ^

30
00:01:24,306 --> 00:01:26,733
de valeur d'échantillon
x1 jusqu'à xn

31
00:01:26,933 --> 00:01:29,996
dont la valeur nous permet
d'estimer le paramètre inconnu.

32
00:01:30,196 --> 00:01:34,329
Cela nous mène naturellement
à nous poser deux questions.

33
00:01:34,529 --> 00:01:36,037
Tout d'abord

34
00:01:36,237 --> 00:01:38,720
comment construisons-nous
des estimateurs ?

35
00:01:38,920 --> 00:01:41,897
En d'autres termes
quelle est la bonne formule

36
00:01:42,097 --> 00:01:43,109
pour θ^?

37
00:01:44,482 --> 00:01:48,327
Puis, comment pouvons-nous évaluer
la précision des estimateurs ?

38
00:01:48,527 --> 00:01:51,461
Nous allons commencer
par la première question

39
00:01:51,661 --> 00:01:53,908
puis nous nous intéresserons
à la deuxième.

40
00:01:54,108 --> 00:01:57,565
Quelle que soit la formule
des estimateurs qu'on utilise

41
00:01:57,765 --> 00:01:59,527
l'idée de base est toujours la même.

42
00:01:59,727 --> 00:02:03,683
Il s'agit de calibrer la distribution
du modèle de population

43
00:02:03,883 --> 00:02:06,975
par rapport à la distribution
au niveau de l'échantillon.

44
00:02:07,175 --> 00:02:09,355
Par exemple, ici à droite

45
00:02:09,555 --> 00:02:11,150
vous voyez un exemple
d'histogramme en rouge

46
00:02:11,350 --> 00:02:14,339
et différents modèles de distribution
exponentielles en bleu

47
00:02:14,539 --> 00:02:17,594
Chaque cas correspond
à une valeur différente du paramètre

48
00:02:17,794 --> 00:02:20,286
Alors quel paramètre choisir

49
00:02:20,486 --> 00:02:23,084
pour accorder au mieux
l'échantillon et la population ?

50
00:02:23,284 --> 00:02:26,920
La calibration se fait toujours
en fonction de certains critères.

51
00:02:27,120 --> 00:02:31,375
Par exemple, on peut décider
que la moyenne du modèle de population

52
00:02:31,575 --> 00:02:33,424
et la moyenne de distribution
de l'échantillon

53
00:02:33,624 --> 00:02:34,958
doivent être identiques.

54
00:02:35,158 --> 00:02:38,160
et donc choisir le paramètre
en fonction de cette égalité.

55
00:02:38,360 --> 00:02:41,399
Cela revient à chercher
ce qu'on appelle

56
00:02:41,599 --> 00:02:43,346
un estimateur
de la méthode des moments.

57
00:02:43,546 --> 00:02:46,504
On peut aussi tenter
un calibrage plus fin.

58
00:02:46,704 --> 00:02:49,335
On peut essayer de trouver 
le paramètre

59
00:02:49,535 --> 00:02:52,766
qui rend l'échantillon
le plus représentatif possible

60
00:02:52,251 --> 00:02:55,251


61
00:02:52,966 --> 00:02:53,823
du modèle correspondant.

62
00:02:54,023 --> 00:02:56,563
Cela revient à chercher
ce que l'on appelle

63
00:02:56,763 --> 00:02:58,728
un estimateur
de maximum de vraisemblance.

64
00:02:58,928 --> 00:03:02,147
Si le modèle de population
dépend du paramètre θ

65
00:03:02,347 --> 00:03:05,597
la moyenne de la population
dépend également de ce paramètre.

66
00:03:05,797 --> 00:03:08,387
Appelons cette moyenne m de θ.

67
00:03:08,587 --> 00:03:12,498
Si nous utilisons un échantillon
aléatoire x1 jusqu'à xn

68
00:03:12,698 --> 00:03:14,971
alors nous pouvons calculer
la moyenne de l'échantillon

69
00:03:15,171 --> 00:03:16,301
x barre.

70
00:03:16,501 --> 00:03:19,591
La méthode des moments
suggère de trouver la valeur de θ

71
00:03:19,791 --> 00:03:21,519
telle que la moyenne
de la population

72
00:03:21,719 --> 00:03:25,360
m de θ correspond à la moyenne
de l'échantillon x barre.

73
00:03:25,560 --> 00:03:30,049
Cela revient à résoudre l'équation
m de θ est égale à 1 sur n

74
00:03:30,249 --> 00:03:32,480
la somme des observations pour θ.

75
00:03:32,680 --> 00:03:35,740
La solution est appelée
l'estimateur de la méthode des moments

76
00:03:35,940 --> 00:03:39,405
pour θ ou l'estimateur MON de θ.

77
00:03:39,605 --> 00:03:42,695
Le diagramme de droite
est un histogramme rouge

78
00:03:42,895 --> 00:03:45,945
Il correspond à un échantillon
de 40 observations.

79
00:03:46,145 --> 00:03:50,392
On modélise la population
selon une distribution exponentielle.

80
00:03:50,592 --> 00:03:53,563
On voit superposé en bleu

81
00:03:53,763 --> 00:03:56,975
différentes courbes correspondant
à différents choix de paramètres.

82
00:03:57,175 --> 00:03:59,747
La ligne verticale grise

83
00:03:59,947 --> 00:04:01,530
indique la moyenne de l'échantillon.

84
00:04:01,730 --> 00:04:04,303
Elle est égale à 0,938.

85
00:04:04,503 --> 00:04:09,181
La courbe grise represente
la distribution exponentielle

86
00:04:09,381 --> 00:04:13,876
avec une moyenne égale
exactement à 0,938.

87
00:04:17,328 --> 00:04:20,146
Mais la moyenne
de la distribution exponentielle

88
00:04:20,346 --> 00:04:21,770
est l'inverse de son paramètre

89
00:04:21,970 --> 00:04:22,928
comme nous l'avons vu.

90
00:04:23,128 --> 00:04:27,455
Par conséquent, l'estimation trouvée
grâce à la méthode des moments

91
00:04:27,655 --> 00:04:30,077
est l'inverse de 0,938.

92
00:04:30,277 --> 00:04:32,652
C'est à dire 1,066.

93
00:04:33,866 --> 00:04:35,838
La méthode des moment
choisi un paramètre

94
00:04:36,038 --> 00:04:38,593
qui permet à la situation
de l'échantillon de la population

95
00:04:38,793 --> 00:04:41,261
de correspondre à travers la moyenne.

96
00:04:41,461 --> 00:04:43,181
Mais il existe une autre approche

97
00:04:43,381 --> 00:04:45,736
consistant à choisir un paramètre
faisant correspondre

98
00:04:45,936 --> 00:04:48,394
l'échantillon et la population
à un niveau plus fin.

99
00:04:48,594 --> 00:04:52,030
afin que l'échantillon
soit le plus représentatif possible

100
00:04:52,230 --> 00:04:53,168
de la population.

101
00:04:53,368 --> 00:04:56,217
Cela exige
que les proportions calculées

102
00:04:56,417 --> 00:04:58,112
à partir de l'histogramme
de l'échantillon

103
00:04:58,312 --> 00:05:00,690
correspondent
au mieux aux proportions

104
00:05:00,890 --> 00:05:03,161
calculées à partir
de la courbe de population

105
00:05:05,330 --> 00:05:08,356
Il existe une méthode mathématique
nous permettant de déterminer

106
00:05:08,556 --> 00:05:11,061
la meilleure valeur de θ à ces fins.

107
00:05:11,261 --> 00:05:15,171
On l'appelle la méthode
du maximum de vraisemblance.

108
00:05:17,583 --> 00:05:20,805
Cela revient à dire
qu'il faut que nous trouvions

109
00:05:21,005 --> 00:05:22,087
la valeur de θ

110
00:05:22,287 --> 00:05:26,607
qui maximise la fonction
de vraisemblance de θ.

111
00:05:26,807 --> 00:05:29,897
Cette fonction est égale
au produit qu'on obtient

112
00:05:30,097 --> 00:05:33,106
en multipliant la formule
du modèle n fois

113
00:05:33,306 --> 00:05:37,140
chaque terme étant évalué
à l'une des valeurs de l'échantillon.

114
00:05:39,812 --> 00:05:42,758
Il est possible d'interpréter
cette méthode intuitivement.

115
00:05:42,958 --> 00:05:46,867
En fait, c'est le choix du paramètre
qui nous donne le modèle de population

116
00:05:47,067 --> 00:05:49,602
selon lequel l'échantillon aléatoire

117
00:05:49,802 --> 00:05:51,459
aurait été le plus probable.

118
00:05:51,659 --> 00:05:54,648
La méthode des moments souvent
produit le même estimateur

119
00:05:54,848 --> 00:05:56,418
que la méthode
du maximum de vraisemblance.

120
00:05:56,618 --> 00:05:59,044
C'est le cas par exemple
avec les modèles des moments

121
00:05:59,244 --> 00:06:00,524
exponentiels et de Poisson.

122
00:06:00,724 --> 00:06:02,659
Mais il peut également arriver

123
00:06:02,859 --> 00:06:05,632
que les deux méthodes d'estimations
produisent des estimateurs différents

124
00:06:05,832 --> 00:06:06,584
pour certains modèles.

125
00:06:06,784 --> 00:06:09,054
On peut donc naturellement
se demander

126
00:06:09,254 --> 00:06:10,738
lesquels devraient être utilisés ?

127
00:06:12,188 --> 00:06:15,036
La méthode des moments est
généralement plus simple à appliquer

128
00:06:14,577 --> 00:06:17,577


129
00:06:15,236 --> 00:06:18,002
ce qui peut être un avantage
dans des situations compliquées.

130
00:06:18,202 --> 00:06:20,942
Mais l'estimateur du maximum
de vraisemblance

131
00:06:21,142 --> 00:06:22,617
est habituellement préféré

132
00:06:22,817 --> 00:06:24,873
car il permet d'utiliser
plus efficacement

133
00:06:25,073 --> 00:06:25,945
les données à portée de main.

134
00:06:27,170 --> 00:06:29,740
Un autre avantage de la méthode
du maximum de vraisemblance

135
00:06:29,940 --> 00:06:32,391
est que nous avons quelques formules
assez générales

136
00:06:32,591 --> 00:06:33,870
qui décrivent sa précision.

137
00:06:34,633 --> 00:06:37,955
Il est important d'avoir une idée
de la précision de l'estimateur

138
00:06:38,155 --> 00:06:39,273
de paramètre de la population.

139
00:06:40,185 --> 00:06:42,326
Bien que la valeur d'un estimateur

140
00:06:42,526 --> 00:06:43,437
l'estimation

141
00:06:43,637 --> 00:06:45,454
est constante
pour un échantillon donné

142
00:06:45,654 --> 00:06:47,507
elle varie
pour différents échantillons.

143
00:06:47,707 --> 00:06:50,209
Ainsi, pour le premier échantillon

144
00:06:50,409 --> 00:06:53,679
nous pourrions obtenir une estimation
un peu sous évaluée

145
00:06:56,167 --> 00:06:57,690
Pour le deuxième échantillon

146
00:06:57,890 --> 00:06:59,573
encore plus sous évaluée

147
00:07:01,486 --> 00:07:03,064
Et pour le troisième échantillon

148
00:07:03,264 --> 00:07:05,482
le paramètre pourrait être
légèrement sur-estimé.

149
00:07:08,195 --> 00:07:10,347
On voit donc qu'à chaque fois
que nous collectons

150
00:07:10,547 --> 00:07:13,547


151
00:07:10,547 --> 00:07:11,508
un nouvel échantillon

152
00:07:11,708 --> 00:07:13,363
nous obtenons
une nouvelle estimation.

153
00:07:14,326 --> 00:07:16,855
Pour cerner l'exactitude
de notre estimateur

154
00:07:17,055 --> 00:07:20,659
nous devons donc comprendre
les fluctuations de notre estimation

155
00:07:20,859 --> 00:07:22,676
autour de la valeur réelle
du paramètre.

156
00:07:22,876 --> 00:07:24,089
Car chaque échantillon

157
00:07:24,289 --> 00:07:27,306
est seulement un des divers
échantillons possibles.

158
00:07:27,506 --> 00:07:30,427
Considérons
tous les échantillons possibles.

159
00:07:30,627 --> 00:07:34,307
On dispose toutes les estimations
possibles sur un axe.

160
00:07:35,357 --> 00:07:36,971
On peut alors se demander

161
00:07:37,171 --> 00:07:39,586
quelle proportion de ces estimations

162
00:07:39,786 --> 00:07:43,551
si situe à une certaine distance
de la vraie valeur du paramètre ?

163
00:07:43,751 --> 00:07:46,130
Par exemple dans cet intervalle.

164
00:07:46,330 --> 00:07:48,466
Encore plus généralement

165
00:07:48,666 --> 00:07:50,884
on peut se demander
quelle proportion des estimations

166
00:07:51,084 --> 00:07:53,049
tombent dans un certain intervalle.

167
00:07:53,249 --> 00:07:54,277
Dans un intervalle quelconque.

168
00:07:54,477 --> 00:07:56,210
Par exemple ici.

169
00:07:57,845 --> 00:08:01,047
En effet, l'estimateur
a sa propre distribution.

170
00:08:01,247 --> 00:08:03,864
Comprendre la précision
de cet estimateur

171
00:08:04,064 --> 00:08:06,642
revient à évaluer
la concentration de sa distribution

172
00:08:06,842 --> 00:08:10,774
autour de la vraie valeur
du paramètre

173
00:08:10,974 --> 00:08:15,164
On pourrait donc essayer de déterminer
la forme de cette distribution

174
00:08:16,014 --> 00:08:18,001
Malheureusement
la distribution d'échantillonnage

175
00:08:18,201 --> 00:08:19,852
d'un estimateur n'est pas
toujours la même.

176
00:08:20,052 --> 00:08:21,670
Elle dépend du modèle utilisé

177
00:08:21,870 --> 00:08:23,257
du paramètre estimé

178
00:08:23,457 --> 00:08:25,411
et de la méthode d'estimation
que nous utilisons.

179
00:08:25,611 --> 00:08:27,376
Heureusement

180
00:08:27,576 --> 00:08:29,756
Si la taille de l'échantillon
est assez grande

181
00:08:29,956 --> 00:08:32,943
et que nous utilisons un estimateur
de maximum de vraisemblance

182
00:08:33,143 --> 00:08:35,175
nous pouvons obtenir
une bonne approximation

183
00:08:35,375 --> 00:08:36,835
Chose frappante

184
00:08:37,035 --> 00:08:40,561
cette distribution approximative
est en fait une distribution normale

185
00:08:40,761 --> 00:08:43,727
Et cela est vrai quel que soit
le modèle de population

186
00:08:43,927 --> 00:08:45,960
ou le paramètre spécifique
qui nous intéresse.

187
00:08:46,160 --> 00:08:48,986
Ceci est du à un résultat
mathématique très profond

188
00:08:49,186 --> 00:08:51,602
appelé théorème central limite.

189
00:08:51,802 --> 00:08:55,271
La moyenne de cette distribution
normale approximative

190
00:08:55,471 --> 00:08:56,732
est en fait le vrai paramètre

191
00:08:56,932 --> 00:09:00,061
et la variance est donnée
par une formule explicite

192
00:09:00,261 --> 00:09:02,339
qui dépend de la fonction
de vraisemblance.

193
00:09:02,539 --> 00:09:06,508
Nous n'allons pas mentionner
la nature précise de cette formule.

194
00:09:06,702 --> 00:09:08,837
Nous dirons simplement
que c'est une quantité

195
00:09:09,037 --> 00:09:10,421
que nous pouvons calculer facilement

196
00:09:10,621 --> 00:09:12,963
pour tout modèle de population
possible.

197
00:09:13,163 --> 00:09:15,958
Ce que nous allons remarquer
cependant

198
00:09:16,158 --> 00:09:19,393
c'est que cette variance est inversement
proportionnelle à elle-même.

199
00:09:19,593 --> 00:09:21,417
Plus la taille de l'échantillon
augmente

200
00:09:21,617 --> 00:09:23,252
plus la variance diminue.

201
00:09:23,452 --> 00:09:24,870
En d'autres termes

202
00:09:25,070 --> 00:09:26,934
plus l'échantillon est grand

203
00:09:27,134 --> 00:09:29,854
plus l'estimateur du maximum
de vraisemblance

204
00:09:30,054 --> 00:09:32,953
est concentré autour
de la vraie valeur du paramètre

205
00:09:33,153 --> 00:09:35,433
Dans la grande majorité des cas

206
00:09:35,633 --> 00:09:37,454
la méthode du maximum
de vraisemblance

207
00:09:37,654 --> 00:09:39,672
est une très bonne méthode
d'estimation.

