1
00:00:08,994 --> 00:00:11,150
We now have a collection
of n values corresponding

2
00:00:11,372 --> 00:00:12,913
 to the measured values
of the variables

3
00:00:13,116 --> 00:00:15,247
on the sample elements
and would like to use these

4
00:00:15,447 --> 00:00:17,543
to probe the characteristics
of the sample distribution.

5
00:00:17,732 --> 00:00:20,708
We can carry out this exploration
by means of graphical

6
00:00:20,965 --> 00:00:22,561
as well as numerical summaries.

7
00:00:22,825 --> 00:00:25,203
Let's first focus 
on numerical summaries.

8
00:00:25,671 --> 00:00:28,146
In the case where the variable
of interest is continuous

9
00:00:28,340 --> 00:00:29,467
there are several numerical 
summaries

10
00:00:29,667 --> 00:00:31,549
that can be constructed,
as we will soon see. 

11
00:00:31,819 --> 00:00:34,459
But in the case where the variable
of interest is qualitative

12
00:00:34,659 --> 00:00:37,053
all you can essentially do
is record and present

13
00:00:37,253 --> 00:00:40,024
the percentage of sample values
falling in each category.

14
00:00:40,694 --> 00:00:42,713
Consider for instance,
a sample of size

15
00:00:42,913 --> 00:00:44,772
n equals 25, where the variable
of interest

16
00:00:44,972 --> 00:00:46,883
is the blood group
of each individual.

17
00:00:47,797 --> 00:00:50,157
All we can do in this case,
is to classify

18
00:00:50,357 --> 00:00:52,968
and organize the values in 
a so-called frequency table.

19
00:00:53,880 --> 00:00:56,306
A frequency table lists 
all possible categories

20
00:00:56,506 --> 00:00:59,031
of the qualitative variable
in it's first column.

21
00:00:59,231 --> 00:01:01,877
It then lists the corresponding
number of appearances

22
00:01:02,077 --> 00:01:03,461
at the level of the sample

23
00:01:03,661 --> 00:01:05,583
which are called the absolute
frequencies. 

24
00:01:05,783 --> 00:01:09,046
Finally, it lists what proportion
of the same members

25
00:01:09,246 --> 00:01:12,017
has any given value
in the last column.

26
00:01:12,217 --> 00:01:13,978
This is called
the relative frequency.

27
00:01:14,891 --> 00:01:17,583
The frequency table summarizes
and organizes all the information

28
00:01:17,834 --> 00:01:20,633
that the sample carries
about the qualitative variable.

29
00:01:20,849 --> 00:01:23,296
When the variables are quantitative,
on the other hand,

30
00:01:23,496 --> 00:01:26,040
one can use more sophisticated
numerical summaries.

31
00:01:26,240 --> 00:01:29,535
In order to do this.
a very useful pre-processing step

32
00:01:29,735 --> 00:01:32,716
is to order the sample values
in increasing order,

33
00:01:32,916 --> 00:01:35,012
the so-called order statistics. 

34
00:01:35,212 --> 00:01:37,940
In fact, it is this very ordering
that makes

35
00:01:38,140 --> 00:01:39,729
quantitative variables interesting.

36
00:01:39,929 --> 00:01:43,128
The fact that they can be arranged
and visualized on an axis.

37
00:01:44,202 --> 00:01:45,895
Getting the order statistics 
involves

38
00:01:46,097 --> 00:01:49,334
taking the original sample values,
x1 up to xn,

39
00:01:49,534 --> 00:01:52,520
and rearranging them 
as x(1 in parenthesis)

40
00:01:52,720 --> 00:01:54,927
up to x(n in parenthesis).

41
00:01:55,600 --> 00:01:57,679
These new labels in parenthesis
highlight

42
00:01:57,879 --> 00:02:00,318
what the rank of each observation is
in the sample

43
00:02:00,518 --> 00:02:04,066
rather than it's arbitrary position
in the initial list.

44
00:02:05,765 --> 00:02:08,361
For example, consider a sample
of size n equals 2

45
00:02:08,561 --> 00:02:11,228
with sample values of 5, 1, and 4.

46
00:02:11,428 --> 00:02:15,003
The order statistics relabel
the original observations

47
00:02:15,203 --> 00:02:17,663
according to rank,
even though the value 1

48
00:02:17,863 --> 00:02:19,658
corresponds to the second member
of the sample

49
00:02:19,858 --> 00:02:22,353
it has the smallest rank, being 
the minimal value.

50
00:02:22,553 --> 00:02:24,831
And thus, becomes the first
order statistics.

51
00:02:25,370 --> 00:02:27,381
When this ordering 
is finalized we can  

52
00:02:27,612 --> 00:02:29,603
then probe features 
of the distribution.

53
00:02:29,824 --> 00:02:31,797
Is it concentrated
around a certain location?

54
00:02:31,997 --> 00:02:34,915
Is it dispersed?
Does it possess some symmetries?

55
00:02:35,203 --> 00:02:37,736
All these characteristics
give us information

56
00:02:37,936 --> 00:02:39,663
about the distribution
of the sample.

57
00:02:40,473 --> 00:02:42,854
We will consider numerical summaries
for the following

58
00:02:43,046 --> 00:02:45,546
sample characteristics
of quantitative variables. 

59
00:02:45,746 --> 00:02:48,549
First, measures of location,
indicating the center

60
00:02:48,796 --> 00:02:51,874
of the sample distribution,
such as the mean and the median.

61
00:02:52,074 --> 00:02:56,456
Second, measures of dispersion,
indicating how spread out

62
00:02:56,656 --> 00:02:59,637
the sample values are,
and whether they locally concentrate

63
00:02:59,837 --> 00:03:01,144
and are otherwise
dispersed.

64
00:03:01,773 --> 00:03:04,248
These include the variance, 
quantiles and quartiles

65
00:03:04,448 --> 00:03:07,662
and finally the range,
and interquartile range.

66
00:03:08,697 --> 00:03:10,952
Let's start with the mean
and the median. 

67
00:03:11,626 --> 00:03:13,664
So suppose we have a sample
of n values

68
00:03:13,864 --> 00:03:16,041
denoted by x1 up to xn.

69
00:03:16,241 --> 00:03:20,007
The sample mean is defined
as the sum of these observations

70
00:03:20,207 --> 00:03:22,241
divided by the sample size.

71
00:03:22,824 --> 00:03:24,613
On the other hand, 
the sample median 

72
00:03:24,813 --> 00:03:26,564
is a bit more complicated
to define.

73
00:03:26,764 --> 00:03:28,719
It is defined as
the middle observation

74
00:03:28,919 --> 00:03:31,001
when the sample size n is odd.

75
00:03:31,201 --> 00:03:35,198
Or the average of the two
middle observations

76
00:03:35,398 --> 00:03:37,127
when the sample size is even.

77
00:03:37,942 --> 00:03:39,816
But what do these
definitions mean?

78
00:03:40,016 --> 00:03:41,301
Let's take a closer look.

79
00:03:42,735 --> 00:03:44,608
The physical interpretation
of the mean

80
00:03:44,808 --> 00:03:47,249
is that it is the center of mass
of the data.

81
00:03:47,552 --> 00:03:49,593
Let's say we have
 a sample of size 5.

82
00:03:49,793 --> 00:03:54,174
And let's order this sample 
on an axis as shown right here.

83
00:03:55,169 --> 00:03:58,206
Suppose that we place an equal
amount of mass

84
00:03:58,406 --> 00:04:01,583
on the location of each one
of these observations.

85
00:04:01,783 --> 00:04:05,642
We can then ask the question
where on the axis

86
00:04:05,867 --> 00:04:09,756
should we place this pen
in order for the axis to balance?

87
00:04:09,956 --> 00:04:12,825
If we do so too far to the left

88
00:04:13,025 --> 00:04:15,993
then the axis is going to fall down
to the right.

89
00:04:16,785 --> 00:04:19,209
If we do so too far
to the right

90
00:04:19,409 --> 00:04:22,187
then the axis is going to fall down
to the left.

91
00:04:23,018 --> 00:04:26,539
We seek a perfect point where
the axis is going to balance.

92
00:04:27,451 --> 00:04:30,283
Such a unique location
actually exists.

93
00:04:30,483 --> 00:04:32,986
It is precisely the sample mean.

94
00:04:33,186 --> 00:04:35,821
In this case,
it is somewhere here.

95
00:04:37,053 --> 00:04:39,216
The median, on the other hand
is motivated

96
00:04:39,416 --> 00:04:41,370
by a symmetry consideration.

97
00:04:41,570 --> 00:04:45,312
Suppose we ask for a point
on the axis

98
00:04:45,512 --> 00:04:48,196
that splits the data in half.

99
00:04:48,396 --> 00:04:51,643
That means that to the left 
of the point we should have

100
00:04:51,843 --> 00:04:55,221
as many observations as we have
to the right of that point.

101
00:04:55,796 --> 00:04:58,380
Now, if the number 
of observations is odd, 

102
00:04:58,580 --> 00:05:01,648
such as 5.
in this example,

103
00:05:01,848 --> 00:05:05,566
this is easy, we can simply
pick the middle observation.

104
00:05:06,440 --> 00:05:10,576
In this case, the middle observation
is the third largest observation.

105
00:05:10,776 --> 00:05:14,676
Notice that there are exactly 
two observations to the left of this

106
00:05:14,876 --> 00:05:17,346
and two observations
to it's right.

107
00:05:17,546 --> 00:05:20,668
So we pronounce
this observation to be the median.

108
00:05:22,965 --> 00:05:26,006
If the number of observations
is even, on the other hand

109
00:05:26,206 --> 00:05:29,763
then any point between two
middle observations

110
00:05:29,963 --> 00:05:31,850
can serve as a median.

111
00:05:32,087 --> 00:05:33,710
For instance, in this case,
we have

112
00:05:33,910 --> 00:05:36,737
the two middle observations,
x(2) and x(3).

113
00:05:36,937 --> 00:05:40,666
Notice that any point we 
might choose in the interval

114
00:05:40,866 --> 00:05:42,271
between these two observations

115
00:05:42,471 --> 00:05:45,502
would split the data set
into two equal halves.

116
00:05:45,702 --> 00:05:48,279
The first half containing
the first two observations

117
00:05:48,459 --> 00:05:51,275
the second half containing
the last two observations.

118
00:05:51,618 --> 00:05:54,198
Which point should we pick?

119
00:05:54,653 --> 00:05:58,226
Well, by symmetric considerations
it could make sense

120
00:05:58,426 --> 00:06:00,557
to simply pick the midpoint,

121
00:06:00,757 --> 00:06:02,876
the point right at the middle
of the interval.

122
00:06:03,076 --> 00:06:06,184
This midpoint turns out to be
exactly the average

123
00:06:06,384 --> 00:06:15,110
1 over 2 times x (2) plus x (3)
in this case.

124
00:06:15,310 --> 00:06:19,899
Otherwise said, the average
between the two middle observations.

125
00:06:21,223 --> 00:06:24,629
Now, notice that the mean
uses the precise numerical value

126
00:06:24,829 --> 00:06:26,441
of all the observations
in the sample.

127
00:06:27,232 --> 00:06:29,205
The median, on the other hand,
relies mostly

128
00:06:29,405 --> 00:06:31,137
on the order of the observations.

129
00:06:31,337 --> 00:06:34,437
So generally the mean is a more 
efficient means

130
00:06:34,637 --> 00:06:36,675
of using the data
and will typically be

131
00:06:36,872 --> 00:06:39,910
a  better descriptor 
of the center of the sample.

132
00:06:40,403 --> 00:06:42,599
Then why bother with the median?

133
00:06:42,799 --> 00:06:45,863
The reason is that the mean can
be very sensitive

134
00:06:46,063 --> 00:06:47,917
to the presence 
of extreme observations.

135
00:06:48,710 --> 00:06:51,698
Consider what can happen
if a single observation

136
00:06:51,898 --> 00:06:53,715
stands out far from the rest.

137
00:06:54,423 --> 00:06:56,176
For instance, going back 
to our example

138
00:06:56,376 --> 00:06:58,483
of 5 observations,
suppose we take

139
00:06:58,683 --> 00:07:00,903
the largest observation
and we shift it

140
00:07:01,103 --> 00:07:02,589
to the edge of the axis.

141
00:07:02,789 --> 00:07:06,104
Now the original location 
of the mean provided the location

142
00:07:06,313 --> 00:07:08,296
where this axis
is going to balance

143
00:07:08,496 --> 00:07:10,775
if we've placed 
an equal amount of weight

144
00:07:10,975 --> 00:07:13,074
on each of these observations.

145
00:07:13,274 --> 00:07:16,153
If we shift the largest observation
to the right

146
00:07:16,353 --> 00:07:18,670
then the weight will be shifted
to the right.

147
00:07:18,870 --> 00:07:22,168
So at this point now,
the axis is going to fall down.

148
00:07:22,368 --> 00:07:26,147
This means that we need 
to correspondingly shift the mean

149
00:07:26,347 --> 00:07:28,503
in order to re-balance the axis.

150
00:07:29,498 --> 00:07:33,710
In fact, the further away 
the fifth observation is moved

151
00:07:33,910 --> 00:07:36,963
the further the mean 
is going to be shifted.

152
00:07:37,736 --> 00:07:40,851
The morale is that a single
extreme data point

153
00:07:41,051 --> 00:07:43,694
could completely undermine
the quality of the mean

154
00:07:43,894 --> 00:07:45,973
as a descriptor of the location
of the data set.

155
00:07:48,153 --> 00:07:50,745
In contrast, let's see what happens
to the median.

156
00:07:50,945 --> 00:07:53,921
Let's again take the largest
observation in our sample

157
00:07:54,121 --> 00:07:55,750
and push it to the right.

158
00:07:56,325 --> 00:07:59,155
Now, the original median
was the third observation.

159
00:07:59,355 --> 00:08:02,321
After all, this is exactly 
in the middle of the sample.

160
00:08:02,521 --> 00:08:04,190
There are 2 observations 
to it's left

161
00:08:04,390 --> 00:08:06,137
and 2 observations to it's right.

162
00:08:06,337 --> 00:08:09,674
Having shifted the fifth observation
to the right,

163
00:08:09,874 --> 00:08:12,111
this doesn't really change.

164
00:08:12,311 --> 00:08:14,344
There are still 2 observations
to the left

165
00:08:14,544 --> 00:08:17,762
and then 1, 2 observations
to the right.

166
00:08:18,435 --> 00:08:20,702
The median stays put. 

167
00:08:20,902 --> 00:08:24,976
In fact, no matter how much we push
the largest observation

168
00:08:25,176 --> 00:08:27,755
to the right,
the median will not move.

169
00:08:27,955 --> 00:08:30,372
It remains the middle observation

170
00:08:30,572 --> 00:08:32,787
no matter how much
the extremes are moved around.

171
00:08:33,824 --> 00:08:36,292
In summary, the mean is generally

172
00:08:36,492 --> 00:08:38,315
a more accurate descriptor 
of location

173
00:08:38,569 --> 00:08:40,581
and should be used 
when we are not liable

174
00:08:40,781 --> 00:08:42,230
to having
extreme observations.

175
00:08:43,103 --> 00:08:44,979
The median, on the other hand, 
maybe less efficient

176
00:08:45,251 --> 00:08:46,305
in it's use of it's data,

177
00:08:46,557 --> 00:08:48,653
but could come in useful 
when we expect 

178
00:08:48,887 --> 00:08:51,282
that extreme observations
are likely to arise. 

179
00:08:52,155 --> 00:08:53,989
Now, once we have a notion
of center

180
00:08:54,189 --> 00:08:56,721
for our sample distribution,
we may want to know

181
00:08:56,952 --> 00:08:59,561
how dispersed or concentrated
the sample values are

182
00:08:59,761 --> 00:09:01,044
around that center.

183
00:09:01,836 --> 00:09:04,490
The variance is a natural
descriptor of how dispersed

184
00:09:04,726 --> 00:09:07,566
the sample values are  
around their mean, in particular.

185
00:09:07,766 --> 00:09:11,226
It is defined as the sum
of square differences

186
00:09:11,426 --> 00:09:13,990
of observations 
minus their mean,

187
00:09:14,190 --> 00:09:15,650
suitably renormalized.

188
00:09:15,850 --> 00:09:19,370
It represents 
the average square distance

189
00:09:19,570 --> 00:09:21,929
between a sample value
and the sample mean.

190
00:09:22,129 --> 00:09:24,805
How far is an observation
from the center

191
00:09:25,005 --> 00:09:26,230
of the data set, on average?

192
00:09:26,430 --> 00:09:28,501
Now, for technical reasons,
one often uses

193
00:09:28,701 --> 00:09:32,658
a scaling factor 1 over n minus 1,
instead of 1 over n.

194
00:09:32,858 --> 00:09:34,957
But let's not worry about
that too much.

195
00:09:35,157 --> 00:09:36,386
Now, a draw back of the variance

196
00:09:36,592 --> 00:09:39,012
is that it is not expressed 
in the same units of measurement

197
00:09:39,212 --> 00:09:41,697
as the original variable,
because of the squares.

198
00:09:41,897 --> 00:09:44,902
For instance, if the values x1 to xn
are measured in meters,

199
00:09:45,102 --> 00:09:48,420
their mean is also
measured in meters.

200
00:09:48,620 --> 00:09:50,820
But their variance is measured
in square meters.

201
00:09:51,975 --> 00:09:53,914
The standard deviation
corrects for that

202
00:09:54,114 --> 00:09:56,482
by taking the square root
of the variance.

203
00:09:56,682 --> 00:09:59,149
The 2 notions 
are equally informative

204
00:09:59,349 --> 00:10:01,851
the only difference is a difference
of scale.

205
00:10:02,684 --> 00:10:04,438
To understand variance,
we consider

206
00:10:04,638 --> 00:10:06,515
2 different samples,
each comprised

207
00:10:06,715 --> 00:10:07,817
of 5 observations,

208
00:10:08,017 --> 00:10:11,716
x1 to x5, and y1 to y5.

209
00:10:12,408 --> 00:10:15,510
We arrange these 2 samples
on 2 different axes

210
00:10:15,710 --> 00:10:18,927
from smallest observation
to largest observation

211
00:10:19,127 --> 00:10:20,980
using the order statistics.

212
00:10:21,474 --> 00:10:24,036
We then calculate
their sample means.

213
00:10:25,203 --> 00:10:28,170
Notice that these 2 sample means
are exactly the same.

214
00:10:28,370 --> 00:10:31,054
Still, the 2 samples
are different.

215
00:10:31,254 --> 00:10:34,090
In the first sample, 
the sample observations

216
00:10:34,290 --> 00:10:37,133
are more concentrated 
around their sample mean

217
00:10:37,333 --> 00:10:39,404
than they are in the second sample. 

218
00:10:39,604 --> 00:10:42,930
This means that the first sample
has a smaller variance

219
00:10:43,130 --> 00:10:44,759
than the second sample.

220
00:10:44,959 --> 00:10:48,774
The average deviation of 
the sample observation to it's mean

221
00:10:48,974 --> 00:10:52,981
is higher in the second sample
than it is in the first.

222
00:10:53,976 --> 00:10:56,060
Now, the variance 
could be argued to be

223
00:10:56,260 --> 00:10:58,623
too coarse a measure
for some data sets.

224
00:10:58,823 --> 00:11:02,078
For example, if you look at 
the 2 data sets on my right,

225
00:11:02,278 --> 00:11:06,614
these have the exact same mean
and the have the exact same variance.

226
00:11:06,814 --> 00:11:09,199
But, arguably, the distribution
of their values

227
00:11:09,399 --> 00:11:11,291
on the axis is quite different.

228
00:11:11,491 --> 00:11:13,988
In effect, what's going on
is that they have different

229
00:11:14,188 --> 00:11:16,325
asymmetry relative to their mean.

230
00:11:16,525 --> 00:11:20,072
To distinguish finer characteristics
such as asymmetries,

231
00:11:20,272 --> 00:11:22,493
we define the notion of quantiles.

232
00:11:22,693 --> 00:11:26,598
For any percentage point alpha,
the alpha quantile

233
00:11:26,798 --> 00:11:28,956
is defined to be the smallest
observation

234
00:11:29,156 --> 00:11:33,919
of the sample that exceeds at least
alpha percent of the sample values.

235
00:11:34,119 --> 00:11:37,067
For instance, when the sample
size is odd

236
00:11:37,267 --> 00:11:39,925
the 50% quantile is equal
to the median.

237
00:11:40,125 --> 00:11:44,756
We term the 25%, 50 and 75% 
quantiles

238
00:11:44,956 --> 00:11:48,306
as the first, second
and third quartile.

239
00:11:48,506 --> 00:11:51,168
We partition the axis
into four regions,

240
00:11:51,368 --> 00:11:54,945
each containing roughly
one-fourth of the sample,

241
00:11:55,145 --> 00:11:58,977
that is one quarter of the sample,
hence the name quartile.

242
00:11:59,806 --> 00:12:02,433
Now the quartiles give us
more detailed information

243
00:12:02,633 --> 00:12:04,200
on the dispersion and concentration

244
00:12:04,400 --> 00:12:05,599
properties of the sample.

245
00:12:05,799 --> 00:12:08,218
For instance, they allow us
to appreciate

246
00:12:08,418 --> 00:12:11,144
whether the distribution 
of the sample is symmetric

247
00:12:11,344 --> 00:12:14,168
or asymmetric
around the sample mean.

248
00:12:14,859 --> 00:12:17,783
If the distance between the first
and second quartile

249
00:12:17,983 --> 00:12:19,637
is smaller than 
the distance between

250
00:12:19,837 --> 00:12:21,402
the second and third quartile

251
00:12:21,602 --> 00:12:24,244
then we see that there is 
a right a symmetry.

252
00:12:24,444 --> 00:12:26,919
The second half of the sample
is more spread out

253
00:12:27,119 --> 00:12:28,196
than the first half.

254
00:12:28,396 --> 00:12:30,817
This is the case in the first plot 
on the right.

255
00:12:31,017 --> 00:12:33,246
Conversely, when 
the first and second quartile

256
00:12:33,446 --> 00:12:35,700
are further apart than
second and third one

257
00:12:35,900 --> 00:12:37,552
we have a left symmetry.

258
00:12:37,752 --> 00:12:41,036
If the distance between consecutive
quartiles is roughly the same

259
00:12:41,236 --> 00:12:43,396
then we speak 
of a symmetric distribution.

260
00:12:43,596 --> 00:12:46,945
This is precisely the case
with the last plot on the right.

261
00:12:47,860 --> 00:12:50,418
To conclude this section,
we briefly mention

262
00:12:50,618 --> 00:12:53,209
two more measures of dispersion.

263
00:12:53,409 --> 00:12:57,311
First, the difference between
the first and third quartile.

264
00:12:57,511 --> 00:13:00,269
This is called 
the interquartile range

265
00:13:00,469 --> 00:13:02,837
It can be used to assess
the concentration of the sample

266
00:13:03,037 --> 00:13:05,906
It reveals how concentrated
or spread apart

267
00:13:06,106 --> 00:13:09,157
the middle 50% portion
of the sample is.

268
00:13:09,357 --> 00:13:12,853
Finally, the overall range
or just range

269
00:13:13,053 --> 00:13:14,578
is an even coarser descriptor.

270
00:13:14,778 --> 00:13:18,606
It gives us the length of 
the smallest possible interval

271
00:13:18,806 --> 00:13:20,252
containing the entire sample.

272
00:13:20,452 --> 00:13:23,664
Therefore, it's just a difference 
between the largest observation

273
00:13:23,864 --> 00:13:25,688
and the smallest observation.

