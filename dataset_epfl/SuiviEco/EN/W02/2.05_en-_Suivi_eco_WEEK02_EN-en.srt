1
00:00:09,282 --> 00:00:12,145
Our whole premise is that we will
use a distribution of a statistical

2
00:00:12,235 --> 00:00:15,348
variable at the level of a random
sample in order to understand

3
00:00:15,432 --> 00:00:18,432
the distribution of the variable
on the level of the population.

4
00:00:18,891 --> 00:00:22,079
At the level of the sample a simple
way of visualizing the data

5
00:00:22,186 --> 00:00:24,286
distribution as the histogram.

6
00:00:24,415 --> 00:00:26,978
The height of each bar revealing
the percentage of sample

7
00:00:27,074 --> 00:00:30,074
observations falling inside
the corresponding bin.

8
00:00:31,124 --> 00:00:33,412
Is there a similar device that
we could use to represent

9
00:00:33,508 --> 00:00:36,508
the distribution of
the entire population?

10
00:00:37,971 --> 00:00:40,721
Although, the population is
in principle very large

11
00:00:40,787 --> 00:00:44,299
and we can essentially think of it
as being of infinite size

12
00:00:44,472 --> 00:00:48,872
so if we want to create a histogram
for the population we could try

13
00:00:48,962 --> 00:00:53,575
to use one with a very large
number of very narrow bins.

14
00:00:53,713 --> 00:00:56,813
How many exactly?
As many as possible.

15
00:00:57,644 --> 00:01:00,094
For a discreet variable that
can only take the value zero

16
00:01:00,203 --> 00:01:04,128
zero, one, two, three,
and so on and so forth

17
00:01:04,262 --> 00:01:09,287
each bin would have to correspond
to one of these values exactly.

18
00:01:09,515 --> 00:01:14,290
After all, we can never
take finer bins than these.

19
00:01:14,425 --> 00:01:17,787
For continuous variable on
the other hand there is no limit

20
00:01:17,860 --> 00:01:19,610
to the number of bins we could take

21
00:01:19,717 --> 00:01:22,342
there could be as fine
as we wish them.

22
00:01:22,443 --> 00:01:24,981
So the histogram now
becomes a smooth curve

23
00:01:25,052 --> 00:01:26,977
 as seen in blue on the right.

24
00:01:27,073 --> 00:01:30,123
We can interpret this as
a histogram with infinitely

25
00:01:30,243 --> 00:01:32,930
many minutely fine bins.

26
00:01:33,031 --> 00:01:35,993
In either case, continuous or
discreet we speak of

27
00:01:36,114 --> 00:01:38,764
the population distribution.

28
00:01:38,979 --> 00:01:41,304
In many cases we can actually
describe the population

29
00:01:41,403 --> 00:01:44,853
distribution by closed form
mathematical formula.

30
00:01:45,088 --> 00:01:47,775
having such a formula for
a population allows us to

31
00:01:47,873 --> 00:01:50,523
better interpret the form
of the distribution.

32
00:01:50,639 --> 00:01:54,489
Just as in physics, a formula reveals
a physical law of the phenomenon

33
00:01:54,593 --> 00:01:57,881
under study so does it
reveal the law governing

34
00:01:57,997 --> 00:02:00,110
the population distribution.

35
00:02:00,180 --> 00:02:02,868
This is why the population
model formula is often

36
00:02:02,940 --> 00:02:05,428
called the law of the population.

37
00:02:05,738 --> 00:02:08,500
Population models usually
depend on parameters that allow

38
00:02:08,585 --> 00:02:12,160
us to fine tune the model
to the population at hand.

39
00:02:12,246 --> 00:02:15,246
Some examples of laws that
are very often included in practice

40
00:02:15,327 --> 00:02:18,789
are the normal distribution,
the exponential distribution

41
00:02:18,904 --> 00:02:21,204
and the Poisson distribution.

42
00:02:21,287 --> 00:02:23,787
let's consider these
in a bit more detail.

43
00:02:24,141 --> 00:02:27,829
The normal distribution is a law
for continuous random variables.

44
00:02:27,918 --> 00:02:30,856
It's formula tells us that
the distribution is symmetric

45
00:02:30,925 --> 00:02:34,337
around a certain value μ.

46
00:02:34,441 --> 00:02:36,453
Changing the value of μ shifts

47
00:02:36,545 --> 00:02:38,833
the location of the peak
of the distribution.

48
00:02:38,932 --> 00:02:44,032
For instance, this one has μ
equal to zero, whereas this one

49
00:02:44,119 --> 00:02:47,419
has μ approximately equal to -2.

50
00:02:48,367 --> 00:02:53,929
changing the value of σ squared
will actually compress or stretch

51
00:02:54,049 --> 00:02:57,674
the distribution, so for example
the distribution in blue

52
00:02:57,794 --> 00:03:02,019
has a lower σ squared value
than the distribution in red.

53
00:03:02,122 --> 00:03:05,284
The exact values are
given on the top right.

54
00:03:06,278 --> 00:03:09,278
The normal distribution is one
of the most important models

55
00:03:09,440 --> 00:03:13,028
as it describes extremely
large variety of situations.

56
00:03:13,424 --> 00:03:16,261
The exponential distribution
is a law for continuous

57
00:03:16,371 --> 00:03:19,659
random variables that
take on only positive values.

58
00:03:19,895 --> 00:03:24,032
It usually models variables that
represent the time until some event.

59
00:03:24,226 --> 00:03:26,914
The lifetime of a battery
for an example.

60
00:03:27,065 --> 00:03:30,565
It's formula depends on
a positive parameter λ.

61
00:03:30,665 --> 00:03:33,115
This parameter is called the rate.

62
00:03:33,181 --> 00:03:36,006
It actually controls how
likely it is to observe

63
00:03:36,111 --> 00:03:39,324
larger values of
the variable of time.

64
00:03:39,913 --> 00:03:43,051
For a large value of λ,
the distribution concentrates

65
00:03:43,147 --> 00:03:47,334
around zero, such is the case
of the curve in green.

66
00:03:47,877 --> 00:03:50,852
On the other hand,
for small values of λ

67
00:03:50,949 --> 00:03:54,662
the distribution tails off more
slowly, such is the case with

68
00:03:54,764 --> 00:03:57,352
the curve in blue.

69
00:03:57,842 --> 00:04:01,129
The Poisson distribution is a law
for discreet random variables

70
00:04:01,267 --> 00:04:06,154
taking the value zero, one, two,
three, and so on, and so forth.

71
00:04:06,261 --> 00:04:09,261
It is typically used when
considering the statistical variables

72
00:04:09,397 --> 00:04:14,159
that count occurrences, for instance
the number of bacteria in a bottle

73
00:04:14,242 --> 00:04:18,029
of pasteurized milk could be
modeled by a Poisson distribution.

74
00:04:18,696 --> 00:04:22,446
This distribution also depends on
a single parameter λ.

75
00:04:22,676 --> 00:04:27,126
This is also a positive parameter
and it controls how large or small

76
00:04:27,261 --> 00:04:30,198
the values of the variable
will typically be.

77
00:04:30,431 --> 00:04:34,656
Small values of λ will concentrate
the distribution close to zero

78
00:04:34,770 --> 00:04:38,795
while larger values will shift it to
the right, widen it, and make it

79
00:04:38,917 --> 00:04:43,392
look more symmetric, for instance
on the left we see what the Poisson

80
00:04:43,465 --> 00:04:46,953


81
00:04:43,482 --> 00:04:46,407
distribution of λ
equals one looks like.

82
00:04:46,459 --> 00:04:50,071
Clearly, we have the zero and one
are the more likely values

83
00:04:50,159 --> 00:04:52,734
and then the proportions
of different values tail off

84
00:04:52,817 --> 00:04:54,517
rather quickly.

85
00:04:54,630 --> 00:04:59,142
For the larger value of λ equals 2.5
we see that the distribution is 

86
00:04:59,270 --> 00:05:03,682
shifted more to the right likely
values now are bigger values

87
00:05:03,793 --> 00:05:07,081
and it appears that we have
more of a symmetric pattern.

88
00:05:08,061 --> 00:05:11,736
But how do we calculate proportions
with these population models?

89
00:05:11,927 --> 00:05:15,602
In the case of discreet variable,
the answer is quite simple

90
00:05:15,675 --> 00:05:18,675
just as with the histogram.

91
00:05:18,942 --> 00:05:22,204
In the case of the continuous
variable though, our distribution

92
00:05:22,318 --> 00:05:24,868
model is given by a curve.

93
00:05:24,964 --> 00:05:27,489
Now we can choose any
arbitrary interval that

94
00:05:27,595 --> 00:05:30,107
we wish, for example the interval I.

95
00:05:30,198 --> 00:05:33,298
We could ask, what proportion of
population has variable values

96
00:05:33,410 --> 00:05:35,760
contained in the interval I?

97
00:05:35,896 --> 00:05:40,558
the answer is that this proportion
should be given by the area

98
00:05:40,681 --> 00:05:44,744
under the curve delineated by
the interval end points.

99
00:05:44,861 --> 00:05:49,599
What this means is that we need to
draw vertical lines at the interval

100
00:05:49,694 --> 00:05:55,407
end points, and then find what area
is contained between these two lines

101
00:05:55,528 --> 00:05:58,741
the axis and the curve.

102
00:05:56,880 --> 00:05:59,880


103
00:05:58,837 --> 00:06:02,400
This is going to give us
the proportion of population values

104
00:06:02,521 --> 00:06:05,296
contained in I.

105
00:06:06,875 --> 00:06:11,050
Just as we defined notion such as
the mean, median, variants

106
00:06:11,132 --> 00:06:15,045
and quantiles of a sample
distribution so can we also

107
00:06:15,172 --> 00:06:17,260
do in the case of
the population model.

108
00:06:17,359 --> 00:06:19,772
Now we will not give
precise definitions

109
00:06:19,871 --> 00:06:22,559
but we will simply note that all
theses quantities can be obtained

110
00:06:22,628 --> 00:06:25,991
using the mathematical formula
for the population model.

111
00:06:26,128 --> 00:06:28,828
The key aspect is to
highlight that all these

112
00:06:28,927 --> 00:06:32,127
concepts will now depend on
the unknown parameter.

113
00:06:32,278 --> 00:06:34,541
It will be functions
of the parameter

114
00:06:34,641 --> 00:06:37,728
since the population curve changes
as the parameter changes

115
00:06:37,835 --> 00:06:39,660
it's numerical summaries must also

116
00:06:39,756 --> 00:06:42,593
change as a function
of the parameter.

117
00:06:42,749 --> 00:06:46,399
Now, some of these functions may
not have explicit formulas

118
00:06:46,475 --> 00:06:49,838
but others do, so here's some key
numerical summaries for

119
00:06:49,910 --> 00:06:52,060
the three models we saw earlier.

120
00:06:52,207 --> 00:06:55,794
For the Poisson distribution
the mean is equal to the variants

121
00:06:55,885 --> 00:06:58,885
which in turn is equal to
the parameter λ.

122
00:06:59,486 --> 00:07:03,249
For the exponential distribution,
the mean is equal to the inverse

123
00:07:03,369 --> 00:07:07,994
of λ, whereas the variant is equal
to one divided by λ squared. 

124
00:07:08,221 --> 00:07:11,221
We even have a formula for
the α percent quantile

125
00:07:11,352 --> 00:07:13,190
which is given to my right.

126
00:07:13,317 --> 00:07:16,042
In the normal distribution
the mean equals the median

127
00:07:16,158 --> 00:07:17,621
and equals μ.

128
00:07:17,735 --> 00:07:20,347
The variants equal to σ squared.

129
00:07:20,479 --> 00:07:22,579
The quantiles of the normal
distribution do not have

130
00:07:22,684 --> 00:07:26,346
the simple closed formula, but
there is one very important property

131
00:07:26,435 --> 00:07:28,672
that we will now mention.

132
00:07:28,818 --> 00:07:32,855
Whatever the value of the mean
parameter μ and the various

133
00:07:32,948 --> 00:07:35,098
parameter σ squared might be

134
00:07:35,212 --> 00:07:38,012
the following statements
will always remain true.

135
00:07:38,236 --> 00:07:41,574
First of all, the proportion
of population values within

136
00:07:41,663 --> 00:07:47,476
one standard deviation of the mean,
is always equal to 68%.

137
00:07:48,485 --> 00:07:52,110
On the other hand, the proportion
of population values within two

138
00:07:52,217 --> 00:07:57,742
standard deviations of the mean,
is always equal to 95%.

139
00:07:57,928 --> 00:08:01,378
Finally, the proportion of
population values within three

140
00:08:01,499 --> 00:08:06,462
standard deviations of the mean,
is always equal to 99%.

141
00:08:08,096 --> 00:08:11,096
So what we're having in population
how do we know what is a good

142
00:08:11,231 --> 00:08:13,456
model to use as it's law?

143
00:08:13,593 --> 00:08:16,893
This choice is often based on
prior information as well as

144
00:08:16,981 --> 00:08:20,906
first principles, for instance,
it is known that some populations

145
00:08:21,009 --> 00:08:24,296
have properties that uniquely
correspond to a given model

146
00:08:24,383 --> 00:08:27,171
and so that is the model
that should be chosen.

147
00:08:27,298 --> 00:08:29,048
Other times we know
that the certain model is

148
00:08:29,133 --> 00:08:30,546
a good approximation for a wide

149
00:08:30,642 --> 00:08:33,642
variety of phenomena
with some characteristics.

150
00:08:33,836 --> 00:08:37,311
Sometimes, a model is not
motivated by the first principles

151
00:08:37,394 --> 00:08:41,256
or mathematical theory, but by
extensive practical experience.

152
00:08:41,396 --> 00:08:45,083
We simply know that this model
has been successful in the past.

153
00:08:45,198 --> 00:08:50,123
In some cases, when we have selected
a model, but the exploratory graphical

154
00:08:50,201 --> 00:08:53,801
numerical analysis of the sample
might reveal the features of this

155
00:08:53,886 --> 00:08:57,274
model are not compatible
with the sample's structure.

156
00:08:57,368 --> 00:09:00,880
This means, that we may
need to reconsider or modify

157
00:09:00,995 --> 00:09:02,795
our initial choice of model.

158
00:09:02,881 --> 00:09:06,069
This interplay between modeling
principles and exploratory

159
00:09:06,150 --> 00:09:09,925
analysis is what statisticians
call model selection.

160
00:09:10,022 --> 00:09:11,897
Luckily for many standard problems

161
00:09:11,995 --> 00:09:13,732
there exists a models
who's appropriateness

162
00:09:13,832 --> 00:09:16,982
has been established by both
mathematical investigation

163
00:09:17,068 --> 00:09:19,481
and practical experience.

164
00:09:19,582 --> 00:09:23,445
The powerful thing about a model
is that it allows us to calculate

165
00:09:23,537 --> 00:09:26,000
everything we need to
know about a population

166
00:09:26,082 --> 00:09:29,220
provided that we know the value
of the parameter it depends on.

167
00:09:29,774 --> 00:09:32,112
This value is typically
unknown unfortunately

168
00:09:32,215 --> 00:09:34,940
but luckily we have our sample. 

169
00:09:35,047 --> 00:09:39,547
The problem of statistical inference
is to use out sample in as best

170
00:09:39,635 --> 00:09:42,048
of ways possible in order to inform

171
00:09:42,134 --> 00:09:45,134
ourselves about true
value of this parameter.

172
00:09:45,368 --> 00:09:47,218
Once we can say something
about this parameter

173
00:09:47,333 --> 00:09:51,483
we can answer any question we want
about the population distribution.

174
00:09:51,980 --> 00:09:55,430
The triple of statistical inference
questions one typically wishes

175
00:09:55,527 --> 00:09:56,827
to answer are

176
00:09:56,973 --> 00:09:58,923
first, point estimation

177
00:09:59,043 --> 00:10:01,693
determine the precise value
of the unknown parameter

178
00:10:01,824 --> 00:10:06,274
and quantify how far off we
might be in doing so on average

179
00:10:06,370 --> 00:10:10,432
secondly, interval estimation,
given interval of plausible

180
00:10:10,519 --> 00:10:13,432
values for the parameter
will quantify the chance that

181
00:10:13,498 --> 00:10:16,061
this would contain the true value

182
00:10:16,164 --> 00:10:19,414
finally, hypothesis testing,
determine whether a certain 

183
00:10:19,473 --> 00:10:22,661
hypothesized value or range of
values for the parameter

184
00:10:22,779 --> 00:10:26,417
is compatible or not with
a sample that we observe

185
00:10:26,478 --> 00:10:28,366
and also determine the chance of

186
00:10:28,454 --> 00:10:31,954
making a mistake in
this determination.

