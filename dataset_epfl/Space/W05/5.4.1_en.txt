We're talking about the reliability of the space systems and we'll touch also the subject of human rating for human spaceship like a Space Shuttle.
Now a few definitions first.
<i>R(t)</i> is a probability that the system will not fail in the interval <i>(0,t)</i>.
And we have two important concepts.
The <i>MTTF</i>, Mean Time To Failure.
It's the time until the first failure of a given system.
The mean time between failures is the average time between two consecutive failures of a given system.
The failure rate <i>Î»(t)</i> is reciprocal of the <i>MTBF</i> in <i>hours to the power -1</i> or <i>months to the power -1</i>.
And the probability of failure
<i>Î»(t)dt</i> is a probability that the system will fail between <i>t</i> and <i>t+dt</i> knowing that it still works at time <i>t</i>.
Let's do now some simple development to find the value of <i>rt</i>, the reliability of time <i>t</i> as a function of the time and of the failure rate <i>Î»</i>.
Now we'll consider that <i>Î»</i> is a constant and not depending on time.
Now this is a simplification.
It may not be the case always but in this simple development, that's what we'll assume.
And it's going to be in
<i>hours to the power -1</i> or possibly <i>years</i> but <i>hours</i> or <i>months</i>.
Let's look at reliability-- at time <i>(t+dt)</i>.
It's going to be equal to the reliability at <i>(t)</i> and we factor here <i>[1 - Î»dt]</i>.
Now this follows from the definition of these various components.
So we can rewrite this as <i>R(t+dt) - R(t),</i> time derivative of this is equal to
<i>-R(t) Î»</i> constant <i>Î»</i> not depending on time.
So it follows from that that <i>R(t)</i>, the reliability of time <i>(t)</i> is equal to <i>exp (-Î»t)</i>.
And we'll give an example in a second.
We saw before that <i>MTBF</i> of the mean time between the failures is the reciprocal of the failure rate.
And let's take an example here where we have <i>MTBF</i> of 30 months, 30 months on the average between two failures of a given system.
Following what we have been developing before, we have the probability of the proper functioning of the processor.
Let's say the system is a processor.
After two years or 24 months, it's going to be--
<i>e to the power minus 24 over 30</i>, which is about <i>0.45</i>.
So again, if we have this very simple case where we have one system only and a failure rate independent of time, we can determine the probability that the system is still alive after a certain time, or between two given times in the life of the system.
Now the reality is more complex and I will let you make further development if you feel like doing it or deepen the subject, but that's a a basic for a relatively simple case.
Now let me say a few words about human rating.
Obviously if you have a given spaceship or rocket like Ariane 5, and it's used to launch a satellite, and at some point you want to make it launch a human spacecraft, like was the plan a couple of decades ago with ESA that wanted to develop the so-called Hermes Project.
It would have been a small manned spaceship on top of Ariane 5.
It would have been needed to man rate the Ariane 5 rockets, which was not-- which is not now because Hermes was abandoned and this effort of man rating
Ariane 5 was not completed.
Let me say a few words about human rating of the Space Shuttle, some of the features that make it adequate to carry humans to orbit.
There is this principle of two failure tolerance: fail operational, fail safe.
If you have a system, whether it's inertial measurement unit or whether it's a fuel cell to generate electricity on board the Shuttle, you want to have a system such that if you have one of a redundant set of systems, one that fails, you can still do the mission if you have a second that failed, it can still save the spaceship and the crew.
In fact in the case of the Shuttle the two were equivalent because there was no escape system for the crew.
Two-failure tolerance: fail operational, fail safe.
One system fail, you are still okay to do the mission although you might decide to maybe shorten it or do only part of the mission objective.
If you have a second failure in a redundant set, than you are okay to save the crew and save the spaceship.
That's a very important principle.
Now another one is no single crew error will lead to a catastrophic event.
A catastrophic event is a loss of the spaceship and a loss of the crew.
So the whole system has to be developed in the crew interface with a spaceship so that this criteria is satisfied.
No single crew error lead to a catastrophic event.
Now obviously, there's quality build and quality control.
There was a lot of quality control of all of the components of the Shuttle and during the build or any modification.
Quality control, I wouldn't say make it sure that nothing will happen but at least it reduces significantly the likelihood that a human error in any modification or in the design will lead to a catastrophic event.
A lot of inspections also.
And the last item is <i>FMEA</i>,
Failure Modes and Effects Analysis.
This is a pretty thick book at that time because it was not really on a computer folder.
Now it will be on a computer folder but in the early 90s it was in a book,
Failure Modes and Effects Analysis.
Engineers looked at all possible failures and looking at the effect of these failures on the operation of the Space Shuttle and the safety of the crew and of the spaceship itself.
And the idea was to try to mitigate the danger and try to design one way to still save ourselves despite these failures.
So this was a very important effort.
And it is a case for any major human-rated spaceship.
<i>FMEA</i> is an important document or set of guidelines and restrictions that have to be produced by the designer and the constructor of the vehicle.
