1
00:00:05,330 --> 00:00:08,954
I’ll now be talking to you
about a core piece 

2
00:00:09,239 --> 00:00:11,612
of the neuroinformatics
platform

3
00:00:11,860 --> 00:00:14,017
which is the knowledge
graph.

4
00:00:14,661 --> 00:00:17,489
And the knowledge
graph is really built

5
00:00:17,705 --> 00:00:20,678
at it’s core on
a provenance data model

6
00:00:20,912 --> 00:00:22,516
And what is provenance?

7
00:00:22,516 --> 00:00:25,204
Why is that important?

8
00:00:25,646 --> 00:00:29,577
So, provenance is really
meta data about the origin

9
00:00:29,797 --> 00:00:31,937
and the transformation
of the data.

10
00:00:31,937 --> 00:00:33,017
Where did the data
come from

11
00:00:33,017 --> 00:00:35,953
and what has happened
to it all along

12
00:00:35,953 --> 00:00:37,674
the way as you
cleaned it up,

13
00:00:37,674 --> 00:00:40,656
You removed artifacts,
you normalized it

14
00:00:40,938 --> 00:00:45,602
you maybe transformed
it to a specific

15
00:00:45,602 --> 00:00:47,751
set of units and you
did an analysis.

16
00:00:47,954 --> 00:00:49,422
That’s provenance.

17
00:00:49,422 --> 00:00:52,424
Keeping track of all those
things you did to the data.

18
00:00:52,629 --> 00:00:56,047
It also can be used to keep
track of who produced

19
00:00:56,282 --> 00:00:59,221
the data and who performed
those transformations.

20
00:00:59,221 --> 00:01:02,144
So, is the data
actually derived?

21
00:01:02,406 --> 00:01:04,986
is it a derivation,
is it some transformation

22
00:01:05,188 --> 00:01:06,830
of a previous data set?

23
00:01:07,047 --> 00:01:09,249
Well, which data set
is it coming from?

24
00:01:09,474 --> 00:01:11,375
Where is the raw
data that led to it?

25
00:01:11,578 --> 00:01:13,741
And what of those
specific processes

26
00:01:13,741 --> 00:01:15,578
or analyses,
or transformations

27
00:01:15,835 --> 00:01:17,800
that were used to
produce the data?

28
00:01:18,051 --> 00:01:21,407
And specifically
keeping track of that.

29
00:01:21,671 --> 00:01:23,565
Which software
and version

30
00:01:23,783 --> 00:01:25,257
for example,
were used?

31
00:01:25,610 --> 00:01:27,922
And all of this
is important

32
00:01:28,156 --> 00:01:31,800
because it enables
reproducibility.

33
00:01:32,001 --> 00:01:33,484
It supports it,
it doesn’t guarantee it

34
00:01:33,843 --> 00:01:35,658
but it certainly
is an important

35
00:01:35,874 --> 00:01:39,048
part of the process of making
science reproducible.

36
00:01:39,314 --> 00:01:42,242
Documenting the steps
involved in the data production.

37
00:01:42,242 --> 00:01:46,551
Being transparent,
providing a clear trail

38
00:01:46,766 --> 00:01:49,863
of the data sources
involved in an analysis.

39
00:01:50,203 --> 00:01:52,489
Helping to improve trust

40
00:01:52,489 --> 00:01:55,504
in an analysis and
in the data it self

41
00:01:55,504 --> 00:01:58,687
by giving a clear audit
of the origins of the data.

42
00:01:59,397 --> 00:02:04,147
Also, to help discover things,
like methods and software

43
00:02:04,147 --> 00:02:08,423
that would be useful to
applying to similar data sets.

44
00:02:08,689 --> 00:02:10,922
Also, finding related
data sets.

45
00:02:11,569 --> 00:02:14,665
And finally,
in providing attribution

46
00:02:14,871 --> 00:02:17,376
And this is really important
in ultimately building up

47
00:02:17,623 --> 00:02:22,241
a global culture of data
sharing in neuro science

48
00:02:22,445 --> 00:02:26,102
Making sure that credit is
given to all of those involved.

49
00:02:26,466 --> 00:02:29,694
Not just in producing data,
but to all of those who

50
00:02:29,901 --> 00:02:32,149
produced the analysis and
who produced the software

51
00:02:32,352 --> 00:02:33,278
to perform the analysis.

52
00:02:33,278 --> 00:02:38,479
All of the participants in
producing a final data set

53
00:02:38,479 --> 00:02:42,713
or figure can be captured
in the data provenance.

54
00:02:43,351 --> 00:02:46,992
So, W3C, the World Wide
Web Consortium

55
00:02:47,335 --> 00:02:49,781
has actually developed
a provenance standard

56
00:02:49,781 --> 00:02:52,272
and this is what we built
the knowledge graph off of.

57
00:02:52,554 --> 00:02:56,900
And this really has
a number of key properties.

58
00:02:56,900 --> 00:02:58,522
But first of all,
there is the entity

59
00:02:58,522 --> 00:03:01,060
which would be for
example, a data set.

60
00:03:01,481 --> 00:03:04,431
But, where was
it coming from?

61
00:03:04,431 --> 00:03:08,184
Is it derived
from something?

62
00:03:08,184 --> 00:03:10,794
How was it produced?

63
00:03:10,794 --> 00:03:14,262
Which activity actually
produced it and who

64
00:03:14,262 --> 00:03:16,915
or what software
actually generated it?

65
00:03:16,915 --> 00:03:19,442
So, the agent is
the who or the what

66
00:03:19,442 --> 00:03:19,482
the activity is the how
and the entity
So, the agent is
the who or the what

67
00:03:19,482 --> 00:03:21,987
the activity is the how
and the entity

68
00:03:22,248 --> 00:03:25,989
is the data itself what
was actually produced.

69
00:03:26,426 --> 00:03:28,751
And this is the pattern
that then you extend

70
00:03:29,034 --> 00:03:32,127
these to be specific
to different

71
00:03:32,127 --> 00:03:35,519
experimental conditions
and different types of context

72
00:03:35,819 --> 00:03:38,686
to fully provide
characterization

73
00:03:38,952 --> 00:03:42,227
of the data
and its provenance.

74
00:03:43,053 --> 00:03:47,000
One example of a W3C Prov.
Data Model

75
00:03:47,347 --> 00:03:51,487
was developed in
the INCF task force

76
00:03:51,703 --> 00:03:53,579
for neuroimaging
data sharing

77
00:03:53,844 --> 00:03:56,233
and they developed
the neuroimaging data model.

78
00:03:56,562 --> 00:03:59,940
And this was the data
model that really could

79
00:03:59,940 --> 00:04:03,692
keep track of all of the details,
from acquisition details

80
00:04:03,968 --> 00:04:07,504
describing the raw data,
the analysis

81
00:04:07,780 --> 00:04:11,285
the workflows applied
to derived data

82
00:04:11,545 --> 00:04:14,113
and ultimately to
the publications.

83
00:04:14,389 --> 00:04:18,079
And the idea is to support
access and search

84
00:04:18,079 --> 00:04:21,361
of imaging data that’s
been annotated with

85
00:04:21,438 --> 00:04:23,545
the neuroimaging
data model through

86
00:04:23,810 --> 00:04:25,578
common API and databases.

87
00:04:26,080 --> 00:04:27,500
This is something
that’s been developed

88
00:04:27,764 --> 00:04:29,606
it’s being integrated
into many

89
00:04:29,606 --> 00:04:31,896
neuroimaging tools
and we’d like to see

90
00:04:32,121 --> 00:04:34,328
that become
commonly used.

91
00:04:34,826 --> 00:04:37,513
The knowledge graph
is really something

92
00:04:37,513 --> 00:04:40,325
also build on the W3C
provenance standard.

93
00:04:40,574 --> 00:04:41,951
So, it can integrate,
for example

94
00:04:42,216 --> 00:04:43,615
the neuroimaging
data model

95
00:04:44,142 --> 00:04:45,672
because it is based
on the same

96
00:04:45,892 --> 00:04:47,359
underlying
metadata model.

97
00:04:47,575 --> 00:04:51,795
But it is provenance based,
semantic metadata catalog.

98
00:04:52,061 --> 00:04:56,064
It gives really a way to keep
track of neuroscience data,

99
00:04:56,064 --> 00:04:58,639
models and literature.

100
00:04:58,941 --> 00:05:01,247
It’s at the heart
of the human

101
00:05:01,247 --> 00:05:02,955
brain project
neuroinformatics

102
00:05:03,156 --> 00:05:05,828
platform, as well
as Blue Brain's

103
00:05:06,028 --> 00:05:07,733
processes for
keeping track

104
00:05:07,733 --> 00:05:09,284
of data for data
driven modeling.

105
00:05:09,505 --> 00:05:12,604
It’s W3C provenance
standard compliant

106
00:05:12,897 --> 00:05:15,573
and it really provides a way
to track, for example

107
00:05:15,777 --> 00:05:17,576
the specimen,
the samples of specimen

108
00:05:19,108 --> 00:05:21,296
in terms of potential
brain slices,

109
00:05:21,655 --> 00:05:25,319
the specific
experimental protocols

110
00:05:25,719 --> 00:05:27,358
and the extracted data

111
00:05:27,562 --> 00:05:29,847
as well as the models
built from that data.

112
00:05:30,705 --> 00:05:33,967
So, by building up
a graph that captures

113
00:05:33,967 --> 00:05:35,207
all of those relationships

114
00:05:35,453 --> 00:05:39,188
as well as the semantic
annotations

115
00:05:39,691 --> 00:05:40,609
and we’ll get to

116
00:05:40,894 --> 00:05:42,189
the ontologies in
another session

117
00:05:42,189 --> 00:05:45,800
But, talking
about consistently

118
00:05:45,800 --> 00:05:49,298
labeling the specimen
with controlled vocabulary

119
00:05:49,563 --> 00:05:51,786
and making it possible
to search through

120
00:05:51,786 --> 00:05:54,863
what was the software,
who were the people

121
00:05:55,063 --> 00:05:56,332
and what were
the techniques

122
00:05:56,332 --> 00:05:57,985
used to produce
this data.

123
00:05:57,985 --> 00:06:00,928
It provides a very rich
annotation for data

124
00:06:00,928 --> 00:06:04,053
and finding, for example,
related data sets

125
00:06:04,053 --> 00:06:06,565
such as an individual
cell morphology

126
00:06:06,829 --> 00:06:10,172
Was it from a slice,
from which there is

127
00:06:10,392 --> 00:06:11,975
also electrophysiological
data?

128
00:06:12,191 --> 00:06:14,175
And you can find those
links between them.

129
00:06:14,626 --> 00:06:16,612
And that’s very
important for supporting

130
00:06:16,612 --> 00:06:18,024
the modeling process.

131
00:06:18,298 --> 00:06:21,283
So, in this session,
you’ve learned about

132
00:06:21,283 --> 00:06:23,908
the use of provenance
information and its importance.

133
00:06:23,908 --> 00:06:26,789
I’ve talked about the W3C
provenance standard

134
00:06:27,002 --> 00:06:29,473
and described to you
the knowledge graph

135
00:06:29,473 --> 00:06:31,844
which is really this
provenance based semantic

136
00:06:31,844 --> 00:06:35,195
metadata catalog necessary
for searching data

137
00:06:35,195 --> 00:06:37,723
but also finding key
relationships between

138
00:06:37,723 --> 00:06:40,786
the data and
the data producers.

