1
00:00:05,212 --> 00:00:08,358
Okay, so let's look now at some
of the principles.

2
00:00:08,558 --> 00:00:12,156
What are the principles on which
simulation neuroscience rests?

3
00:00:12,356 --> 00:00:16,332
So, the first important principle

4
00:00:16,532 --> 00:00:22,794
is that we have to do dense
reconstructions

5
00:00:23,030 --> 00:00:25,927
dense, very detailed reconstructions

6
00:00:26,127 --> 00:00:28,532
and we have to do it
from sparse data.

7
00:00:28,732 --> 00:00:35,638
Ok, so, I just gave you an idea,
a glimpse

8
00:00:35,838 --> 00:00:39,034
at how much data there really
is to measure.

9
00:00:39,234 --> 00:00:41,859
And if anybody has
to do a calculation you will realize

10
00:00:42,056 --> 00:00:45,165
that it would take the entire
human race,

11
00:00:45,365 --> 00:00:48,527
thousands of years if you wanted
to map out all of those things

12
00:00:48,727 --> 00:00:51,149
in all of those
different connotations.

13
00:00:51,349 --> 00:00:54,229
So, we will forever
have sparse data.

14
00:00:54,429 --> 00:00:57,886
No matter how much data
we collect, it will forever

15
00:00:58,086 --> 00:01:01,610
be sparse in terms of experimental.

16
00:01:01,810 --> 00:01:03,795
So, the problem we have to solve

17
00:01:04,025 --> 00:01:07,017
is how do we get a complete picture

18
00:01:07,217 --> 00:01:08,508
from sparse data.

19
00:01:08,708 --> 00:01:13,491
So, the first principle of simulation
neuroscience

20
00:01:13,701 --> 00:01:18,222
is we have to establish the strategy
from going to a little bit of data

21
00:01:18,422 --> 00:01:24,687
to using whatever knowledge we have
of how the pieces fit together

22
00:01:24,887 --> 00:01:30,405
to build algorithms
and algorithmically build the circuit.

23
00:01:30,605 --> 00:01:37,030
Now, this first principle is not
a new principle.

24
00:01:37,230 --> 00:01:41,997
It is extremely old, it is the basis,
actually, of our entire society today

25
00:01:42,197 --> 00:01:44,861
of information
and communication technologies.

26
00:01:45,061 --> 00:01:50,597
Let me try and explain
this in another way.

27
00:01:50,797 --> 00:01:55,806
Imagine that you have a TV screen

28
00:01:57,843 --> 00:01:58,505
Okay?

29
00:01:58,771 --> 00:02:01,346
And the channel is unplugged.

30
00:02:01,601 --> 00:02:04,088
So, it is a white noise.

31
00:02:04,285 --> 00:02:08,797
So, basically every pixel
is independent

32
00:02:08,995 --> 00:02:10,383
of every pixel.

33
00:02:10,691 --> 00:02:12,352
Okay?

34
00:02:12,552 --> 00:02:16,862
And now I want to transmit
this image to you.

35
00:02:17,062 --> 00:02:19,924
I want to tell you what
is this image.

36
00:02:20,124 --> 00:02:23,923
I need to give you a complete
picture of what this image is.

37
00:02:24,134 --> 00:02:29,413
Based on Claude Shannon's work
from the 40s

38
00:02:29,613 --> 00:02:31,975
we know the theory here

39
00:02:32,232 --> 00:02:33,407
It is very clear.

40
00:02:33,625 --> 00:02:39,329
I have to measure
if this is a random system. 

41
00:02:40,191 --> 00:02:43,241
If this is a random image
or a random system

42
00:02:43,441 --> 00:02:46,441
I have to measure every single pixel.

43
00:02:46,408 --> 00:02:51,089
That is I have no way out,
but to measure every pixel

44
00:02:51,289 --> 00:02:55,138
if I wanna tell you about
this complete story here

45
00:02:55,354 --> 00:02:56,466
Okay?

46
00:02:56,682 --> 00:02:59,277
But it is only if I have
a random system.

47
00:02:59,476 --> 00:03:02,476
If I now have an organized system

48
00:03:03,049 --> 00:03:07,323
where there is a very clear structure

49
00:03:07,562 --> 00:03:11,604
the theory shows you absolutely
clearly

50
00:03:11,804 --> 00:03:14,804
that I don't need
to transmit every pixel

51
00:03:15,004 --> 00:03:18,935
to here, I don't need to transmit
every single pixel,

52
00:03:19,135 --> 00:03:22,135
I don't have to tell you
what every pixel is here

53
00:03:22,335 --> 00:03:24,958
because there are relationships
between all these pixels

54
00:03:25,158 --> 00:03:27,808
and it is the basis
of image compression.

55
00:03:28,034 --> 00:03:31,272
So, this is order.

56
00:03:34,235 --> 00:03:38,381
So, in this case if I have
a random system

57
00:03:38,581 --> 00:03:41,104
I don't need any intelligence,

58
00:03:41,405 --> 00:03:44,431
I just have to copy
these pixels across.

59
00:03:44,631 --> 00:03:47,973
So, I don't need an algorithm here.

60
00:03:48,173 --> 00:03:49,215
Okay?

61
00:03:49,415 --> 00:03:53,074
I don't need an algorithm, I just
need to transfer the data.

62
00:03:53,274 --> 00:03:57,323
But if I have the order
in the system

63
00:03:57,522 --> 00:04:00,299
I need a rule how to rebuild it

64
00:04:00,499 --> 00:04:03,499
if I am going to send a few
of these pixels across

65
00:04:03,696 --> 00:04:08,176
and I want to rebuild this picture.

66
00:04:08,376 --> 00:04:10,100
I need an algorithm.

67
00:04:10,310 --> 00:04:12,390
Okay?

68
00:04:12,590 --> 00:04:16,497
I need some rule that will rebuild
the relationships

69
00:04:16,697 --> 00:04:17,959
that are in this picture.

70
00:04:18,160 --> 00:04:22,901
Okay, so in a way with a random
system I need to measure everything

71
00:04:23,101 --> 00:04:26,992
and I do it blindly, I don't
understand anything,

72
00:04:27,192 --> 00:04:29,854
I just have to copy it
from here to here.

73
00:04:30,062 --> 00:04:33,469
In an ordered system I have
to understand order.

74
00:04:33,669 --> 00:04:36,331
And I have to package it into
an algorithm.

75
00:04:36,531 --> 00:04:39,531
Then I can send it to you 
and I can reconstruct it.

76
00:04:40,825 --> 00:04:48,222
Basically, the important message
is that dense reconstructing

77
00:04:48,422 --> 00:04:50,134
from sparse data

78
00:04:50,330 --> 00:04:54,306
is not just because we have to,
because we forever have sparse data

79
00:04:54,506 --> 00:04:57,368
it is because it is science.

80
00:04:57,688 --> 00:05:01,317
It is actually not scientific to say
that we need to go and measure

81
00:05:01,517 --> 00:05:03,041
everything in the brain.

82
00:05:03,287 --> 00:05:08,698
Okay? Only if it is a random system
do we need to measure every pixel.

83
00:05:08,937 --> 00:05:11,690
You don't need any principles,
you don't have to understand

84
00:05:11,890 --> 00:05:15,962
very much and you can close
your eyes and blindly map one thing

85
00:05:16,162 --> 00:05:17,649
to the next.

86
00:05:17,851 --> 00:05:21,460
So, when there is an objection
that says:

87
00:05:21,660 --> 00:05:25,183
"Oh, you can't reconstruct
or simulate a cell

88
00:05:25,383 --> 00:05:28,295
because we don't know everything
about the cell",

89
00:05:28,495 --> 00:05:30,985
that is not a scientific statement.

90
00:05:32,441 --> 00:05:37,158
The challenge is to find the minimum
data you need.

91
00:05:37,358 --> 00:05:40,995
The smallest data set,
not the largest data set.

92
00:05:41,216 --> 00:05:45,848
The real science is to say what is
the least amount of data I need

93
00:05:46,048 --> 00:05:50,660
to be able to reconstruct it.

94
00:05:50,876 --> 00:05:52,353
That is a compression algorithm.

95
00:05:52,553 --> 00:05:55,150
It is a simile, it is the inverse,
what is the least amount of data

96
00:05:55,350 --> 00:05:56,900
that I need to transmit to you

97
00:05:57,101 --> 00:05:58,926
so, you can rebuild the image.

98
00:05:59,143 --> 00:06:00,234
Okay.

99
00:06:00,434 --> 00:06:02,937
In that case you do not need
to measure everything,

100
00:06:03,149 --> 00:06:07,588
you need principles and that is
what drives simulation neuroscience.

101
00:06:07,788 --> 00:06:11,578
And then you algorithmically
reconstruct it.

102
00:06:11,778 --> 00:06:15,556
So a simulation neuroscience
is fundamentally about finding

103
00:06:15,756 --> 00:06:18,989
those principles, packaging them
into algorithms,

104
00:06:19,189 --> 00:06:21,826
and then reconstructing.

105
00:06:22,044 --> 00:06:25,493
That is the first principle
of simulation neuroscience.

106
00:06:25,701 --> 00:06:31,926
The second principle is, actually
also quite similar to computer

107
00:06:32,192 --> 00:06:33,759
and software engineering.

108
00:06:33,964 --> 00:06:37,789
It is a bottom-up reconstruction
process.

109
00:06:37,984 --> 00:06:40,200
And it actually
has very strict rules.

110
00:06:40,400 --> 00:06:45,715
And the rules are, first of all,
you have got to follow

111
00:06:45,915 --> 00:06:47,952
the biological principles.

112
00:06:48,180 --> 00:06:51,741
You don't try and invent how
you think the brain should look.

113
00:06:51,941 --> 00:06:53,853
or the neuron should look.

114
00:06:54,064 --> 00:06:58,680
You measure and you use
as much of the data

115
00:06:58,880 --> 00:07:01,880
that is available and where
it is not available

116
00:07:03,008 --> 00:07:06,904
you have a hypothesis
of what is available.

117
00:07:07,104 --> 00:07:10,572
And you can then
test that hypothesis.

118
00:07:10,772 --> 00:07:14,376
You build the smallest
components first

119
00:07:14,576 --> 00:07:18,809
you really start atomic, if you wish,
you start at the eye channel

120
00:07:19,009 --> 00:07:22,583
to build a neuron, you don't start
at the neuron and then try make

121
00:07:22,783 --> 00:07:25,716
a neuron behave and then say:
"Oh, let me go back and build

122
00:07:25,916 --> 00:07:26,706
eye channels".

123
00:07:26,906 --> 00:07:30,343
You start at the very bottom
and you build upwards

124
00:07:30,630 --> 00:07:32,455
Okay?

125
00:07:32,661 --> 00:07:37,227
And a key thing which is the same
as what you do in computer

126
00:07:37,426 --> 00:07:40,426
and software engineering,
you build modules and cells,

127
00:07:40,745 --> 00:07:44,411
and functions and there you freeze
your variables and you freeze them.

128
00:07:44,611 --> 00:07:45,927
And then you combine them.

129
00:07:46,127 --> 00:07:48,963
We go to pi cell, it is so beautiful,
it is combinatorial

130
00:07:49,163 --> 00:07:52,163
because I just built these
and I can consume them later.

131
00:07:52,936 --> 00:07:57,510
But in order to do that I freeze
the components

132
00:07:57,710 --> 00:08:00,710
and then I can combine
the components.

133
00:08:01,121 --> 00:08:05,298
And the other important thing
and very different from

134
00:08:05,498 --> 00:08:07,510
computation neuroscience,
for example

135
00:08:07,727 --> 00:08:10,164
is you validate upwards.

136
00:08:10,358 --> 00:08:13,944
In other words, you validate
what emerges

137
00:08:14,144 --> 00:08:15,369
when you combine things.

138
00:08:15,567 --> 00:08:20,334
You don't try to fit and your data,

139
00:08:20,534 --> 00:08:24,532
you never fit the data

140
00:08:24,732 --> 00:08:28,414
looking up at an emerging property.

141
00:08:28,614 --> 00:08:33,806
So, for example, you wouldn't try
to say: "look, my brain is not speaking

142
00:08:34,006 --> 00:08:36,956
how can I adjust my eye channels
until I speak?"

143
00:08:37,155 --> 00:08:39,089
You will be adjusting eye channels
forever. 

144
00:08:39,289 --> 00:08:42,861
Okay, that is a massively,
it is an intractable problem.

145
00:08:43,062 --> 00:08:46,340
So, you have got to come down
to the emerging property

146
00:08:46,540 --> 00:08:50,256
as close to that parameter
as possible.

147
00:08:50,456 --> 00:08:54,330
For example, an eye channel,
you want to build an eye channel

148
00:08:54,530 --> 00:08:56,855
you look at the behavior of an eye
channel.

149
00:08:57,076 --> 00:09:00,692
You don't look at the behavior of the neuron
to build an eye channel.

150
00:09:00,892 --> 00:09:03,738
So, you always do it, at the bottom
you freeze it,

151
00:09:03,938 --> 00:09:07,173
and then when you say: "ok, I have
got my eye channels,

152
00:09:07,373 --> 00:09:10,341
I want to know what they do,
I put them in a neuron

153
00:09:10,541 --> 00:09:15,109
and then I look at the neuronal
behavior and that way I can see

154
00:09:15,309 --> 00:09:18,309
how they play out when they
are being used.

155
00:09:18,488 --> 00:09:24,447
If you find that you can
never replicate the neurons behavior

156
00:09:24,647 --> 00:09:28,367
then you can say: "maybe
I got my eye channels wrong.

157
00:09:28,567 --> 00:09:31,121
Maybe I don't have the right
eye channels."

158
00:09:31,321 --> 00:09:32,317
And so on.

159
00:09:32,517 --> 00:09:36,452
So that is the way we begin the cycle,
which we are going to learn a lot about

160
00:09:36,652 --> 00:09:39,041
in the course of this
and other lectures.

161
00:09:39,241 --> 00:09:43,939
The guiding principle here is
that if you build it right

162
00:09:44,139 --> 00:09:46,879
it will automatically behave right.

163
00:09:47,079 --> 00:09:50,736
OK, so you build bottom up.

164
00:09:51,218 --> 00:09:53,480
You build the components
you freeze them.

165
00:09:53,684 --> 00:09:56,524
If this is valid in terms
of the behavior

166
00:09:56,724 --> 00:09:58,420
even if you don't know
all the pieces,

167
00:09:58,620 --> 00:10:02,193
but if a neuron behaves right,
and you put in a circuit

168
00:10:02,393 --> 00:10:04,280
you can talk about what
neurons do.

169
00:10:04,480 --> 00:10:07,661
If the circuit behaves right
and you put it into a brain

170
00:10:07,861 --> 00:10:11,412
you can talk about what the circuit
does and not the brain.

171
00:10:11,612 --> 00:10:16,906
OK, so you don't try and tweak
the model to behave right.

172
00:10:17,106 --> 00:10:23,679
If the neuron, if you built it right
it automatically behaves right.

173
00:10:23,892 --> 00:10:26,191
The last, the third,
and there are of course many

174
00:10:26,391 --> 00:10:31,066
but the third principle is that
it is iterative reconstruction

175
00:10:31,291 --> 00:10:33,016
and testing.

176
00:10:33,216 --> 00:10:35,716
So you get your experimental data,

177
00:10:35,912 --> 00:10:41,529
you get your literature, you go
and find all the papers you can

178
00:10:41,729 --> 00:10:44,729
you mind all the facts
you possibly can.

179
00:10:44,929 --> 00:10:50,336
and you try and build
the unifying model of a neuron.

180
00:10:50,653 --> 00:10:54,102
You find the eye channels, you find
the morphologies, the structures

181
00:10:54,302 --> 00:10:57,574
the physiology, any data that
you have about that neuron

182
00:10:57,774 --> 00:10:59,098
you collect.

183
00:10:59,296 --> 00:11:02,705
And then the challenge is how
do you package that into

184
00:11:02,905 --> 00:11:06,367
the simplest algorithm that
will then reconstruct it

185
00:11:06,567 --> 00:11:10,192
that is consistent with all the data
that you gathered?

186
00:11:10,452 --> 00:11:13,448
You obtain your model

187
00:11:13,648 --> 00:11:16,624
and then you interrogate it
anatomically, you look at it

188
00:11:16,824 --> 00:11:19,824
and you see: "OK, I got it right,
it looks like a real neuron,

189
00:11:20,024 --> 00:11:24,353
I do the statistics between
my reconstructed neuron

190
00:11:24,553 --> 00:11:26,507
and the real neuron and I see
that they match".

191
00:11:26,707 --> 00:11:29,734
I look at where the eye channels
are, they match and so on.

192
00:11:29,946 --> 00:11:32,848
And then you simulate it to see
if it behaves the way

193
00:11:33,048 --> 00:11:35,343
that it does in the real tissue.

194
00:11:35,556 --> 00:11:40,121
And then you do an analysis,
you do the systematic comparison

195
00:11:40,321 --> 00:11:42,008
and you get your errors.

196
00:11:42,212 --> 00:11:47,163
Well, it is not going to work
the first time.

197
00:11:47,363 --> 00:11:52,976
In fact, the goal is to do it
very fast, fail very fast, identify

198
00:11:53,176 --> 00:11:56,926
where you may have got the wrong
data or the wrong assumptions

199
00:11:57,126 --> 00:12:02,509
and then you build it again,
and you keep going through the cycle

200
00:12:02,709 --> 00:12:06,325
as many times as you possibly can.

201
00:12:06,525 --> 00:12:10,213
In fact, it is an endless loop,
you keep going and integrating

202
00:12:10,413 --> 00:12:15,064
and perfecting it, but with each
cycle, this model

203
00:12:15,264 --> 00:12:19,105
replicates the tissue more
and more accurately.

204
00:12:19,305 --> 00:12:22,956
You follow this process,
you can't go left, you can't go right

205
00:12:23,156 --> 00:12:26,168
you can't go backwards,
you can only go forward.

206
00:12:26,368 --> 00:12:30,686
So, the model can only improve
each and every time

207
00:12:30,886 --> 00:12:32,390
that you integrate it.

208
00:12:32,590 --> 00:12:37,340
So, to illustrate this
let's just imagine

209
00:12:37,551 --> 00:12:43,781
that you step inside
a forest of neurons

210
00:12:43,981 --> 00:12:48,381
and you look up at the neurons,
there are thousands of neurons

211
00:12:48,581 --> 00:12:50,318
millions of synapses,

212
00:12:50,519 --> 00:12:52,383
and you look around.

213
00:12:52,583 --> 00:12:54,057
And you say:

214
00:12:54,267 --> 00:12:56,484
"I wonder how these neurons connect?

215
00:12:56,696 --> 00:13:00,039
I mean, how are they connecting
with each other?

216
00:13:00,239 --> 00:13:01,688
Who is connected with each
other?

217
00:13:01,912 --> 00:13:04,046
Where are all these...?"

218
00:13:04,246 --> 00:13:06,006
So, how do you approach
this problem?

219
00:13:06,206 --> 00:13:09,206
Of course you can try and let's take
an electro microscope

220
00:13:09,406 --> 00:13:11,668
and measure everything

221
00:13:11,893 --> 00:13:14,927
that is, of course, one approach,
but it you actually look at it

222
00:13:15,127 --> 00:13:17,501
you will be measuring for a very
very long time

223
00:13:17,709 --> 00:13:20,709
But there is another approach
and the way that we do it in simulation

224
00:13:20,909 --> 00:13:25,176
neuroscience, we say:
"OK, let's just look at what we know.

225
00:13:25,376 --> 00:13:32,086
Let's start off and let's imagine
that we have a whole series

226
00:13:32,291 --> 00:13:34,742
of cells, neurons".

227
00:13:36,867 --> 00:13:37,942
OK.

228
00:13:40,655 --> 00:13:44,190
And, of course, there are different
kinds of neurons.

229
00:13:47,353 --> 00:13:49,950
You have many different kinds
of neurons.

230
00:13:50,150 --> 00:13:55,857
Each one looks different,
behaves different

231
00:13:56,057 --> 00:14:03,365
and it can, of course, connect
differently to the others.

232
00:14:05,078 --> 00:14:06,803
So, how do you
approach this problem ?

233
00:14:07,435 --> 00:14:09,984
Well, you can say: "What do we know?"

234
00:14:10,184 --> 00:14:13,184
And maybe there's only
one experiment

235
00:14:13,527 --> 00:14:18,274
that tells you how this one cell,
this one type of cell

236
00:14:18,474 --> 00:14:20,082
connects with others.

237
00:14:20,282 --> 00:14:23,899
There are potentially thousands
of different types of connections

238
00:14:24,099 --> 00:14:27,473
here, but you only have one
experimental data point.

239
00:14:27,673 --> 00:14:32,373
And this experimental data point
you go and you see

240
00:14:32,654 --> 00:14:36,825
that the axon that goes to connect
all these neurons does this.

241
00:14:37,025 --> 00:14:40,179
And you look at this and you analyze
the data here and you say: 

242
00:14:40,379 --> 00:14:44,860
"Oh, I can see the principle". 
First principle:

243
00:14:45,060 --> 00:14:50,492
The axon somehow touches
every neuron.

244
00:14:50,692 --> 00:14:52,523
Okay?

245
00:14:52,723 --> 00:14:57,322
So, before I look at who is connected
I just see that the way this axon

246
00:14:57,522 --> 00:15:01,118
goes, it is like what we call
a tabular riser.

247
00:15:01,318 --> 00:15:03,906
It goes and it touches
everything on you.

248
00:15:04,106 --> 00:15:09,989
And then I look at this one neuron
and I say: Oh, I see that when it

249
00:15:10,189 --> 00:15:15,828
touches, when it touches onto
another cell, it actually puts lots

250
00:15:16,028 --> 00:15:17,577
of little synapses on it

251
00:15:17,795 --> 00:15:21,857
It never puts just one synapse".

252
00:15:22,047 --> 00:15:23,209
OK?

253
00:15:23,414 --> 00:15:26,263
It never puts just one synapse
it puts lots of them.

254
00:15:26,459 --> 00:15:29,041
So, I see principle number 2:

255
00:15:29,241 --> 00:15:31,653
it is a multi synapse rule.

256
00:15:31,872 --> 00:15:33,040
Okay?

257
00:15:33,240 --> 00:15:37,192
And I think: "oh that's interesting,
but what else can I learn

258
00:15:37,392 --> 00:15:40,116
by looking at this one experiment?"

259
00:15:40,316 --> 00:15:42,354
I see principle number 3:

260
00:15:42,554 --> 00:15:47,432
I see, wow, if I look at
the axon of the cell,

261
00:15:47,632 --> 00:15:49,744
and I look at it very carefully

262
00:15:49,957 --> 00:15:55,027
I see that it has got places
called blue tones

263
00:15:55,227 --> 00:15:58,227
which is where it can form synapses.

264
00:15:58,427 --> 00:16:00,394
So, I think: "how many are there?

265
00:16:00,594 --> 00:16:03,852
And what is the space between them?"

266
00:16:04,052 --> 00:16:08,447
And then I say: "okay, that will limit
how many neurons

267
00:16:08,647 --> 00:16:14,373
this one can contact", right,
because if I have an axon only as two

268
00:16:14,573 --> 00:16:18,006
then it is, of course, going to have
a very different kind of activity

269
00:16:18,206 --> 00:16:20,024
than I have axon
that has many boutons.

270
00:16:20,224 --> 00:16:23,664
Then now I have a bouton principle.

271
00:16:23,864 --> 00:16:25,903
It is a physical limitation.

272
00:16:26,103 --> 00:16:29,354
If I have lots of boutons,
if I have a neuron with an axon

273
00:16:29,554 --> 00:16:32,979
with lots of boutons, then
I can contact lots of cells.

274
00:16:33,201 --> 00:16:35,638
If I have one, I can
contact one cell.

275
00:16:35,853 --> 00:16:38,097
So, these are 3 principles.

276
00:16:38,297 --> 00:16:42,124
Now there are more principles,
but let's just assume, just say: "OK

277
00:16:42,324 --> 00:16:47,610
I like these 3 principles,
I am going to see if I can rebuild

278
00:16:47,810 --> 00:16:50,810
the tissue
just with these three principles".

279
00:16:51,010 --> 00:16:54,010
So, we package them
into an algorithm.

280
00:16:54,210 --> 00:16:56,085
Okay?

281
00:16:56,304 --> 00:16:59,414
And digitally we reconstruct
this tissue.

282
00:16:59,614 --> 00:17:02,830
Now we have 2 possible
scenarios:

283
00:17:03,030 --> 00:17:06,715
it succeeds or it fails.

284
00:17:06,915 --> 00:17:11,232
Succeeds means that
you have a look at it

285
00:17:11,432 --> 00:17:13,978
and then somebody tells you:
"Hey, you know what?

286
00:17:14,178 --> 00:17:17,403
There are 10 other experiments
out there that looked at

287
00:17:17,617 --> 00:17:22,088
how this cell connects,
and this cell connects

288
00:17:22,288 --> 00:17:24,890
and you have other data
that you can check it with".

289
00:17:25,089 --> 00:17:30,090
And then when you look at that
you see that your reconstructed tissue

290
00:17:30,290 --> 00:17:33,783
now reproduces all of that
experiment.

291
00:17:33,983 --> 00:17:38,999
So, you think: "wow, I mean I looked
at 1 cell, applied 3 principles

292
00:17:39,199 --> 00:17:41,811
of how they should connect with
each other

293
00:17:42,015 --> 00:17:46,299
and they reproduce what other people
have done in other laboratories

294
00:17:46,499 --> 00:17:47,836
all over the world".

295
00:17:48,043 --> 00:17:49,981
That is a success.

296
00:17:50,195 --> 00:17:53,180
But what is important to understand
with this success

297
00:17:53,380 --> 00:17:56,831
is that you haven't really gained any
new knowledge, but you have gained

298
00:17:57,031 --> 00:17:58,472
a new understanding.

299
00:17:58,672 --> 00:18:01,764
You understand how
your principles interact.

300
00:18:01,964 --> 00:18:09,063
You understand that this principle
for this neuron applies to all of them.

301
00:18:09,263 --> 00:18:13,503
Two very concrete
new understandings.

302
00:18:13,703 --> 00:18:17,302
It is not new knowledge because
this knowledge existed,

303
00:18:17,502 --> 00:18:21,121
people had measured this, we saw
this, it was just fragmented knowledge

304
00:18:21,321 --> 00:18:27,312
but you didn't even had that sort
of integrated, unified view.

305
00:18:27,512 --> 00:18:33,257
So, when it succeeds,
you understand better.

306
00:18:33,457 --> 00:18:36,922
I am an experimental neuroscientist
and I have looked under microscopes

307
00:18:37,122 --> 00:18:38,384
for 20 years.

308
00:18:38,605 --> 00:18:43,094
And when I put this together,
in a single reconstruction

309
00:18:43,294 --> 00:18:48,033
I understand what I was doing
for all those 20 years.

310
00:18:48,233 --> 00:18:51,394
Because you can see this
as an integrated,

311
00:18:51,594 --> 00:18:56,510
an integrated answer or perspective
on what the pieces are

312
00:18:56,710 --> 00:18:59,256
that you have been collecting
for so long.

313
00:18:59,469 --> 00:19:03,631
Now the other scenario is it fails.

314
00:19:03,831 --> 00:19:07,730
I do this, I check it again,
somebody comes into the door

315
00:19:07,930 --> 00:19:11,358
and they say: "Look, I have
an experiment and it shows me

316
00:19:11,558 --> 00:19:15,855
that this cell, it really doesn't follow
those principles and it connects

317
00:19:16,055 --> 00:19:18,058
in a completely different way".

318
00:19:18,271 --> 00:19:24,736
And then I have new knowledge.

319
00:19:24,936 --> 00:19:29,930
I know that these principles
are not enough.

320
00:19:30,130 --> 00:19:32,873
There have to be new principles.

321
00:19:33,073 --> 00:19:36,889
There have to be some other rules
that will apply

322
00:19:37,089 --> 00:19:40,569
whether they are exceptions,
or whether they are

323
00:19:40,769 --> 00:19:43,769
that these principles have to be modified.

324
00:19:43,988 --> 00:19:47,330
But there has to be something
else that has to be understood.

325
00:19:47,530 --> 00:19:50,995
And then one can start investigating
and that triggers, when you fail

326
00:19:51,195 --> 00:19:54,120
it triggers new experiments
which you have to test now.

327
00:19:54,320 --> 00:19:59,562
How would an algorithm reconcile
these differences?

328
00:19:59,762 --> 00:20:05,205
Another way to describe this
is imagine that this algorithm

329
00:20:05,405 --> 00:20:07,272
works in one part of the brain.

330
00:20:07,472 --> 00:20:09,910
And it explains
all the way the neurons connect.

331
00:20:10,098 --> 00:20:14,117
Now I go to another part of the brain
and it doesn't work there.

332
00:20:14,317 --> 00:20:15,486
You think: "that is terrible"!

333
00:20:15,686 --> 00:20:20,020
No, that is great, because it tells
you that in that other part of the brain

334
00:20:20,220 --> 00:20:23,044
there is something else going on.

335
00:20:23,265 --> 00:20:27,227
And that something else nobody
knew about before.

336
00:20:27,742 --> 00:20:31,304
Because you had too much
fragmented knowledge.

337
00:20:31,504 --> 00:20:37,993
That is when failing really leads
to an advancement of knowledge.

338
00:20:38,193 --> 00:20:40,492
New knowledge.

339
00:20:40,702 --> 00:20:44,660
Because it triggers a completely
new perspective.

340
00:20:44,860 --> 00:20:48,749
It actually shows you the boundaries
of a current knowledge.

341
00:20:48,949 --> 00:20:51,028
You get to the end and you say :
"I've taken all the data,

342
00:20:51,228 --> 00:20:55,498
all the principles
and I can't explain

343
00:20:55,698 --> 00:20:57,585
how this happens".

344
00:20:57,773 --> 00:20:59,459
Then you are at the frontier.

345
00:20:59,659 --> 00:21:03,445
And at that frontier you can either
do theory, you can do experiment

346
00:21:03,645 --> 00:21:07,532
you can iteratively test,

347
00:21:07,837 --> 00:21:09,764
but there are many
ways to advance it.

348
00:21:09,964 --> 00:21:14,770
And this is a very exciting approach
to advancing knowledge.

349
00:21:14,970 --> 00:21:17,970
Okay, so we looked at these
3 principles

350
00:21:19,661 --> 00:21:23,713
on which simulation neuroscience
is based.

