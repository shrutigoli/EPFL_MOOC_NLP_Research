1
00:00:05,031 --> 00:00:09,203
I would like to talk about some
of the activities with text mining

2
00:00:09,503 --> 00:00:12,926
and actually extracting values
for data integration

3
00:00:13,126 --> 00:00:14,273
from the literature

4
00:00:14,977 --> 00:00:18,588
One of the big challenges as we know

5
00:00:18,788 --> 00:00:23,990
that knowledge and data there's been
a tremendous amount of it published

6
00:00:24,730 --> 00:00:26,880
in neuroscience
over the last hundred years

7
00:00:27,080 --> 00:00:29,512
But, we don't easily access that data

8
00:00:29,712 --> 00:00:32,133
So, how do we make the knowledge
and data

9
00:00:32,333 --> 00:00:37,753
from this huge archival past
of literature ?

10
00:00:37,953 --> 00:00:40,829
how do we make it accessible,
to search it, to analyze it

11
00:00:41,029 --> 00:00:44,849
or to integrate it, or to use it
for computational models?

12
00:00:45,137 --> 00:00:49,311
So, most valuable knowledge lies
in an unstructured form

13
00:00:49,511 --> 00:00:51,464
within scientific papers
you've got to read it

14
00:00:51,664 --> 00:00:53,787
you've got to follow it
through the text

15
00:00:53,987 --> 00:00:57,914
and actually find out
where does it say something useful?

16
00:00:58,114 --> 00:01:00,650
Where is a useful parameter
to build my model?

17
00:01:01,636 --> 00:01:04,345
And there is one new paper
each minute on PubMed

18
00:01:04,559 --> 00:01:06,447
So there is a tremendous challenge
here

19
00:01:06,647 --> 00:01:09,647
because there is no standardization
there is no centralization.

20
00:01:09,847 --> 00:01:13,222
There is a tremendous flood of data
and knowledge that is coming out

21
00:01:13,422 --> 00:01:17,820
but is also in the archival history
of neuroscience

22
00:01:18,020 --> 00:01:21,196
and we have got to have some tools
to address that

23
00:01:21,396 --> 00:01:22,956
to start accessing that

24
00:01:23,256 --> 00:01:28,155
So, our goal with text mining
was to take an example

25
00:01:28,355 --> 00:01:31,716
where we wanted to extract
metascale brain connectivity

26
00:01:31,916 --> 00:01:32,916
we wanted to see

27
00:01:33,116 --> 00:01:37,155
can we usefully find connectivity
statements from the literature ?

28
00:01:37,605 --> 00:01:40,747
In order to accelerate
the literature review

29
00:01:41,325 --> 00:01:44,384
rapidly summarize
the existing knowledge

30
00:01:44,584 --> 00:01:48,722
and  provide a centralized repository
of connectivity statements

31
00:01:48,922 --> 00:01:50,472
for neuroscientists or modelers

32
00:01:50,672 --> 00:01:54,072
if they need to quickly find out
is this area connected to this area

33
00:01:54,272 --> 00:01:56,874
they will have a large body
of literature

34
00:01:57,073 --> 00:01:59,357
summarized from this text mining.

35
00:01:59,898 --> 00:02:04,591
Because we don't really think
that we can reliably

36
00:02:05,546 --> 00:02:08,641
get actual connectivity data
for the whole brain here

37
00:02:08,841 --> 00:02:11,923
this is not
where we would just blindly take

38
00:02:12,123 --> 00:02:15,373
the results of the text mining
and use it to build a model

39
00:02:15,673 --> 00:02:18,619
But we use it as a way
of accelerating the process

40
00:02:18,850 --> 00:02:22,186
of going through thousands
upon thousands of papers.

41
00:02:22,686 --> 00:02:25,306
And so the first step in this process

42
00:02:25,506 --> 00:02:28,435
is a process called
“named entity recognition”

43
00:02:28,635 --> 00:02:32,874
and this is where you use
existing databases of words

44
00:02:33,074 --> 00:02:36,774
and the type of word that they are

45
00:02:36,974 --> 00:02:42,968
to parse through and identify specific
types of entities within a sentence

46
00:02:43,168 --> 00:02:44,168
So, in the sentence

47
00:02:44,368 --> 00:02:46,804
“the interstitial nucleus
of the posterior limb"

48
00:02:47,004 --> 00:02:48,676
"of of the anterior commisure”

49
00:02:48,876 --> 00:02:53,222
you can see that these words
are being recognized

50
00:02:53,422 --> 00:02:55,998
as, well, different brain regions

51
00:02:56,198 --> 00:02:59,605
for example,
nucleus of the posterior limb

52
00:02:59,805 --> 00:03:01,145
of the anterior commisure

53
00:03:01,345 --> 00:03:04,692
so it is recognizing overall
that is the name of a brain region

54
00:03:04,892 --> 00:03:08,342
and then there are sub-regions
named within that.

55
00:03:08,542 --> 00:03:12,555
And then, in the next phrase
it recognizes the IPAC

56
00:03:13,197 --> 00:03:15,893
is an abbreviation for that,

57
00:03:16,165 --> 00:03:20,492
and lies at the junction
of the striatopalladial system

58
00:03:20,692 --> 00:03:22,850
so it recognizes
another brain region.

59
00:03:23,050 --> 00:03:27,136
So, through this way, this process
of named entity recognition

60
00:03:27,336 --> 00:03:30,970
you can start to parse out
the different types of entities

61
00:03:31,170 --> 00:03:33,179
described in the sentence

62
00:03:33,566 --> 00:03:36,696
So, to apply this,
we actually want to mine

63
00:03:36,896 --> 00:03:39,241
for example, connectivity statements

64
00:03:40,821 --> 00:03:44,889
where we are using the named entity
recognizers to find brain regions

65
00:03:45,089 --> 00:03:46,992
to find statements of connectivity

66
00:03:47,192 --> 00:03:49,442
and then to find the combination
of those two.

67
00:03:49,642 --> 00:03:52,473
And here are a number of example
connectivity statements

68
00:03:52,673 --> 00:03:53,724
that we parsed out

69
00:03:54,308 --> 00:03:59,109
and specific formal description
of that statement.

70
00:03:59,309 --> 00:04:01,659
And you can see, we have got
the nucleus accumbens

71
00:04:01,859 --> 00:04:04,929
receives projections
from both substantia nigra

72
00:04:05,129 --> 00:04:07,172
and ventral tegmental area

73
00:04:07,372 --> 00:04:09,433
and the formal expression of that.

74
00:04:09,637 --> 00:04:13,023
We do that for many different texts

75
00:04:13,223 --> 00:04:18,073
and that provides a way of ultimately
identifying

76
00:04:18,814 --> 00:04:20,979
specific statements of connectivity

77
00:04:21,179 --> 00:04:24,999
brain region connection type
to another brain region.

78
00:04:25,426 --> 00:04:28,201
And to do this, we use a BLUIMA

79
00:04:28,401 --> 00:04:32,049
it is an open source text mining
system built of UIMA

80
00:04:32,249 --> 00:04:34,905
which is coming
from IBM Watson's technologies

81
00:04:35,105 --> 00:04:36,599
it is an open source project

82
00:04:36,799 --> 00:04:39,145
We use three named entity recognizers

83
00:04:39,345 --> 00:04:43,243
to identify and normalize
brain region names

84
00:04:43,477 --> 00:04:46,121
We use three different extractors

85
00:04:46,321 --> 00:04:48,498
to predict the connectivity
probability

86
00:04:49,018 --> 00:04:51,481
of brain region co-occurrences

87
00:04:51,868 --> 00:04:54,168
And then,
we use the connectivity results

88
00:04:54,882 --> 00:04:59,844
we provide it through a user interface
to allow feedback from a user

89
00:05:00,106 --> 00:05:04,350
to validate. Is this actually a useful
connectivity statement, or not?

90
00:05:04,550 --> 00:05:08,062
And we are using as data sources
PubMed abstracts

91
00:05:08,562 --> 00:05:11,486
full text articles
from open source journals.

92
00:05:12,086 --> 00:05:16,086
And so, we have got named entity
recognizers for the Allen Brain Atlas

93
00:05:16,286 --> 00:05:18,486
from the Brain Architecture
Management System

94
00:05:18,686 --> 00:05:22,225
and from our own brain
named entity recognizer.

95
00:05:22,787 --> 00:05:24,603
So, we ran this system

96
00:05:25,210 --> 00:05:31,127
this set of named entity recognizers
and connectivity statement extractors

97
00:05:31,327 --> 00:05:34,406
on 13.2 million PubMed abstracts

98
00:05:34,606 --> 00:05:39,279
and 630,000 full text publications
related to neuroscience

99
00:05:39,496 --> 00:05:44,262
In that, we found over 4 million
brain region mentions

100
00:05:44,462 --> 00:05:45,762
from the Allen Brain Atlas

101
00:05:45,962 --> 00:05:49,189
and 7 million from the Brain
Architecture Management System

102
00:05:49,969 --> 00:05:52,922
Over 100,000 of those statements

103
00:05:53,122 --> 00:05:55,809
and 160,000 from BAMS

104
00:05:56,009 --> 00:05:58,346
were potential brain region
connections

105
00:05:58,610 --> 00:05:59,810
And when we checked that

106
00:06:00,010 --> 00:06:03,008
we found that there was precision
of about 78%

107
00:06:03,208 --> 00:06:07,498
against actual experimentally
measured NVIVO connectivity data

108
00:06:07,698 --> 00:06:09,244
from the Allen Brain Atlas

109
00:06:09,739 --> 00:06:13,899
And so we actually characterize
the connectivity matrix

110
00:06:14,099 --> 00:06:18,070
and along the sides here
you see the different brain regions

111
00:06:18,616 --> 00:06:21,219
connected to, along the top,
the brain regions again

112
00:06:21,419 --> 00:06:23,813
So, you see which regions
are connected

113
00:06:24,963 --> 00:06:27,961
and the grey shows
the connectivity statement

114
00:06:28,161 --> 00:06:29,726
and we compare on the left

115
00:06:29,926 --> 00:06:32,892
one from the Allen Brain
Connectivity Atlas

116
00:06:33,147 --> 00:06:37,704
to the right, to the connectivities
discovered by our text mining system

117
00:06:37,934 --> 00:06:42,329
So, we see that there is actually
a decent structural similarity

118
00:06:42,629 --> 00:06:43,953
between these two

119
00:06:44,153 --> 00:06:48,320
but importantly, it shows
that this is viable way

120
00:06:48,520 --> 00:06:50,220
of getting connectivity statements

121
00:06:50,420 --> 00:06:52,784
as a rapid way of reviewing
the literature

122
00:06:52,984 --> 00:06:55,980
and we can compare that
to existing data

123
00:06:56,180 --> 00:06:58,215
and data captured from real animals.

124
00:06:58,478 --> 00:07:01,896
As well as use it as a way
to quickly identify for a modeler

125
00:07:02,096 --> 00:07:04,287
the details of specific literature

126
00:07:04,487 --> 00:07:06,760
that makes a statement
about connectivity

127
00:07:06,960 --> 00:07:09,013
from one brain region to another.

128
00:07:09,248 --> 00:07:13,175
Another approach is to actually
annotate the literature

129
00:07:13,741 --> 00:07:17,236
for specific parameters needed
in building models

130
00:07:17,436 --> 00:07:22,049
And so when a modeler is building
a model neuron or a model synapse,

131
00:07:22,249 --> 00:07:25,081
you need things like resting
numbering potentials

132
00:07:25,281 --> 00:07:29,090
or synaptic conductances, or protein
concentrations from the literature.

133
00:07:29,349 --> 00:07:35,640
And we want to enable the scientist
to go into the paper

134
00:07:35,840 --> 00:07:37,677
and make a specific annotation

135
00:07:37,877 --> 00:07:41,857
kind of as though you're taking notes
on a paper, highlight it

136
00:07:42,117 --> 00:07:45,676
and link that highlighted element
within the paper

137
00:07:46,040 --> 00:07:50,329
to a specific machine
readable description of the parameter

138
00:07:50,529 --> 00:07:54,105
and how that needs to be transformed
to be integrated into a model

139
00:07:54,305 --> 00:07:56,022
And so, this is Neuro Curator

140
00:07:56,222 --> 00:07:58,478
this is a tool developed
by Christian O'Reilly

141
00:07:59,003 --> 00:08:01,877
to annotate these model parameters
from the literature

142
00:08:02,077 --> 00:08:05,410
and also track when we use
the parameters in a model:

143
00:08:06,027 --> 00:08:08,727
where did those parameters come
from in the literature?

144
00:08:08,927 --> 00:08:11,277
So, that we can always track
the source document

145
00:08:11,477 --> 00:08:14,177
the specific statement
any transformation that happened

146
00:08:14,377 --> 00:08:16,608
to that parameter
in order to be incorporated

147
00:08:16,808 --> 00:08:18,708
So, this has a graphical
user interface

148
00:08:18,908 --> 00:08:21,134
for keeping track of the corpus
of literature

149
00:08:21,334 --> 00:08:25,440
and all of the annotations
and the transformations performed

150
00:08:25,752 --> 00:08:28,969
And we've extracted large numbers
of parameters here

151
00:08:29,595 --> 00:08:31,653
mostly of 30 parameter types

152
00:08:32,043 --> 00:08:35,542
but this is an ongoing process
we're continuing to do this

153
00:08:35,950 --> 00:08:38,166
to support the thalamal
and cortical modeling

154
00:08:38,366 --> 00:08:41,580
and this gives some examples
of the types of values extracted

155
00:08:41,780 --> 00:08:43,590
Now, another part of the process

156
00:08:43,790 --> 00:08:50,049
a meta-modeler actually lets you tag
in your source code for your model

157
00:08:50,930 --> 00:08:56,900
which parameters you want to insert
from the curator annotation database

158
00:08:57,200 --> 00:09:02,458
And this takes care of passing
into the source code.

159
00:09:03,277 --> 00:09:04,436
So you make a reference

160
00:09:04,636 --> 00:09:07,434
and then it basically replaces
that reference

161
00:09:07,634 --> 00:09:09,970
with the actual parameter
from the literature

162
00:09:10,170 --> 00:09:13,070
keeping track of which paper
was it actually coming from

163
00:09:13,270 --> 00:09:15,641
But this is an important way
of keeping the link

164
00:09:15,841 --> 00:09:20,106
between the literature, the citation
and the model

165
00:09:20,306 --> 00:09:22,315
And then, since we are annotating

166
00:09:22,515 --> 00:09:24,769
as we annotate each
of those parameters

167
00:09:25,083 --> 00:09:28,138
using controlled vocabulary
and using ontologies

168
00:09:28,338 --> 00:09:31,726
in particular, using ontologies
of brain regions

169
00:09:32,114 --> 00:09:35,605
that allows us to link
in specific statements

170
00:09:35,805 --> 00:09:40,281
for example, on cell density
into a brain atlas

171
00:09:40,481 --> 00:09:43,667
So, because we're using
the same names as in the brain atlas

172
00:09:44,089 --> 00:09:49,398
we can annotate
that there are 150.3 relay cells

173
00:09:50,333 --> 00:09:54,138
or 150,000 relay cells
per cubic millimeter

174
00:09:54,338 --> 00:09:58,486
within the dorsal thalamus
for example

175
00:09:58,686 --> 00:10:03,246
and use that information to actually
then parameterize the model

176
00:10:03,715 --> 00:10:06,740
which we provide
through a VoxelBrain API

177
00:10:06,940 --> 00:10:09,361
which allows you
to then query these properties.

178
00:10:10,314 --> 00:10:12,008
Again, linked back to literature

179
00:10:12,208 --> 00:10:16,328
but as actual data
from the atlas to build the models

180
00:10:16,528 --> 00:10:19,794
This is an important way
of extracting data from the literature

181
00:10:19,994 --> 00:10:22,631
linking it into atlases
and then using that

182
00:10:22,831 --> 00:10:24,986
to actually parameterize models

183
00:10:25,215 --> 00:10:28,123
both in terms of building
individual cell models

184
00:10:28,323 --> 00:10:30,741
but also building models
of brain regions

185
00:10:31,326 --> 00:10:34,826
So, in this session you've learned
about some approaches to text mining

186
00:10:35,026 --> 00:10:36,141
for neuroscience data

187
00:10:36,441 --> 00:10:38,191
extracting data from the literature

188
00:10:38,391 --> 00:10:41,319
and a tool Neuro Curator
for annotating literature

189
00:10:41,519 --> 00:10:43,003
for modeling parameters

190
00:10:43,282 --> 00:10:47,511
As well as integrating data
with an atlas via ontologies

