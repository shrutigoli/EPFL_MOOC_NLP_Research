1
00:00:05,283 --> 00:00:07,000
I am Sean Hill,
co-director

2
00:00:07,219 --> 00:00:08,937
of the Blue Brain Project
and the head

3
00:00:09,137 --> 00:00:10,561
of the division of
the neuroinformatics.

4
00:00:10,879 --> 00:00:12,753
I'll be talking today
about some of

5
00:00:12,753 --> 00:00:15,079
the neuro informatics'
issues and challenges

6
00:00:15,425 --> 00:00:18,326
in organizing all of
the data needed

7
00:00:18,561 --> 00:00:21,079
for the data driven
modeling process.

8
00:00:21,497 --> 00:00:24,817
So, I'll start off taking you
through the importance

9
00:00:24,817 --> 00:00:28,388
of meta data and
provenance and how we use

10
00:00:28,639 --> 00:00:30,129
that to build up
the knowledge graph

11
00:00:30,485 --> 00:00:32,720
I'll introduce ontologies

12
00:00:33,034 --> 00:00:35,170
Iíll give some examples
of text mining

13
00:00:35,450 --> 00:00:37,281
and data integration
from the literature

14
00:00:37,560 --> 00:00:39,768
and Iíll also just give
a quick overview

15
00:00:40,069 --> 00:00:41,450
of the brain Atlases

16
00:00:41,749 --> 00:00:45,080
and search and interface
into our knowledge base.

17
00:00:45,951 --> 00:00:48,500
So, first of all, the challenge
in neuroscience

18
00:00:48,795 --> 00:00:52,220
is really that neuroscience
data is really heterogenous.

19
00:00:52,639 --> 00:00:55,562
Nearly every piece
of data is gathered

20
00:00:55,842 --> 00:00:57,951
in a different lab with
different protocols

21
00:00:58,249 --> 00:01:00,686
and different
experimental techniques

22
00:01:00,967 --> 00:01:04,091
and the challenge is of how
do we take all this data

23
00:01:04,330 --> 00:01:06,733
which is really ranging from
the sub-cellular level

24
00:01:07,152 --> 00:01:09,309
from gene expression
and proteomics

25
00:01:09,562 --> 00:01:11,889
to the cellular level
with individual cell

26
00:01:12,152 --> 00:01:13,890
electro physiology
and morphology

27
00:01:14,153 --> 00:01:17,090
up to the tissue level
and whole brain scale

28
00:01:17,400 --> 00:01:19,635
with the new techniques
coming in

29
00:01:19,870 --> 00:01:22,027
to measure the whole
brain activity

30
00:01:22,309 --> 00:01:25,260
EEG behavioral measurements.

31
00:01:25,560 --> 00:01:28,211
How do we actually
integrate that data?

32
00:01:28,211 --> 00:01:30,091
How do we organize it
so that we can find

33
00:01:30,091 --> 00:01:33,056
the relationships between
those different levels

34
00:01:33,056 --> 00:01:35,573
and ultimately build
models that helps us

35
00:01:35,775 --> 00:01:38,264
go from gene to behavior

36
00:01:38,890 --> 00:01:41,019
and this is the challenge
in neuroscience.

37
00:01:41,019 --> 00:01:41,265
And the way that we
approach it in Blue Brain
and this is the challenge
in neuroscience.

38
00:01:41,265 --> 00:01:43,515
And the way that we
approach it in Blue Brain

39
00:01:43,874 --> 00:01:46,954
is really to establish
an iterative

40
00:01:47,163 --> 00:01:49,066
cycle of data integration

41
00:01:49,348 --> 00:01:50,938
by building models

42
00:01:51,203 --> 00:01:53,326
but building digital
preconstructions

43
00:01:53,563 --> 00:01:56,548
that help us understand

44
00:01:56,780 --> 00:01:59,020
how do the pieces of data
actually fit together

45
00:01:59,345 --> 00:02:05,923
and then if we take this step
by step by starting from data

46
00:02:06,234 --> 00:02:09,863
available data from the literature,
existing models

47
00:02:10,238 --> 00:02:14,521
existing data repositories,
we have to organize

48
00:02:14,798 --> 00:02:16,561
that data into Brain Atlases

49
00:02:16,896 --> 00:02:20,049
so we can start using
to build models

50
00:02:20,264 --> 00:02:24,364
run simulations, and then
perform a validation step

51
00:02:24,640 --> 00:02:27,785
and that validation is really
essential to the process

52
00:02:28,095 --> 00:02:30,487
because itís only by
validating the model

53
00:02:30,779 --> 00:02:33,066
by showing where
does it work

54
00:02:33,376 --> 00:02:34,711
and where does it not work

55
00:02:34,922 --> 00:02:37,345
where is it consistent
with biological data

56
00:02:37,658 --> 00:02:39,663
and where does it
fail to recreate

57
00:02:40,002 --> 00:02:42,444
the biological phenomenon
that we know occur.

58
00:02:42,733 --> 00:02:44,256
And itís through
that process

59
00:02:44,256 --> 00:02:46,250
and iteratively
performing that process

60
00:02:46,474 --> 00:02:47,851
that we improve
the models

61
00:02:48,111 --> 00:02:49,956
that we identify
new experiments

62
00:02:50,234 --> 00:02:51,220
that should
be performed

63
00:02:51,532 --> 00:02:53,190
missing data that
would be critical

64
00:02:53,469 --> 00:02:55,253
that would be
filling in key gaps

65
00:02:55,545 --> 00:02:58,380
between the levels,
and overall starting

66
00:02:58,595 --> 00:03:01,772
to identify the principals
by which this whole

67
00:03:02,046 --> 00:03:05,469
brain operates across
different scales.

68
00:03:05,858 --> 00:03:08,654
And the neuroinformatics
platform is really the key

69
00:03:08,910 --> 00:03:12,826
to supporting that process,
that center of the process

70
00:03:13,062 --> 00:03:16,298
by enabling the data
to be organized

71
00:03:16,630 --> 00:03:19,804
data that maybe distributed
around the world

72
00:03:20,233 --> 00:03:22,756
And here, there we got
different components

73
00:03:23,093 --> 00:03:25,062
of the neuroinformatics
platform.

74
00:03:25,280 --> 00:03:29,183
One is the data space,
which is really where

75
00:03:29,482 --> 00:03:32,410
is the data situated,
distributed around the world.

76
00:03:33,467 --> 00:03:35,636
Weíve got data
registration a process

77
00:03:35,840 --> 00:03:37,526
by which we annotate
the data

78
00:03:37,729 --> 00:03:40,165
with the meta data
necessary to discover it

79
00:03:40,462 --> 00:03:42,964
and to anchor it in Atlases.

80
00:03:43,416 --> 00:03:45,447
Weíve god the knowledge
graph and search

81
00:03:45,806 --> 00:03:48,651
which Iíll talk about, which
allows us to actually find

82
00:03:48,917 --> 00:03:51,854
and discover data
and the related data

83
00:03:52,058 --> 00:03:55,606
so any type of data
and its properties

84
00:03:55,885 --> 00:03:57,922
as well as Atlases,
which help

85
00:03:58,228 --> 00:03:59,634
us to navigate the data

86
00:03:59,634 --> 00:04:02,341
discover data related to
particular brain structures

87
00:04:02,634 --> 00:04:07,247
and also anchor data
into a standard space.

88
00:04:07,666 --> 00:04:09,686
And finally, we have
the knowledge space

89
00:04:09,686 --> 00:04:12,026
which the online
community encyclopedia

90
00:04:12,340 --> 00:04:14,372
which really provides
a place where

91
00:04:14,682 --> 00:04:16,635
the current state
of knowledge

92
00:04:16,947 --> 00:04:17,884
can be maintained

93
00:04:18,125 --> 00:04:20,075
in terms of
encyclopedic article

94
00:04:20,462 --> 00:04:25,415
but also links to data
and data that

95
00:04:25,685 --> 00:04:27,487
is either in
the knowledge graph

96
00:04:27,775 --> 00:04:28,984
that weíre talking about

97
00:04:29,244 --> 00:04:30,384
or in other
curated data

98
00:04:30,590 --> 00:04:31,712
bases from
around the world.

99
00:04:32,089 --> 00:04:33,327
So where is the data?

100
00:04:33,528 --> 00:04:36,025
This is actually a massive
challenge for neuroscience

101
00:04:36,325 --> 00:04:39,127
because most of,
whatís the so called

102
00:04:39,356 --> 00:04:42,404
the Long tell data is actually
in printed documents

103
00:04:42,622 --> 00:04:44,281
or itís unpublished.

104
00:04:44,281 --> 00:04:44,423
There are about a Hundred
thousand publications
or itís unpublished.

105
00:04:44,423 --> 00:04:46,904
There are about a Hundred
thousand publications

106
00:04:47,278 --> 00:04:50,700
each year in neuroscience,
but unfortunately

107
00:04:51,061 --> 00:04:54,717
a print publication
or a .PDF is not

108
00:04:55,079 --> 00:04:56,894
a machine accessible way

109
00:04:57,218 --> 00:05:00,018
to get data or even
to get knowledge.

110
00:05:00,297 --> 00:05:02,940
It really requires
reading the paper

111
00:05:03,203 --> 00:05:07,829
understanding what is
talked about and seeing

112
00:05:08,107 --> 00:05:10,861
if you can extract data
from that paper manually.

113
00:05:11,154 --> 00:05:12,375
And thatís
a massive challenge

114
00:05:12,748 --> 00:05:16,326
itís not an efficient way for
the future of sharing data.

115
00:05:16,627 --> 00:05:19,201
What we see on this
graph is that there

116
00:05:19,498 --> 00:05:21,271
is organized big data

117
00:05:21,566 --> 00:05:23,537
in the Allen Institute
for Brain Science

118
00:05:23,830 --> 00:05:26,191
is probably the best
example of generating

119
00:05:26,406 --> 00:05:31,469
high quality large scale data,
but as I was saying

120
00:05:31,749 --> 00:05:35,301
most of the data
is actually unpublished

121
00:05:35,301 --> 00:05:39,420
or dark data or itís
referred to in papers.

122
00:05:39,642 --> 00:05:42,796
And thereís a big challenge
of how do we discover it

123
00:05:43,105 --> 00:05:44,679
how do we find it,
how do we organize it

124
00:05:44,981 --> 00:05:46,198
how do we make
it accessible?

125
00:05:46,761 --> 00:05:48,869
And the way that
you do that

126
00:05:49,215 --> 00:05:53,073
youíve got to be able
to make it possible

127
00:05:53,073 --> 00:05:57,304
to combine data, so in order
to find the small data

128
00:05:57,541 --> 00:06:00,569
and to make it
possible to combine it

129
00:06:00,773 --> 00:06:04,210
to make big data,
is that youíve got to make

130
00:06:04,414 --> 00:06:06,209
that small data discoverable

131
00:06:06,477 --> 00:06:09,060
youíve got to make it
machine accessible

132
00:06:09,342 --> 00:06:12,444
youíve got to use
the standardized meta data

133
00:06:12,687 --> 00:06:18,358
data types, data structures,
and identify

134
00:06:18,358 --> 00:06:21,350
which data has actually
been produced using

135
00:06:21,554 --> 00:06:23,631
a compatible
experimental method

136
00:06:23,835 --> 00:06:26,729
or from a compatible
experimental context

137
00:06:26,945 --> 00:06:30,151
from which data
can be compared

138
00:06:30,430 --> 00:06:31,672
and thatís
a massive challenge.

139
00:06:32,009 --> 00:06:35,342
Now, there are different
ways of organizing data.

140
00:06:35,553 --> 00:06:40,995
One of those is to put them
into folders on a hard drive

141
00:06:41,274 --> 00:06:44,881
and this is quite common
when you ask somebody

142
00:06:44,881 --> 00:06:47,491
to share their data,
very often it comes in folders

143
00:06:47,600 --> 00:06:52,465
in sets of different files,
and you navigate the folders

144
00:06:52,674 --> 00:06:55,176
to find the pieces of data
that youíre looking for.

145
00:06:55,488 --> 00:06:58,835
Now, a somewhat more
sophisticated approach

146
00:06:59,049 --> 00:07:02,400
is to actually have searchable
meta data that tags

147
00:07:02,695 --> 00:07:06,649
this data with properties
that are then searchable

148
00:07:06,863 --> 00:07:08,581
and this gives you
a lot of flexibility

149
00:07:09,004 --> 00:07:11,624
and how you can discover
and access the data.

150
00:07:11,843 --> 00:07:16,123
So, we really thing that
having meta data annotations

151
00:07:16,123 --> 00:07:19,974
for the data files
and making that searchable

152
00:07:19,974 --> 00:07:23,044
is really key to having
a much more flexible way

153
00:07:23,044 --> 00:07:25,220
to discovering
and accessing the data.

154
00:07:25,440 --> 00:07:29,436
So, there are three main
classes of meta data.

155
00:07:29,673 --> 00:07:31,325
Thereís descriptive
meta data

156
00:07:31,581 --> 00:07:35,315
and thatís really the data
that describes the key

157
00:07:35,535 --> 00:07:39,123
properties of the data for
discovery and identification.

158
00:07:39,343 --> 00:07:43,716
That includes things like
the title, the abstract

159
00:07:43,923 --> 00:07:46,487
the author,
maybe keywords that

160
00:07:46,749 --> 00:07:49,596
help identify the data set.

161
00:07:49,830 --> 00:07:52,735
Structural meta data
is information about

162
00:07:52,735 --> 00:07:57,140
the structure of
the different pieces of data

163
00:07:57,140 --> 00:07:59,765
how are they put together,
for example in a document

164
00:07:59,765 --> 00:08:02,282
how are the pages ordered
to make chapters.

165
00:08:02,529 --> 00:08:07,398
Administrative meta data
is actually that meta

166
00:08:07,624 --> 00:08:09,987
data that provides information

167
00:08:09,987 --> 00:08:13,311
on how that resource can
be accessed, by who

168
00:08:13,745 --> 00:08:19,437
what file type is it, it really
helps provide information

169
00:08:19,437 --> 00:08:23,475
about who can, who
should and what ways

170
00:08:23,681 --> 00:08:26,977
in which that data set
can be accessed.

171
00:08:27,357 --> 00:08:28,774
And thatís
important for things

172
00:08:28,774 --> 00:08:29,977
like protecting privacy

173
00:08:30,230 --> 00:08:35,555
or knowing when
the data set actually

174
00:08:35,758 --> 00:08:37,384
hasnít been accessed
for a long time

175
00:08:37,637 --> 00:08:39,522
and can be
archived to tape.

176
00:08:39,789 --> 00:08:42,038
But coming out of
the laboratory

177
00:08:42,038 --> 00:08:44,655
thatís really the point where
you want to have

178
00:08:44,655 --> 00:08:47,226
the richest meta data
annotations, in fact

179
00:08:47,226 --> 00:08:48,685
one of the greatest
challenges

180
00:08:48,685 --> 00:08:51,232
in current
neuroscience is that

181
00:08:51,524 --> 00:08:54,619
when you get a data set
it usually it doesnít have

182
00:08:54,619 --> 00:08:54,914
the meta data
that you would
when you get a data set
it usually it doesnít have

183
00:08:54,914 --> 00:08:55,905
the meta data
that you would

184
00:08:56,184 --> 00:08:58,076
need to actually understand
the contents

185
00:08:58,283 --> 00:09:00,859
and it would be a lot of work
for the experimenter

186
00:09:01,094 --> 00:09:03,315
to go back and add
that meta data.

187
00:09:03,525 --> 00:09:05,261
So, weíre really
advocating that

188
00:09:05,529 --> 00:09:07,155
at the point of data capture

189
00:09:07,386 --> 00:09:09,951
in the laboratory
that you capture

190
00:09:10,187 --> 00:09:11,685
all the meta data needed

191
00:09:11,933 --> 00:09:14,635
and some of the best practices
that we would advocate

192
00:09:14,887 --> 00:09:16,952
is using the electronic
note books

193
00:09:16,952 --> 00:09:18,775
use of the laboratory
information

194
00:09:19,034 --> 00:09:20,074
management systems

195
00:09:20,388 --> 00:09:24,563
electronically capture
the details of the specimen.

196
00:09:24,812 --> 00:09:25,920
What species is it?

197
00:09:25,920 --> 00:09:28,978
What experimental
protocol are you using?

198
00:09:28,978 --> 00:09:32,744
What is the data captured
from specific experiments?

199
00:09:33,010 --> 00:09:37,063
Document the experimental
design that includes

200
00:09:37,063 --> 00:09:42,261
having the hypothesis clearly
documented the objectives

201
00:09:42,261 --> 00:09:44,385
the protocols are really critical

202
00:09:44,385 --> 00:09:46,752
and the provenance in terms
of which data samples

203
00:09:46,997 --> 00:09:50,120
came from which specimens,
and so on.

204
00:09:50,480 --> 00:09:53,028
Use standardized
vocabulariesí

205
00:09:53,313 --> 00:09:55,229
when recoding
meta data values.

206
00:09:55,229 --> 00:09:59,123
This is really essential because
in the end when you

207
00:09:59,123 --> 00:10:01,233
want to analyze what
you discovered

208
00:10:01,494 --> 00:10:05,215
you want to be as consistent
and as rigorous as possible

209
00:10:05,512 --> 00:10:07,640
in the way that you annotate the data.

210
00:10:07,933 --> 00:10:10,544
And also, finally,
curate the data

211
00:10:10,854 --> 00:10:13,435
when youíre selecting
the key set of data

212
00:10:13,683 --> 00:10:15,220
that is used for
the publication

213
00:10:15,448 --> 00:10:17,732
or is used to be shared
with the community

214
00:10:18,072 --> 00:10:21,603
select the high-quality data,
make sure that you flag

215
00:10:21,869 --> 00:10:24,893
and remove the data with
questionable quality.

216
00:10:25,245 --> 00:10:29,938
You as the experimenter really
are the best person to judge

217
00:10:29,938 --> 00:10:31,810
and the best time to make
that decision is when

218
00:10:32,346 --> 00:10:34,217
youíre very familiar
with the data that

219
00:10:34,478 --> 00:10:36,431
has been captured
from the experiment.

220
00:10:36,983 --> 00:10:39,124
One of the additional
challenges is what

221
00:10:39,399 --> 00:10:41,906
meta data is really needed.

222
00:10:42,150 --> 00:10:43,916
How do you find
neuroscience

223
00:10:44,169 --> 00:10:45,955
data set if youíre talking

224
00:10:45,955 --> 00:10:48,905
about any possible type
of neuroscience data set?

225
00:10:49,220 --> 00:10:51,562
And this is a big challenge,
and it still remains

226
00:10:51,790 --> 00:10:54,481
to be addressed by
the community in terms

227
00:10:54,729 --> 00:10:59,274
of setting the common
standards od what is

228
00:10:59,274 --> 00:11:00,858
the minimal meta data

229
00:11:01,385 --> 00:11:03,400
needed to describe
a neuroscience data set.

230
00:11:03,400 --> 00:11:07,149
Here weíve developed
an initial proposal

231
00:11:07,386 --> 00:11:10,150
we want to see this
developed further

232
00:11:10,150 --> 00:11:12,009
in collaboration with
the community

233
00:11:12,291 --> 00:11:13,831
but also adopted widely.

234
00:11:14,246 --> 00:11:17,160
So, what our proposal
is what we call

235
00:11:17,375 --> 00:11:19,998
ìThe Minimal Information
for Neuroscience Datasetsî

236
00:11:20,277 --> 00:11:21,871
M.I.N.D.S. And that means

237
00:11:22,129 --> 00:11:26,129
what that includes is
actually capturing details

238
00:11:26,610 --> 00:11:31,191
of the subject of the experiment,
the species, the strain, the sex

239
00:11:31,488 --> 00:11:35,048
the methods used,
the protocols

240
00:11:35,251 --> 00:11:37,078
the equipment,
and the parameters

241
00:11:37,313 --> 00:11:38,999
used to perform
the experiment

242
00:11:39,328 --> 00:11:43,109
the classification,
what is the data category

243
00:11:43,374 --> 00:11:44,765
the data format,
the cell type

244
00:11:45,046 --> 00:11:46,827
the brain location

245
00:11:47,299 --> 00:11:50,437
where in the brain
in a standard Atlas

246
00:11:50,764 --> 00:11:52,568
either in terms
of coordinates

247
00:11:52,942 --> 00:11:55,070
or in terms of
just standardized

248
00:11:55,070 --> 00:11:56,879
names for that
brain region

249
00:11:57,124 --> 00:12:00,331
was this data captured,
who other contributors

250
00:12:00,586 --> 00:12:01,799
and what are
their affiliations

251
00:12:02,048 --> 00:12:04,550
and ideally identify those
contributors by something

252
00:12:04,550 --> 00:12:07,953
like an Orchid, a standard
dentifier for authors

253
00:12:07,953 --> 00:12:12,467
so they can get credit for
making their data available?

254
00:12:12,750 --> 00:12:14,958
And then, importantly,
and URL

255
00:12:15,233 --> 00:12:19,468
or a persistent identifier,
and this is something

256
00:12:19,468 --> 00:12:22,754
like a DOY that allows
you to actually go online

257
00:12:23,004 --> 00:12:25,266
and directly access
the raw data.

258
00:12:25,501 --> 00:12:27,850
So that URL is the key part of

259
00:12:28,110 --> 00:12:30,018
the Minimal Information for
Neuroscience Datasets.

260
00:12:30,708 --> 00:12:33,485
So, in this session we
talked about how

261
00:12:33,485 --> 00:12:35,717
neuroscience data
is very heterogenous

262
00:12:35,983 --> 00:12:38,578
and some of the challenges
in organizing it

263
00:12:38,844 --> 00:12:41,095
described to you
what meta data

264
00:12:41,443 --> 00:12:44,580
is and how we can use meta
data to organize data sets

265
00:12:44,940 --> 00:12:47,454
and Iíve also described
to you M.I.N.D.S.

266
00:12:47,722 --> 00:12:50,095
itís a proposed initial
standard for a minimal

267
00:12:50,406 --> 00:12:52,663
meta data set for
neuroscience data

268
00:12:53,194 --> 00:12:56,054
and we thing thatís really
essential to starting

269
00:12:56,289 --> 00:12:58,223
to get the broader
community to consistently

270
00:12:58,466 --> 00:13:00,879
annotate and organize their data.

