1
00:00:31,395 --> 00:00:35,033
Hello and welcome
to the last lesson of this MOOC.

2
00:00:35,233 --> 00:00:37,223
It is devoted
to augmented reality,

3
00:00:37,423 --> 00:00:41,011
a computer technology that allows 
to superimpose a virtual model

4
00:00:41,211 --> 00:00:44,136
in 2 or 3 dimensions, to the 
perception that we have

5
00:00:44,342 --> 00:00:46,591
of reality and this, in real time.

6
00:00:46,791 --> 00:00:51,061
The combination of augmented reality
with geographic information systems

7
00:00:51,261 --> 00:00:53,421
offers interesting prospects

8
00:00:53,621 --> 00:00:56,989
and it is this technological coupling
that we will present to you.

9
00:00:57,189 --> 00:01:00,797
The goals of this lesson are
to explain the technology

10
00:01:00,997 --> 00:01:03,997
of augmented reality and then
to present some examples

11
00:01:04,197 --> 00:01:06,422
of integration of augmented 
reality with

12
00:01:06,634 --> 00:01:08,886
geographic information
system applications.

13
00:01:09,086 --> 00:01:12,086
After this lesson, you will be 
able to restore the principle

14
00:01:12,286 --> 00:01:14,052
of the augmented reality functioning,

15
00:01:14,252 --> 00:01:17,002
to explain what can the
advantages of coupling be

16
00:01:17,202 --> 00:01:19,756
between augmented reality
and geographic information system

17
00:01:19,956 --> 00:01:22,956
and to give a few examples
of applications for which

18
00:01:23,156 --> 00:01:25,105
this coupling was carried out.

19
00:01:25,542 --> 00:01:27,930
We are going first to explain the
functioning

20
00:01:28,130 --> 00:01:31,443
of the augmented reality
and then evoke the combination

21
00:01:31,643 --> 00:01:35,565
between this technology and
the GIS before presenting 2 examples.

22
00:01:39,499 --> 00:01:41,189
So what is the augmented reality?

23
00:01:41,389 --> 00:01:44,389
This is the question
we asked Jens Ingensand,

24
00:01:44,589 --> 00:01:47,833
professor of geoinformatics at
the G2C institute

25
00:01:48,033 --> 00:01:51,343
of the "Haute Ecole d'Informatique
et de Gestion" of the canton of Vaud

26
00:01:51,543 --> 00:01:53,797
located in Yverdon-les-Bains.

27
00:01:54,022 --> 00:01:58,234
The augmented reality 
is a technology which is about

28
00:01:58,434 --> 00:02:01,916
superimposing virtual
information to the reality.

29
00:02:02,117 --> 00:02:05,149
So very often, we use
devices like this one,

30
00:02:05,349 --> 00:02:08,349
so a tablet
or also a smartphone,

31
00:02:08,549 --> 00:02:11,433
and these devices, they have a camera

32
00:02:11,633 --> 00:02:15,295
and then they have 
accelerometers and a GPS.

33
00:02:15,495 --> 00:02:20,194
This allows to determine 
the exact position

34
00:02:20,394 --> 00:02:25,088
of the person who uses the device
and then it also allows to determine

35
00:02:25,288 --> 00:02:28,684
what is the visible
area through the camera.

36
00:02:28,884 --> 00:02:33,454
As a result, with these information
it is possible to superimpose spatial information

37
00:02:33,654 --> 00:02:36,403
through that interface.

38
00:02:36,603 --> 00:02:40,362
Then we can make things visible

39
00:02:40,562 --> 00:02:43,249
which are otherwise not
visible in the environment.

40
00:02:44,737 --> 00:02:49,744
In fact, it was already in 1901 that
the american writer Lyman Frank Baum,

41
00:02:49,944 --> 00:02:52,697
the author of the novel for children
"The magician of Oz",

42
00:02:52,897 --> 00:02:56,537
imagines some glasses that would
allow their wearers to see appearing

43
00:02:56,737 --> 00:03:00,204
on the forehead of the people that 
they meet a letter that would correspond

44
00:03:00,404 --> 00:03:01,618
to their characters.

45
00:03:01,818 --> 00:03:04,693
In 1960, Morton Heilig

46
00:03:04,891 --> 00:03:09,026
invented an immersive cinema camera
called the sensorama.

47
00:03:09,226 --> 00:03:12,454
The viewer is immersed
in a visual,

48
00:03:12,654 --> 00:03:15,655
olfactory and sonorous environment 
associated to vibrations.

49
00:03:15,855 --> 00:03:19,954
The increase in reality
is made by superimposition

50
00:03:20,154 --> 00:03:23,154
of sensory effects
that are synchronized with the image.

51
00:03:23,354 --> 00:03:28,683
A little later in 1968 Intel releases 
the first integrated microprocessor.

52
00:03:28,883 --> 00:03:33,342
Ivan Sutherland with two
Harvard students develop

53
00:03:33,542 --> 00:03:36,542
an image processing software
which constitutes the first application

54
00:03:36,742 --> 00:03:38,160
of augmented reality.

55
00:03:38,360 --> 00:03:43,393
Then in 1972, Myron Krueger invents
the videoplace

56
00:03:43,593 --> 00:03:46,593
which makes interactions
with virtual objects possible.

57
00:03:46,793 --> 00:03:51,060
And in 1978, Steve Mann
creates an electronic eye

58
00:03:51,260 --> 00:03:54,100
of augmented reality called
Digital Eye Glass.

59
00:03:54,300 --> 00:03:57,517
And from this date,
it is the technological evolution

60
00:03:57,717 --> 00:03:59,776
of various components that has made 
the augmented reality progress, 

61
00:03:59,976 --> 00:04:04,106
the augmented reality being very demanding
in terms of calculation power.

62
00:04:04,306 --> 00:04:08,448
There is a clear turning
point from 1980

63
00:04:08,648 --> 00:04:12,727
with the release of the
Motorola 68000 32-bit processor.

64
00:04:13,664 --> 00:04:17,093
The principle of the functioning
was developed in 1972

65
00:04:17,293 --> 00:04:19,654
by Krueger and it is
schematized in this figure.

66
00:04:19,854 --> 00:04:22,794
We capture an image
of the reality,

67
00:04:22,994 --> 00:04:24,584
the images are collected
in real time

68
00:04:24,784 --> 00:04:27,097
by an augmented reality software.

69
00:04:27,297 --> 00:04:29,889
The software detects predefined
catching points,

70
00:04:30,089 --> 00:04:33,546
here the hand, but it can be also GPS
coordinates for example.

71
00:04:33,746 --> 00:04:36,418
And the software selects
the information associated

72
00:04:36,618 --> 00:04:38,395
to the catchment point, 
here the ball.

73
00:04:38,595 --> 00:04:41,378
Next, the real image
is augmented by this information

74
00:04:41,578 --> 00:04:45,345
then projected on a screen
or on glasses or on a tablet.

75
00:04:45,545 --> 00:04:48,981
And the algorithm runs in 
a loop in real time

76
00:04:49,181 --> 00:04:50,492
and in interactivity.

77
00:04:58,043 --> 00:05:01,392
So the augmented reality
allows to place precisely

78
00:05:01,592 --> 00:05:04,592
virtual objects in shots of reality.

79
00:05:04,792 --> 00:05:08,728
Boeing, for example, had
the idea to use this technology

80
00:05:08,928 --> 00:05:12,816
in its assembly lines by superimposing 
by augmented reality

81
00:05:13,016 --> 00:05:15,756
the assembly instructions
directly on the pieces.

82
00:05:15,956 --> 00:05:20,011
So if we consider one of
the trades of geoinformatics,

83
00:05:20,211 --> 00:05:23,891
what interest can we find
in combining augmented reality

84
00:05:24,091 --> 00:05:26,427
with GIS?

85
00:05:26,902 --> 00:05:29,834
So we can say that GIS and 
augmented reality

86
00:05:30,034 --> 00:05:33,129
are relatively complementary, 
but we can also say

87
00:05:33,329 --> 00:05:38,415
that the augmented reality 
also brings another vision

88
00:05:38,615 --> 00:05:40,802
to the geographic information.

89
00:05:41,002 --> 00:05:43,656
First of all,
we can see that in a GIS,

90
00:05:43,854 --> 00:05:47,483
most of the time, we
use the data in 2 dimensions

91
00:05:47,683 --> 00:05:50,151
so we create for example
a two-dimensional map.

92
00:05:50,351 --> 00:05:54,414
And what happens is that 
for the user,

93
00:05:54,614 --> 00:05:57,342
the user who creates the map or 
the person who sees the map,

94
00:05:57,542 --> 00:06:02,262
he has to do a recoding of the 
two-dimensional information to reality.

95
00:06:02,462 --> 00:06:04,822
For example here
we have contour lines

96
00:06:05,022 --> 00:06:07,163
and they are very close.

97
00:06:07,363 --> 00:06:11,039
It means that we have to 
recode this information

98
00:06:11,239 --> 00:06:14,837
and then understand that as
these contour lines are close,

99
00:06:15,037 --> 00:06:17,106
there is a steep slope,
so you have to imagine

100
00:06:17,306 --> 00:06:20,306
that at that place,
there is a certain slope.

101
00:06:20,506 --> 00:06:26,705
Whilst with the augmented reality
this recoding does not take place

102
00:06:26,905 --> 00:06:29,532
because we directly see
the reality then we directly see

103
00:06:29,732 --> 00:06:32,455
the virtual information
superimposed to the reality.

104
00:06:32,655 --> 00:06:38,680
The second thing is that there
is a certain democratization

105
00:06:38,880 --> 00:06:41,857
at the level of geographical
information through augmented reality.

106
00:06:42,145 --> 00:06:45,232
You have to know that GIS
are very often restricted

107
00:06:45,432 --> 00:06:47,566
to a very targeted audience
so there are few users

108
00:06:47,766 --> 00:06:50,766
who know how to use a GIS.
And with augmented reality,

109
00:06:50,966 --> 00:06:53,966
as now almost everyone has a tablet or

110
00:06:54,166 --> 00:06:58,277
a smartphone, we can make these
geographic data accessible

111
00:06:58,477 --> 00:07:02,579
when they are otherwise just
restricted to very targeted audience.

112
00:07:10,393 --> 00:07:13,683
We are going now to present
2 examples of application

113
00:07:13,883 --> 00:07:16,883
which incorporate augmented reality
and geographic information.

114
00:07:17,083 --> 00:07:20,449
The first example is a
project called biosentiers

115
00:07:20,649 --> 00:07:24,348
and whose aim is to raise awareness
to urban biodiversity

116
00:07:24,548 --> 00:07:27,215
whilst encouraging the users
to carry out actions

117
00:07:27,415 --> 00:07:30,853
in favor of the latter, one of which 
being the capture of new observations.

118
00:07:31,053 --> 00:07:35,414
The augmented reality facilitates
the collaborative aspects

119
00:07:35,614 --> 00:07:36,917
as we will see.

120
00:07:37,117 --> 00:07:42,430
Jens Ingensand explains the 
details of this project.

121
00:07:43,455 --> 00:07:47,082
So the biosentiers project
is a project we have at the HEIG

122
00:07:47,282 --> 00:07:50,282
in Yverdon-les-Bains.
It is a project that aims to develop

123
00:07:50,482 --> 00:07:53,182
an augmented reality application.

124
00:07:53,395 --> 00:07:57,558
This application will 
be used by students

125
00:07:57,758 --> 00:08:02,106
who will go to the station
of Yverdon-les-Bains,

126
00:08:02,306 --> 00:08:05,237
they will go with their teachers

127
00:08:05,437 --> 00:08:08,437
from this station to 
the Champ-Pittet center.

128
00:08:08,637 --> 00:08:11,637
This center is a nature reserve.

129
00:08:11,837 --> 00:08:15,610
So these students will go
to the station

130
00:08:15,810 --> 00:08:19,611
and then they will be able to use
this augmented reality application

131
00:08:19,811 --> 00:08:22,374
and see species along the way,

132
00:08:22,574 --> 00:08:25,386
so birds, plants, trees,

133
00:08:25,586 --> 00:08:27,000
or butterflies for example.

134
00:08:27,200 --> 00:08:31,242
Then they will be able to
click on these objects and learn

135
00:08:31,442 --> 00:08:34,442
several things in relation 
to these species.

136
00:08:34,642 --> 00:08:39,027
What is interesting also,
they will learn which species live

137
00:08:39,227 --> 00:08:41,651
in the city, which species live
outside the city

138
00:08:41,851 --> 00:08:45,497
and then they will be able to see, 
from the station to Champ-Pittet,

139
00:08:45,697 --> 00:08:47,678
an explosion in the number of species.

140
00:08:47,878 --> 00:08:51,402
Close to the station, they will 
maybe see just a few birds,

141
00:08:51,602 --> 00:08:55,990
and towards the center
there are hundreds and thousands

142
00:08:56,190 --> 00:08:59,086
of different species
that will be visible.

143
00:09:01,811 --> 00:09:05,660
The other example we will present
is part of a didactic approach

144
00:09:05,860 --> 00:09:08,860
and falls into the category 
of what is called

145
00:09:09,060 --> 00:09:10,311
the tangible interfaces.

146
00:09:10,511 --> 00:09:13,511
The Augmented Reality Sandbox

147
00:09:13,711 --> 00:09:17,494
lets students learn
the basics concept in topography

148
00:09:17,694 --> 00:09:20,694
and generate contour lines 
with the aim to create 

149
00:09:20,894 --> 00:09:22,755
topographic maps by hand.

150
00:09:22,955 --> 00:09:25,955
This installation also
makes it easier to learn

151
00:09:26,155 --> 00:09:28,893
Earth sciences, one of which 
major challenges

152
00:09:29,093 --> 00:09:31,592
is the visualization of
processes that occur

153
00:09:31,792 --> 00:09:34,792
on large spatial and temporal scales.

154
00:09:34,992 --> 00:09:40,668
The Sandbox consists of
a sandbox of 100 x 75 x 20 cm

155
00:09:40,868 --> 00:09:45,076
filled with 50 dm2 of fine white sand.

156
00:09:45,276 --> 00:09:49,244
A Kinect for Xbox camera
and a beamer

157
00:09:49,444 --> 00:09:52,149
are on top of the tray by 1 meter.

158
00:09:52,349 --> 00:09:55,349
The size of the sandbox is 
limited by the

159
00:09:55,549 --> 00:09:58,091
minimum and maximum detection 
distances of the Kinect

160
00:09:58,291 --> 00:10:00,202
and by the desired resolution.

161
00:10:00,402 --> 00:10:05,762
The ratio of 4 to 3 between the length
and the width of the Sandbox

162
00:10:05,962 --> 00:10:09,418
corresponds to the field of vision
of the Kinect and the beamer.

163
00:10:10,006 --> 00:10:12,568
A Kinect is made up of a color camera

164
00:10:12,818 --> 00:10:15,266
and an infrared depth camera.

165
00:10:15,466 --> 00:10:18,023
The depth camera uses an approach

166
00:10:18,223 --> 00:10:21,223
of structured light according
to which a luminous pattern

167
00:10:21,423 --> 00:10:22,920
is sent to the sand.

168
00:10:23,120 --> 00:10:25,859
Then the camera retrieves
the reflected signal

169
00:10:26,059 --> 00:10:29,333
and can, from the deformation
of the pattern sent,

170
00:10:29,533 --> 00:10:32,098
reconstruct the geometry 
of the surface.

171
00:10:32,698 --> 00:10:35,798
The computer to which the kinect
and the beamer are connected

172
00:10:35,998 --> 00:10:38,696
is powerful enough and is equipped

173
00:10:38,896 --> 00:10:40,514
with a powerful graphic map.

174
00:10:40,714 --> 00:10:44,115
The Augmented Reality Sandbox
software developed by

175
00:10:44,315 --> 00:10:47,815
the geology institute of the
University of Davis in California

176
00:10:48,015 --> 00:10:51,015
is open source and runs
under Linux Mint.

177
00:10:51,215 --> 00:10:54,745
The augmented reality
computer device

178
00:10:54,945 --> 00:10:57,762
sets a closed loop consisting
of the following steps.

179
00:10:57,962 --> 00:11:03,019
First, the kinect receives 
a 480 x 640 matrix

180
00:11:03,219 --> 00:11:06,404
of raw distance with
a frequency of 30 frames per second.

181
00:11:06,779 --> 00:11:09,279
These data go into
a statistical filter

182
00:11:09,479 --> 00:11:13,570
who has 3 goals. The first is
to identify moving objects

183
00:11:13,770 --> 00:11:15,553
like here the hands of the user.

184
00:11:15,753 --> 00:11:19,793
Next, it is to reduce
the signal disturbances

185
00:11:19,993 --> 00:11:23,393
or the noise and ultimately 
it is to compensate

186
00:11:23,593 --> 00:11:25,600
for the missing data in 
the data flow

187
00:11:25,800 --> 00:11:26,699
of the depth of the Kinect.

188
00:11:27,699 --> 00:11:30,991
The resulting topographic
surface is then projected

189
00:11:31,191 --> 00:11:33,786
by the beamer so that it 
corresponds exactly

190
00:11:33,999 --> 00:11:35,861
to that formed in the sand.

191
00:11:36,761 --> 00:11:40,207
The software uses a spectral 
colorimetric palette,

192
00:11:40,407 --> 00:11:42,789
blue for lower altitude areas

193
00:11:42,989 --> 00:11:47,410
to red through green and white 
for the highest points.

194
00:11:47,822 --> 00:11:51,921
The Sandbox is a teaching aid 
for a variety

195
00:11:52,134 --> 00:11:54,744
of subjects related to the Earth 
sciences in general:

196
00:11:54,944 --> 00:11:59,073
the geology, the geomorphology, 
the topography, map reading

197
00:11:59,273 --> 00:12:03,209
on the basis of contour lines 
but also the watersheds

198
00:12:03,434 --> 00:12:06,767
and the runoff problems in hydrology.

199
00:12:07,042 --> 00:12:09,492
Three typical experiments
can be performed

200
00:12:09,692 --> 00:12:13,396
with the Sandbox. On one hand,
the reconstruction of an existing relief

201
00:12:13,596 --> 00:12:16,519
which is based on the capacity
of the device to project

202
00:12:16,719 --> 00:12:25,739
contour lines on the sand,

203
00:12:18,850 --> 00:12:21,171
secondly, the modeling of
historical evolution

204
00:12:21,371 --> 00:12:24,621
of a landscape that exploits
a relief comparison algorithm,

205
00:12:24,821 --> 00:12:27,820
and thirdly, watershed

206
00:12:28,020 --> 00:12:30,715
and runoff analysis based on
a hydrological model

207
00:12:30,915 --> 00:12:33,679
and simulations of fluid flows.

208
00:12:33,879 --> 00:12:35,892
The Sandbox also enables to develop

209
00:12:36,092 --> 00:12:38,905
research activities
such as the integration of different

210
00:12:39,117 --> 00:12:42,567
modes of interaction
and various levels of interactivity

211
00:12:42,767 --> 00:12:44,841
or the aspects of graphical
semiology

212
00:12:45,041 --> 00:12:48,311
in the perspective of adopting,
depending on the phenomena represented,

213
00:12:48,498 --> 00:12:51,676
color palettes that optimize 
the visualization

214
00:12:51,876 --> 00:12:54,665
and thus the understanding
of the processes studied.

215
00:13:00,986 --> 00:13:03,986
There you go ! We are at 
the end of this lesson,

216
00:13:04,186 --> 00:13:07,081
the last of this introduction 
MOOC to the GIS.

217
00:13:07,281 --> 00:13:10,281
By way of perspectives
on the modes of exploitation

218
00:13:10,481 --> 00:13:12,636
and representation of
geographic information,

219
00:13:12,836 --> 00:13:16,378
we have presented
you how it is possible to combine

220
00:13:16,578 --> 00:13:19,578
the augmented reality
technology with spatial information.

221
00:13:19,778 --> 00:13:24,448
This area is evolving a lot on one hand
thanks to extraordinary progresses

222
00:13:24,648 --> 00:13:26,822
of image technologies and,
on the other hand,

223
00:13:27,022 --> 00:13:29,766
thanks to the enormous
increase in calculation capacity

224
00:13:29,966 --> 00:13:32,191
of computer equipments.

225
00:13:32,391 --> 00:13:35,221
Geographic coordinates
are used in algorithms

226
00:13:35,421 --> 00:13:37,982
which run in a loop to 
coordinate data flows

227
00:13:38,182 --> 00:13:41,182
between the equipments which
allow to augment the reality

228
00:13:41,382 --> 00:13:42,450
with virtual objects.

229
00:13:42,650 --> 00:13:45,650
These can appear at the right time

230
00:13:45,850 --> 00:13:49,200
and in the right place thanks
to the location of the users

231
00:13:49,400 --> 00:13:52,050
who are equipped
with tablets or smartphones

232
00:13:52,250 --> 00:13:54,011
and who move in the landscape.

233
00:13:54,211 --> 00:13:57,524
We have illustrated this
coupling with an application dedicated

234
00:13:57,736 --> 00:14:02,238
to the inventory of biodiversity
and an educational aid scheme

235
00:14:02,438 --> 00:14:05,126
but there are many
possible fields of application,

236
00:14:05,326 --> 00:14:08,222
mainly in the fields of air,

237
00:14:08,422 --> 00:14:11,422
marine, road and pedestrian navigation.

238
00:14:11,622 --> 00:14:15,350
So thank you for following this
online course until the end

239
00:14:15,550 --> 00:14:17,948
and good luck for the rest of your studies

240
00:14:18,148 --> 00:14:20,682
or for the implementation
of this new knowledge.

