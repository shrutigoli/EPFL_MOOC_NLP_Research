1
00:00:31,395 --> 00:00:35,033
Bonjour et bienvenue
dans la dernière leçon de ce MOOC.

2
00:00:35,233 --> 00:00:37,223
Elle est consacrée
à la réalité augmentée, 

3
00:00:37,423 --> 00:00:41,011
une technologie informatique qui permet
de superposer un modèle virtuel

4
00:00:41,211 --> 00:00:44,136
en 2 ou 3 dimensions,
à la perception que nous avons

5
00:00:44,342 --> 00:00:46,591
de la réalité et ceci,
en temps réel.

6
00:00:46,791 --> 00:00:51,061
La combinaison de la réalité augmentée
avec les systèmes d'information géographique

7
00:00:51,261 --> 00:00:53,421
offre des perspectives intéressantes

8
00:00:53,621 --> 00:00:56,989
et c'est ce couplage technologique
que nous allons vous présenter.

9
00:00:57,189 --> 00:01:00,797
Les buts de cette leçon sont
de vous expliquer la technologie

10
00:01:00,997 --> 00:01:03,997
de la réalité augmentée puis
de présenter quelques exemples

11
00:01:04,197 --> 00:01:06,422
d'intégration de la réalité augmentée
avec des applications

12
00:01:06,634 --> 00:01:08,886
de systèmes d'information géographique.

13
00:01:09,086 --> 00:01:12,086
Après cette leçon, vous serez capable
de restituer le principe

14
00:01:12,286 --> 00:01:14,052
de fonctionnement
de la réalité augmentée,

15
00:01:14,252 --> 00:01:17,002
d'expliquer quels peuvent être
les avantages du couplage

16
00:01:17,202 --> 00:01:19,756
entre réalité augmentée et
système d'information géographique

17
00:01:19,956 --> 00:01:22,956
et de citer quelques exemples
d'application pour lesquels

18
00:01:23,156 --> 00:01:25,105
ce couplage a été effectué.

19
00:01:25,542 --> 00:01:27,930
Nous allons dans un premier temps
expliquer le fonctionnement

20
00:01:28,130 --> 00:01:31,443
de la réalité augmentée
puis évoquer la combinaison

21
00:01:31,643 --> 00:01:35,565
entre cette technologie et les SIG
avant de présenter 2 exemples.

22
00:01:39,499 --> 00:01:41,189
Alors qu'est-ce que
la réalité augmentée ?

23
00:01:41,389 --> 00:01:44,389
C'est la question que nous avons posée
à Jens Ingensand,

24
00:01:44,589 --> 00:01:47,833
professeur de géoinformatique
à l'institut G2C

25
00:01:48,033 --> 00:01:51,343
de la Haute Ecole d'Informatique
et de Gestion du canton de Vaud

26
00:01:51,543 --> 00:01:53,797
située à Yverdon-les-Bains.

27
00:01:54,022 --> 00:01:58,234
Alors la réalité augmentée,
c'est une technologie où il s'agit

28
00:01:58,434 --> 00:02:01,916
de superposer des informations
virtuelles à la réalité.

29
00:02:02,117 --> 00:02:05,149
Donc très souvent, on utilise
des appareils comme celui-là,

30
00:02:05,349 --> 00:02:08,349
donc un tablette ou aussi
un smartphone,

31
00:02:08,549 --> 00:02:11,433
et puis ces appareils-là,
ils ont donc une caméra

32
00:02:11,633 --> 00:02:15,295
et puis ils ont des accéléromètres
et puis un GPS.

33
00:02:15,495 --> 00:02:20,194
Ça, ça permet de déterminer
la position exacte

34
00:02:20,394 --> 00:02:25,088
de celui qui utilise l'appareil
puis ça permet aussi de déterminer

35
00:02:25,288 --> 00:02:28,684
quelle est la zone visible
à travers la caméra.

36
00:02:28,884 --> 00:02:33,454
Du coup, avec ces informations-là,
on peut superposer des informations spatiales

37
00:02:33,654 --> 00:02:36,403
à travers cette interface-là.

38
00:02:36,603 --> 00:02:40,362
Puis du coup, on peut rendre
des choses visibles

39
00:02:40,562 --> 00:02:43,249
qui ne sont autrement pas visibles
dans l'environnement.

40
00:02:44,737 --> 00:02:49,744
En fait, c'est en 1901 déjà
que l'écrivain américain Lyman Frank Baum,

41
00:02:49,944 --> 00:02:52,697
l'auteur du roman pour enfants
"Le magicien d'Oz",

42
00:02:52,897 --> 00:02:56,537
imagine des lunettes qui permettraient
à leurs porteurs de voir apparaître

43
00:02:56,737 --> 00:03:00,204
sur le front des gens qu'ils rencontrent 
une lettre qui correspondrait

44
00:03:00,404 --> 00:03:01,618
à leurs caractères. 

45
00:03:01,818 --> 00:03:04,693
En 1960, Morton Heilig

46
00:03:04,891 --> 00:03:09,026
invente un appareil de cinéma
immersif appelé le sensorama.

47
00:03:09,226 --> 00:03:12,454
Le spectateur est immergé 
dans un environnement visuel,

48
00:03:12,654 --> 00:03:15,655
olfactif et sonore associé
à des vibrations.

49
00:03:15,855 --> 00:03:19,954
L'augmentation de la réalité
est effectuée par surimposition

50
00:03:20,154 --> 00:03:23,154
d'effets sensoriels qui sont
synchronisés avec l'image.

51
00:03:23,354 --> 00:03:28,683
Un peu plus tard en 1968 sort
le premier microprocesseur intégré d'Intel.

52
00:03:28,883 --> 00:03:33,342
Ivan Sutherland avec deux étudiants
de l'université Harvard développent

53
00:03:33,542 --> 00:03:36,542
un logiciel de traitement d'images
qui constitue la première application

54
00:03:36,742 --> 00:03:38,160
de réalité augmentée.

55
00:03:38,360 --> 00:03:43,393
Ensuite en 1972, Myron Krueger
invente le videoplace

56
00:03:43,593 --> 00:03:46,593
qui rend possible les interactions
avec des objets virtuels. 

57
00:03:46,793 --> 00:03:51,060
Et en 1978, Steve Mann
crée un oeil électronique

58
00:03:51,260 --> 00:03:54,100
de réalité augmentée nommé
Digital Eye Glass.

59
00:03:54,300 --> 00:03:57,517
Et à partir de cette date,
c'est l'évolution technologique 

60
00:03:57,717 --> 00:03:59,776
des divers composants
qui a fait progresser

61
00:03:59,976 --> 00:04:04,106
la réalité augmentée, très exigeante
en terme de puissance de calcul.

62
00:04:04,306 --> 00:04:08,448
On note un net tournant
à partir de 1980

63
00:04:08,648 --> 00:04:12,727
avec la sortie du processeur
Motorola 68000 à 32-bit.

64
00:04:13,664 --> 00:04:17,093
Le principe du fonctionnement
à été mis au point en 1972

65
00:04:17,293 --> 00:04:19,654
par Krueger et il est schématisé
sur cette figure.

66
00:04:19,854 --> 00:04:22,794
On capture une image
de la réalité,

67
00:04:22,994 --> 00:04:24,584
les images sont collectées
en temps réel

68
00:04:24,784 --> 00:04:27,097
par un logiciel de réalité augmentée.

69
00:04:27,297 --> 00:04:29,889
Le logiciel détecte
des points d'accroche prédéfinis,

70
00:04:30,089 --> 00:04:33,546
ici la main, mais cela peut être
aussi des coordonnées GPS par exemple.

71
00:04:33,746 --> 00:04:36,418
Et le logiciel sélectionne
l'information associée

72
00:04:36,618 --> 00:04:38,395
au point d'accroche,
ici la balle.

73
00:04:38,595 --> 00:04:41,378
Ensuite, l'image réelle
est augmentée de cette information

74
00:04:41,578 --> 00:04:45,345
puis projetées sur un écran
ou sur des lunettes ou sur une tablette.

75
00:04:45,545 --> 00:04:48,981
Et l'algorithme tourne en boucle
en temps réel

76
00:04:49,181 --> 00:04:50,492
et en interactivité.

77
00:04:58,043 --> 00:05:01,392
Donc la réalité augmentée
permet de placer précisément

78
00:05:01,592 --> 00:05:04,592
des objets virtuels dans
des prises de vue de la réalité.

79
00:05:04,792 --> 00:05:08,728
Boeing a par exemple eu l'idée
de recourir à cette technologie

80
00:05:08,928 --> 00:05:12,816
dans ses chaînes d'assemblage
en superposant par réalité augmentée

81
00:05:13,016 --> 00:05:15,756
les instructions de montage
directement sur les pièces.

82
00:05:15,956 --> 00:05:20,011
Alors si l'on considère un des métiers
de la géoinformatique,

83
00:05:20,211 --> 00:05:23,891
quel intérêt peut-on trouver
à combiner la réalité augmentée

84
00:05:24,091 --> 00:05:26,427
avec les SIG ?

85
00:05:26,902 --> 00:05:29,834
Alors on peut dire que les SIG
et la réalité augmentée

86
00:05:30,034 --> 00:05:33,129
sont relativement complémentaires
mais on peut aussi dire 

87
00:05:33,329 --> 00:05:38,415
que la réalité augmentée,
ça apporte aussi une autre vision

88
00:05:38,615 --> 00:05:40,802
de l'information géographique.

89
00:05:41,002 --> 00:05:43,656
Tout d'abord, on peut voir
que dans un SIG,

90
00:05:43,854 --> 00:05:47,483
pour la plupart du temps, on utilise
les données en 2 dimensions

91
00:05:47,683 --> 00:05:50,151
donc on fait par exemple
un carte deux-dimensionnelle.

92
00:05:50,351 --> 00:05:54,414
Et du coup ce qu'il y a,
c'est que pour l'utilisateur,

93
00:05:54,614 --> 00:05:57,342
celui qui crée la carte ou aussi
celui qui voit la carte,

94
00:05:57,542 --> 00:06:02,262
il doit faire un recodage de l'information
deux-dimensionnelle à la réalité.

95
00:06:02,462 --> 00:06:04,822
Par exemple ici,
on a des courbes de niveau

96
00:06:05,022 --> 00:06:07,163
puis ces courbes de niveau
sont très proches.

97
00:06:07,363 --> 00:06:11,039
Ça veut dire qu'on est obligé
de recoder cette information-là

98
00:06:11,239 --> 00:06:14,837
puis de comprendre que comme
ces courbes de niveau sont proches,

99
00:06:15,037 --> 00:06:17,106
il y a une forte pente,
donc il faut s'imaginer

100
00:06:17,306 --> 00:06:20,306
qu'à cet endroit-là,
il y a une certaine pente.

101
00:06:20,506 --> 00:06:26,705
Tandis qu'avec la réalité augmentée,
ce recodage-là, il n'a plus lieu

102
00:06:26,905 --> 00:06:29,532
parce qu'on voit directement
la réalité puis on voit directement

103
00:06:29,732 --> 00:06:32,455
les informations virtuelles
superposées à la réalité.

104
00:06:32,655 --> 00:06:38,680
La deuxième chose, c'est
qu'il y a une certaine démocratisation

105
00:06:38,880 --> 00:06:41,857
au niveau de l'information géographique
à travers la réalité augmentée.

106
00:06:42,145 --> 00:06:45,232
Il faut voir que les SIG sont
très souvent restreints

107
00:06:45,432 --> 00:06:47,566
à un public très cible
donc il y a peu d'utilisateurs 

108
00:06:47,766 --> 00:06:50,766
qui savent utiliser un SIG.
Et puis avec la réalité augmentée,

109
00:06:50,966 --> 00:06:53,966
comme aujourd'hui quasiment
tout le monde a une tablette ou

110
00:06:54,166 --> 00:06:58,277
un smartphone, on peut donc rendre
accessible des données géographiques

111
00:06:58,477 --> 00:07:02,579
qui autrement sont juste restreintes
à un public très ciblé.

112
00:07:10,393 --> 00:07:13,683
Nous allons maintenant vous présenter
2 exemples d'application

113
00:07:13,883 --> 00:07:16,883
qui intègrent réalité augmentée
et information géographique.

114
00:07:17,083 --> 00:07:20,449
Le premier exemple est un projet
appelé biosentiers

115
00:07:20,649 --> 00:07:24,348
et dont le but est de sensibiliser
les utilisateurs à la biodiversité urbaine

116
00:07:24,548 --> 00:07:27,215
tout en les encourageant
à accomplir des actions

117
00:07:27,415 --> 00:07:30,853
en faveur de celle-ci dont la saisie
de nouvelles observations.

118
00:07:31,053 --> 00:07:35,414
La réalité augmentée facilite donc
les aspects collaboratifs

119
00:07:35,614 --> 00:07:36,917
comme nous allons le voir.

120
00:07:37,117 --> 00:07:42,430
Nous retrouvons Jens Ingensand
qui nous explique les détails de ce projet.

121
00:07:43,455 --> 00:07:47,082
Alors le projet biosentiers,
c'est un projet qu'on a à la HEIG 

122
00:07:47,282 --> 00:07:50,282
à Yverdon-les-Bains. C'est un projet
qui vise à développer

123
00:07:50,482 --> 00:07:53,182
une application de réalité augmentée.

124
00:07:53,395 --> 00:07:57,558
Puis cette application de réalité augmentée,
elle sera utilisée par des élèves

125
00:07:57,758 --> 00:08:02,106
qui vont descendre à la gare
d'Yverdon-les-Bains

126
00:08:02,306 --> 00:08:05,237
puis du coup, ils vont aller
avec leurs enseignants

127
00:08:05,437 --> 00:08:08,437
de la gare d'Yverdon-les-Bains
au centre Champ-Pittet.

128
00:08:08,637 --> 00:08:11,637
Le centre Champ-Pittet,
c'est une réserve naturelle.

129
00:08:11,837 --> 00:08:15,610
Puis ces élèves-là, ils vont donc
descendre à la gare

130
00:08:15,810 --> 00:08:19,611
et puis ils vont pouvoir utiliser
cette application de réalité augmentée

131
00:08:19,811 --> 00:08:22,374
et puis voir des espèces
le long du chemin

132
00:08:22,574 --> 00:08:25,386
donc comme des oiseaux, comme
des plantes, comme des arbres,

133
00:08:25,586 --> 00:08:27,000
comme des papillons. 

134
00:08:27,200 --> 00:08:31,242
Puis du coup, ils pourront cliquer
sur ces objets-là et puis apprendre

135
00:08:31,442 --> 00:08:34,442
plusieurs choses
par rapport aux espèces.

136
00:08:34,642 --> 00:08:39,027
Puis ce qui est intéressant aussi,
ils vont apprendre quelles espèces vivent

137
00:08:39,227 --> 00:08:41,651
en ville, quelles espèces vivent
en dehors de la ville

138
00:08:41,851 --> 00:08:45,497
et puis ils pourront voir, de la gare
jusqu'au centre Champ-Pittet,

139
00:08:45,697 --> 00:08:47,678
une explosion du nombre d'espèces.

140
00:08:47,878 --> 00:08:51,402
Proche de la gare, ils auront peut-être
juste quelques oiseaux qui sont visibles,

141
00:08:51,602 --> 00:08:55,990
tandis que vers le centre,
il y a des centaines et des milliers

142
00:08:56,190 --> 00:08:59,086
de différentes espèces
qui seront visibles.

143
00:09:01,811 --> 00:09:05,660
L'autre exemple que nous vous présentons
s'intègre dans une démarche didactique

144
00:09:05,860 --> 00:09:08,860
et entre dans la catégorie
de ce que l'on appelle

145
00:09:09,060 --> 00:09:10,311
les interfaces tangibles.

146
00:09:10,511 --> 00:09:13,511
Le bac à sable augmenté ou
Augmented Reality Sandbox

147
00:09:13,711 --> 00:09:17,494
permet d'apprendre aux élèves
les notions de base en topographie

148
00:09:17,694 --> 00:09:20,694
et à générer des courbes de niveau
en vue de créer à la main

149
00:09:20,894 --> 00:09:22,755
des cartes topographiques.

150
00:09:22,955 --> 00:09:25,955
Cette installation permet également
de faciliter l'apprentissage

151
00:09:26,155 --> 00:09:28,893
des sciences de la Terre
dont l'un des grands défis

152
00:09:29,093 --> 00:09:31,592
est la visualisation de processus
qui se produisent

153
00:09:31,792 --> 00:09:34,792
sur de grandes échelles spatiales
et temporelles.

154
00:09:34,992 --> 00:09:40,668
La Sandbox est constituée
d'un bac à sable de 100 x 75 x 20 cm

155
00:09:40,868 --> 00:09:45,076
rempli avec 50 dm2 de sable fin blanc.

156
00:09:45,276 --> 00:09:49,244
Une caméra Kinect for Xbox
et un projecteur vidéo ou beamer

157
00:09:49,444 --> 00:09:52,149
surmonte le fond du bac
d'1 mètre.

158
00:09:52,349 --> 00:09:55,349
La taille du bac à sable
est limitée par les distances

159
00:09:55,549 --> 00:09:58,091
de détection minimales et
maximales de la Kinect

160
00:09:58,291 --> 00:10:00,202
et par la résolution désirée.

161
00:10:00,402 --> 00:10:05,762
La ratio 4 pour 3 entre la longueur
et la largeur de la Sandbox

162
00:10:05,962 --> 00:10:09,418
correspond au champ de vision
de la Kinect et du beamer.

163
00:10:10,006 --> 00:10:12,568
Une Kinect est composée
d'une caméra couleur

164
00:10:12,818 --> 00:10:15,266
et d'une caméra infrarouge
de profondeur.

165
00:10:15,466 --> 00:10:18,023
La caméra de profondeur
utilise une approche

166
00:10:18,223 --> 00:10:21,223
de lumière structurée
selon laquelle un motif lumineux

167
00:10:21,423 --> 00:10:22,920
est envoyé sur le sable.

168
00:10:23,120 --> 00:10:25,859
Puis la caméra récupère
le signal réfléchi

169
00:10:26,059 --> 00:10:29,333
et peut, à partir de
la déformation du motif envoyé,

170
00:10:29,533 --> 00:10:32,098
reconstituer la géométrie
de la surface.

171
00:10:32,698 --> 00:10:35,798
L'ordinateur auquel sont reliés
la kinect et le beamer 

172
00:10:35,998 --> 00:10:38,696
est suffisamment puissant
et il est équipé

173
00:10:38,896 --> 00:10:40,514
d'une carte graphique performante.

174
00:10:40,714 --> 00:10:44,115
Le logiciel Augmented Reality Sandbox
développé par

175
00:10:44,315 --> 00:10:47,815
l'institut de géologie de l'université
de Davis en Californie

176
00:10:48,015 --> 00:10:51,015
est open source et tourne
sous Linux Mint.

177
00:10:51,215 --> 00:10:54,745
Le dispositif informatique
de réalité augmentée

178
00:10:54,945 --> 00:10:57,762
instaure une boucle fermée
constituée des étapes suivantes.

179
00:10:57,962 --> 00:11:03,019
D'abord, la kinect reçoit
une matrice 480 x 640

180
00:11:03,219 --> 00:11:06,404
de distance brut avec une fréquence
de 30 images par seconde.

181
00:11:06,779 --> 00:11:09,279
Ces données passent
dans un filtre statistique

182
00:11:09,479 --> 00:11:13,570
qui a 3 buts. Le premier est
d'identifier les objets en mouvement

183
00:11:13,770 --> 00:11:15,553
comme ici les mains
de l'utilisateur.

184
00:11:15,753 --> 00:11:19,793
Ensuite, il est de réduire
les perturbations du signal

185
00:11:19,993 --> 00:11:23,393
ou le bruit et finalement,
il est de compenser

186
00:11:23,593 --> 00:11:25,600
les données manquantes dans
le flux de données

187
00:11:25,800 --> 00:11:26,699
de profondeur de la Kinect.

188
00:11:27,699 --> 00:11:30,991
La surface topographique
résultante est ensuite projetée

189
00:11:31,191 --> 00:11:33,786
par le beamer de manière
à ce qu'elle corresponde exactement

190
00:11:33,999 --> 00:11:35,861
à celle qui est façonnée
dans le sable.

191
00:11:36,761 --> 00:11:40,207
Le logiciel utilise une palette
colorimétrique spectrale,

192
00:11:40,407 --> 00:11:42,789
du bleu pour les zones
de plus basse altitude

193
00:11:42,989 --> 00:11:47,410
au rouge en passant par le vert
et le blanc pour les points culminants.

194
00:11:47,822 --> 00:11:51,921
La Sandbox constitue un support
à l'enseignement pour une variété

195
00:11:52,134 --> 00:11:54,744
de sujets liés
aux sciences de la Terre en général :

196
00:11:54,944 --> 00:11:59,073
la géologie, la géomorphologie,
la topographie, la lecture de cartes

197
00:11:59,273 --> 00:12:03,209
sur la base des courbes de niveau
mais aussi, les bassins versants

198
00:12:03,434 --> 00:12:06,767
et les problèmes de ruissellement
en hydrologie.

199
00:12:07,042 --> 00:12:09,492
Trois expériences types
peuvent être effectuées

200
00:12:09,692 --> 00:12:13,396
avec la Sandbox. D'une part,
la reconstitution d'un relief existant

201
00:12:13,596 --> 00:12:16,519
qui repose sur la capacité
du dispositif à projeter

202
00:12:16,719 --> 00:12:25,739
des courbes de niveau sur le sable,

203
00:12:18,850 --> 00:12:21,171
deuxièmement, la modélisation
de l'évolution historique

204
00:12:21,371 --> 00:12:24,621
d'un paysage qui exploite
un algorithme de comparaison de relief,

205
00:12:24,821 --> 00:12:27,820
et troisièmement, l'analyse
de bassins versants

206
00:12:28,020 --> 00:12:30,715
et de ruissellements
basée sur un modèle hydrologique

207
00:12:30,915 --> 00:12:33,679
et des simulations de flux
de fluides.

208
00:12:33,879 --> 00:12:35,892
La Sandbox permet également
de développer

209
00:12:36,092 --> 00:12:38,905
des activités de recherche comme
l'intégration de différents

210
00:12:39,117 --> 00:12:42,567
modes d'interaction et de divers
niveaux d'interactivité

211
00:12:42,767 --> 00:12:44,841
ou encore les aspects
de sémiologie graphique

212
00:12:45,041 --> 00:12:48,311
dans la perpective d'adopter,
en fonction des phénomènes représentés,

213
00:12:48,498 --> 00:12:51,676
des palettes de couleurs
qui optimisent la visualisation

214
00:12:51,876 --> 00:12:54,665
et ainsi la compréhension des
processus étudiés.

215
00:13:00,986 --> 00:13:03,986
Et voila ! Nous sommes arrivés
au terme de cette leçon,

216
00:13:04,186 --> 00:13:07,081
la dernière de ce MOOC
d'introduction aux SIG.

217
00:13:07,281 --> 00:13:10,281
En guise de perspectives
sur les modes d'exploitation

218
00:13:10,481 --> 00:13:12,636
et de représentation de
l'information géographique,

219
00:13:12,836 --> 00:13:16,378
nous vous y avons présenté
comment il est possible de combiner

220
00:13:16,578 --> 00:13:19,578
la technologie de la réalité augmentée
avec l'information spatiale.

221
00:13:19,778 --> 00:13:24,448
Ce domaine est en pleine évolution
d'une part grâce aux progrès extraordinaires

222
00:13:24,648 --> 00:13:26,822
des technologies de l'image
et d'autre part,

223
00:13:27,022 --> 00:13:29,766
grâce à l'augmentation faramineuse
de la capacité de calcul

224
00:13:29,966 --> 00:13:32,191
des équipements informatiques.

225
00:13:32,391 --> 00:13:35,221
Les coordonnées géographiques
sont utilisées dans les algorithmes

226
00:13:35,421 --> 00:13:37,982
qui tournent en boucle
pour coordonner les flux de données

227
00:13:38,182 --> 00:13:41,182
entre les équipements qui permettent
d'augmenter la réalité

228
00:13:41,382 --> 00:13:42,450
aux moyens d'objets virtuels.

229
00:13:42,650 --> 00:13:45,650
Ces derniers peuvent apparaître
au bon moment

230
00:13:45,850 --> 00:13:49,200
et au bon endroit grâce
à la localisation des utilisateurs

231
00:13:49,400 --> 00:13:52,050
qui sont équipés de tablettes
ou de smartphones

232
00:13:52,250 --> 00:13:54,011
et qui se déplacent dans le paysage.

233
00:13:54,211 --> 00:13:57,524
Nous avons illustré ce couplage
avec une application dédiée

234
00:13:57,736 --> 00:14:02,238
à l'inventaire de la biodiversité
et un dispositif d'aide à l'enseignement

235
00:14:02,438 --> 00:14:05,126
mais nombreux sont les champs
d'application possible,

236
00:14:05,326 --> 00:14:08,222
principalement dans les domaines
de la navigation aérienne,

237
00:14:08,422 --> 00:14:11,422
marine, routière et piétonne.

238
00:14:11,622 --> 00:14:15,350
Alors merci d'avoir suivi ce cours
en ligne jusqu'à son terme

239
00:14:15,550 --> 00:14:17,948
et bon vent pour la suite
de vos études

240
00:14:18,148 --> 00:14:20,682
ou pour la mise en oeuvre
de ces nouvelles connaissances.

