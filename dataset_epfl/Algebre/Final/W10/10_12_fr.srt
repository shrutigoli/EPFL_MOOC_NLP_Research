1
00:00:03,387 --> 00:00:09,989
On arrive à la fin de notre développement
de la théorie pour pouvoir démontrer

2
00:00:09,989 --> 00:00:14,647
cette décomposition d'une matrice 
quelconque en une matrice

3
00:00:14,647 --> 00:00:18,048
qui est un produit de trois matrices : 
une matrice orthogonale,

4
00:00:18,048 --> 00:00:25,861
une matrice presque diagonale
et puis une matrice orthogonale,

5
00:00:25,861 --> 00:00:29,839
donc je répère l'ordre :inversible, presque diagonale, inversible.

6
00:00:29,839 --> 00:00:33,467
Donc voilà le théorème de décomposition
en valeurs singulières.

7
00:00:33,467 --> 00:00:37,898
Donc je me donne une matrice
<i>m x n</i> de rang <i>r</i>.

8
00:00:37,898 --> 00:00:44,507
Alors il existe une matrice <i>Σ</i> telle que:
<i>Σ</i> est de la forme [voir écran],

9
00:00:44,507 --> 00:00:49,428
où <i>D</i> est une matrice diagonale 
et à part ça, on a des valeurs zéro.

10
00:00:49,428 --> 00:00:53,809
<i>D</i> est en fait la matrice diagonale :
<i>σ<sub>1</sub>,..., σ<sub>r</sub></i>,

11
00:00:53,809 --> 00:00:57,629
où ce sont les <i>r</i> valeurs singulières
non nulles de la matrice <i>A</i>.

12
00:00:57,629 --> 00:01:04,212
Et puis il existe une matrice <i>U</i> de taille <i>m x m</i>
et une matrice <i>V</i> de taille <i>n x n</i>,

13
00:01:04,212 --> 00:01:08,877
orthogonales telles que <i>A</i> est le produit de
<i>UΣV</i>.

14
00:01:08,877 --> 00:01:13,957
Donc ça, c'est la décomposition en
valeurs singulières. En anglais,

15
00:01:13,957 --> 00:01:18,451
"singular value decomposition". Donc c'est 
presque le mieux qu'on puisse espérer.

16
00:01:18,451 --> 00:01:21,938
<i>A</i> n'est même pas forcément une 
matrice carrée et même si elle est carrée,

17
00:01:21,938 --> 00:01:25,491
on sait qu'on ne peut pas forcément 
la diagonaliser mais on peut toujours

18
00:01:25,491 --> 00:01:28,879
faire cette décomposition-là.
C'est ça qui à beaucoup d'applications.

19
00:01:28,879 --> 00:01:33,202
Maintenant, j'aimerais faire la preuve 
de ce théorème, et je commence ici.

20
00:01:33,202 --> 00:01:45,913
Donc soit <i>φ</i>, l'application de <i>R<sup>n</sup></i> dans <i>R<sup>m</sup></i>,
l'application linéaire dont la matrice

21
00:01:45,913 --> 00:01:53,531
est la matrice <i>A</i>, c'est-à-dire telle que la matrice de <i>φ</i>
par rapport aux bases canoniques <i>C<sub>1</sub></i> et <i>C<sub>2</sub></i>,

22
00:01:53,531 --> 00:02:08,233
est égal à la matrice <i>A</i> où <i>C<sub>1</sub></i> et <i>C<sub>2</sub></i> sont les
bases canoniques de <i>R<sup>n</sup></i> et <i>R<sup>m</sup></i> respectivement.

23
00:02:08,233 --> 00:02:12,931
Alors par le théorème de l'existence des bases compatibles,

24
00:02:12,931 --> 00:02:19,281
je sais qu'il existe une base orthonormée

25
00:02:25,731 --> 00:02:38,278
<i>B<sub>1</sub> = (v1,...,v<sub>n</sub>)</i> de <i>R<sup>n</sup></i>
telle que <i>(φ(v<sub>1</sub>), ..., φ(v<sub>r</sub>)</i>,

26
00:02:38,451 --> 00:02:43,118
soit une base orthogonale de l'image de <i>φ</i>.

27
00:02:43,289 --> 00:02:48,424
C'est ce que dit le théorème de 
l'existence des bases compatibles.

28
00:02:48,621 --> 00:02:51,354
Maintenant je reprends ça dans la prochaine slide.

29
00:02:51,588 --> 00:02:55,206
Ça, c'est une base orthogonale, 
ce n'est pas une base orthonormée.

30
00:02:55,364 --> 00:03:02,616
Donc je vais faire ça. On normalise cette base.

31
00:03:02,806 --> 00:03:13,384
Donc posons <i>u<sub>i</sub> = 1/σ<sub>i</i> φ(v<sub>i</sub>)</i>,
où <i>σ<sub>i</sub></i> est en fait la norme de <i>φ(v<sub>i</sub>)</i>.

32
00:03:13,583 --> 00:03:17,623
On a déjà utilisé ça plusieurs fois.
C'est un vecteur de norme un.

33
00:03:20,996 --> 00:03:32,596
Donc maintenant <i>(u<sub>1</sub>, ..., u<sub>r</sub>)</i> est 
une base orthonormée de l'image.

34
00:03:32,776 --> 00:03:37,772
Ensuite, je vais étendre ça à  une base orthonormée de <i>R<sup>m</sup></i>.

35
00:03:37,953 --> 00:03:50,741
On complète cette base pour former 
une base orthonormée de <i>R<sup>m</sup></i>.

36
00:03:51,023 --> 00:04:03,038
J'appelle ça <i>B<sub>2</sub> = (u<sub>1</sub>, ..., u<sub>r</sub>, u<sub>r+1</sub>,..., u<sub>m</sub>)</i>.

37
00:04:03,218 --> 00:04:08,660
Maintenant, on a la base <i>B<sub>1</sub></i>,
une base orthonormée de <i>R<sup>n</sup></i>.

38
00:04:08,818 --> 00:04:13,940
On a <i>(u<sub>1</sub>,..., u<sub>r</sub>)</i>,
une base orthonormée de l'image

39
00:04:14,110 --> 00:04:17,445
et <i>(u<sub>1</sub>,...,u<sub>m</sub>)</i>,
une base orthonormée de <i>R<sup>m</sup></i>.

40
00:04:17,657 --> 00:04:24,864
Comme j'ai cette égalité-là, 
j'ai <i>φ(v<sub>i</sub>) = σ<sub>i</sub>u<sub>i</sub></i>.

41
00:04:25,046 --> 00:04:30,007
Et ça, c'est pour tout <i>i</i> plus petit ou égal à <i>r</i>.

42
00:04:30,195 --> 00:04:36,915
Et les <i>φ(v<sub>j</sub> = 0</i> pour tous les <i>j</i> plus grands ou égaux à <i>r+1</i>,

43
00:04:37,083 --> 00:04:39,918
parce qu'ils correspondaientt à la valeur singulière <i>0</i>.

44
00:04:40,094 --> 00:04:45,801
Donc maintenant, si j'écris <i>φ</i>
par rapport à ces deux bases-là, <i>B<sub>1</sub></i> et <i>B<sub>2</sub></i>,

45
00:04:46,028 --> 00:04:51,841
ça a une très jolie forme,
donc j'aurais <i>σ<sub>1</sub></i> parce que

46
00:04:52,037 --> 00:04:56,035
le premier vecteur est envoyé à <i>σ<sub>1</sub></i>
fois le premier vecteur à droite, donc zéro.

47
00:04:56,035 --> 00:05:00,824
Ensuite le deuxième vecteur est envoyé
à <i>σ<sub>2</sub></i> fois le deuxième vecteur,

48
00:05:01,011 --> 00:05:06,430
donc une colonne comme ça
et ainsi de suite jusqu'à <i>σ<sub>r</sub></i>,

49
00:05:06,610 --> 00:05:12,357
toujours le long de la diagonale
et après le reste de la matrice est 0.

50
00:05:12,533 --> 00:05:16,723
Voilà, c'est une matrice qui a justement
ici, dans ce coin-là,

51
00:05:16,885 --> 00:05:20,512
une matrice diagonale avec des valeurs 
singulières le long de la diagonale.

52
00:05:20,695 --> 00:05:27,347
La matrice <i>A</i> originale était la matrice 
de <i>φ</i> par rapport aux bases canoniques.

53
00:05:27,553 --> 00:05:33,453
Pour faire le lien entre cette matrice-là
et celle-là, je dois juste faire

54
00:05:33,644 --> 00:05:39,520
des changements de base. Donc on a que <i>A</i>, qui est cette matrice,

55
00:05:39,714 --> 00:05:45,783
est égale à : Ici, je mets au milieu
la matrice <i>φ</i> par rapport aux bases <i>B<sub>1</sub></i> et <i>B<sub>2</sub></i>

56
00:05:45,783 --> 00:05:50,543
Comme ici, je veux commencer avec 
quelque chose qui prend la base <i>C<sub>1</sub></i>,

57
00:05:50,778 --> 00:05:56,711
je prends la base <i>C<sub>1</sub></i> écrite en termes de la base 
de <i>B<sub>1</sub></i>, ensuite cette application

58
00:05:56,935 --> 00:06:01,611
me redonne un vecteur en termes de <i>B<sub>2</sub></i>, 
donc je prends la base <i>B<sub>2</sub></i> et

59
00:06:01,837 --> 00:06:09,708
et je l'exprime en termes de <i>C<sub>2</sub></i>. 
Maintenant posons <i>U</i> égal à la matrice

60
00:06:09,708 --> 00:06:16,749
ici à gauche et <i>V</i> égal à la matrice ici. 
Ces deux matrices sont

61
00:06:16,916 --> 00:06:20,219
des matrices orthogonales parce que 
ce sont des matrices de passage

62
00:06:20,381 --> 00:06:28,291
entre des bases orthonormées. 
Je répète : <i>U</i> et <i>V</i> sont orthogonales car

63
00:06:28,418 --> 00:06:34,866
leurs colonnes forment des bases orthonormées.

64
00:06:35,130 --> 00:06:42,951
Ici, c'était dans <i>R<sup>m</sup></i> et ici dans <i>R<sup>n</sup></i>, 
respectivement.

65
00:06:44,679 --> 00:06:58,386
Et posons, <i>Σ</i>, la matrice dont la diagonale est <i>σ<sub>1</sub>,σ<sub>2</sub>, ..., σ<sub>r</sub></i>,

66
00:06:58,572 --> 00:07:03,602
et puis on a que notre matrice <i>A</i>
est égale à <i>UΣV</i>.

67
00:07:03,602 --> 00:07:07,041
Voilà la décomposition de 
cette matrice en un produit de matrices

68
00:07:07,041 --> 00:07:10,041
orthogonale, donc inversible,

69
00:07:10,041 --> 00:07:14,904
une matrice presque diagonale
et orthogonale donc inversible.

70
00:07:15,160 --> 00:07:20,787
C'est la preuve de cette décomposition.
Maintenant dans le dernier paragraphe,

71
00:07:20,975 --> 00:07:23,612
nous allons appliquer ça à un exemple.
