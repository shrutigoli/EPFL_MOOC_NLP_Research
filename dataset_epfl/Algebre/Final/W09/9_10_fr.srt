1
00:00:04,267 --> 00:00:08,657
Ici, nous continuons avec nos applications
du procédé de Gram-Schmidt.

2
00:00:10,464 --> 00:00:15,319
En fait, on va définir ce qui s'appelle
la meilleure approximation quadratique,

3
00:00:15,319 --> 00:00:21,644
et puis après, je l'utiliserai dans
les deux prochains paragraphes du cours,

4
00:00:21,644 --> 00:00:23,514
mais d'abord, je dois le définir.

5
00:00:23,514 --> 00:00:28,259
Et puis, en fait, on utilise
la projection orthogonale

6
00:00:28,259 --> 00:00:30,944
sur un sous-espace,
et puis on montre

7
00:00:30,944 --> 00:00:35,006
que c'est la meilleure approximation
d'un vecteur quelconque

8
00:00:35,006 --> 00:00:37,119
par un vecteur qui appartient
à ce sous-espace,

9
00:00:37,119 --> 00:00:38,973
et après on fera un exemple.

10
00:00:38,973 --> 00:00:42,574
Donc, d'abord, je me donne un <i>R</i>-espace
vectoriel de dimension finie,

11
00:00:42,574 --> 00:00:45,105
muni d'un produit scalaire, avec <i>V</i> de dimension finie,

12
00:00:45,105 --> 00:00:47,764
parce que j'aimerais utiliser
la projection orthogonale.

13
00:00:47,764 --> 00:00:51,513
Et puis je me donne
un sous-espace vectoriel de <i>V</i>.

14
00:00:51,513 --> 00:00:56,762
L'énoncé est le suivant : (après, je vais le commenter)

15
00:00:56,762 --> 00:01:01,357
c'est que je prends un vecteur dans <i>V</i>,
et je fais la distance,

16
00:01:01,357 --> 00:01:06,960
donc la norme de la différence entre <i>x</i> et sa projection dans <i>W</i>.

17
00:01:06,974 --> 00:01:11,234
Donc ça c'est la distance 
entre <i>x</i> et cette projection

18
00:01:11,234 --> 00:01:15,134
et puis en fait, ce qu'on va montrer,
c'est que cette distance-là

19
00:01:15,134 --> 00:01:19,361
est plus petite ou égale
à la distance entre <i>x</i>

20
00:01:19,361 --> 00:01:21,413
et n'importe quel vecteur dans <i>W</i>.

21
00:01:21,413 --> 00:01:23,979
Donc ça c'est le minimum
qu'on peut trouver

22
00:01:23,979 --> 00:01:27,014
pour la distance entre <i>x</i>
et un vecteur qui appartient à <i>W</i>.

23
00:01:27,014 --> 00:01:30,546
Donc ça, c'est ce que j'aimerais commenter
avant la preuve ;

24
00:01:30,546 --> 00:01:32,350
-- donc, remarque --

25
00:01:33,925 --> 00:01:38,211
donc, cette proposition dit
que parmi tous les vecteurs de <i>W</i>,

26
00:01:42,515 --> 00:01:49,243
la projection orthogonale sur <i>W</i> de <i>x</i>

27
00:01:49,243 --> 00:01:54,503
est, disons, la plus proche de <i>x</i>.

28
00:01:55,146 --> 00:01:58,667
Donc je répète ce que j'ai dit avant
-- je vais l'écrire --

29
00:01:58,667 --> 00:02:04,262
<i>x</i> moins cette projection-là est égal à la distance

30
00:02:05,552 --> 00:02:08,847
entre <i>x</i> et cette projection

31
00:02:09,369 --> 00:02:14,769
et <i>||x - y||</i> est égale à la distance entre <i>x</i> et <i>y</i>,

32
00:02:15,073 --> 00:02:19,179
et si <i>y</i>, c'est n'importe quel vecteur
dans <i>W</i>, donc ce qu'on va montrer,

33
00:02:19,179 --> 00:02:22,321
c'est que ce truc-là minimise
cette distance.

34
00:02:22,992 --> 00:02:32,514
Et pour cette raison -- définition --
on dit que la projection orthogonale

35
00:02:32,804 --> 00:02:39,901
de <i>x</i> sur <i>W</i> est la meilleure approximation
quadratique de <i>x</i> par un vecteur dans <i>W</i>.

38
00:02:47,009 --> 00:02:54,070
On dit aussi que c'est la meilleure approximation

39
00:02:57,722 --> 00:02:59,769
au sens des moindres carrés.

40
00:03:04,420 --> 00:03:05,486
Et puis,

41
00:03:07,466 --> 00:03:12,086
et ça c'est la raison 
pour laquelle on dit ça,

42
00:03:12,086 --> 00:03:18,223
c'est parce que si on fait <i>║x - y║<sup>2</sup></i>

43
00:03:18,223 --> 00:03:23,756
j'obtiens la somme 
des <i>x<sub>i</sub> - y<sub>i</i>)<sup>2</sup></i>,

44
00:03:23,937 --> 00:03:28,219
donc c'est une expression quadratique
dans les coordonnées <i>x<sub>i</sub>-y<sub>i</sub></i>,

45
00:03:28,360 --> 00:03:30,655
ou bien c'est une somme de carrés.

46
00:03:31,365 --> 00:03:32,397
Et puis

47
00:03:33,157 --> 00:03:35,537
-- bon, ça c'est dans le cas 
où on est dans <i>R<sup>n</sup></i> --

48
00:03:38,547 --> 00:03:41,886
évidemment, on peut avoir
différents produits scalaires,

49
00:03:41,886 --> 00:03:44,920
mais ça c'est avec le produit
scalaire usuel de <i>R<sup>n</sup></i>,

50
00:03:44,920 --> 00:03:47,742
ça donnerait une expression comme ça,

51
00:03:47,742 --> 00:03:50,114
comme c'est une expression quadratique
dans <i>x<sub>i</sub></i> et <i>y<sub>i</sub></i>,

52
00:03:50,114 --> 00:03:52,601
on est en train de minimiser cette expression.

53
00:03:52,601 --> 00:03:54,102
Ou bien, au sens des moindres carrés,

54
00:03:54,102 --> 00:03:56,763
on est en train de minimiser
cette somme de carrés.

55
00:03:57,405 --> 00:04:03,027
Bon, ce sont juste des remarques
sur l'interprétation

56
00:04:03,027 --> 00:04:04,895
de cette proposition,

57
00:04:04,895 --> 00:04:09,122
et aussi la définition,
une terminologie,

58
00:04:09,122 --> 00:04:11,685
et puis maintenant,
j'aimerais démontrer la proposition.

59
00:04:11,685 --> 00:04:13,717
La preuve ne sera pas difficile.

60
00:04:18,382 --> 00:04:22,883
Alors, je prends un <i>y</i> dans <i>W</i>, quelconque.

61
00:04:25,032 --> 00:04:29,519
Et je prends mon <i>x</i>, 
qui était un vecteur donné,

62
00:04:30,843 --> 00:04:33,500
et puis je considère la différence,

63
00:04:33,500 --> 00:04:34,820
<i>x - y</i>

64
00:04:35,950 --> 00:04:43,514
et puis ceci, je l'écris comme
<i>x</i> moins la projection sur <i>W</i> de <i>x</i>,

65
00:04:43,514 --> 00:04:50,503
plus la projection
sur <i>W</i> de <i>x - y</i>.

66
00:04:51,369 --> 00:04:57,198
Maintenant, ce vecteur-là,
il est dans <i>W</i> orthogonal,

67
00:04:57,198 --> 00:04:58,825
ça, on a déjà vu.

68
00:04:58,825 --> 00:05:02,086
Et puis ce vecteur-là,
bon, ça, c'est dans <i>W</i>,

69
00:05:02,086 --> 00:05:04,409
et <i>y</i>, on a choisi dans <i>W</i> aussi,

70
00:05:04,409 --> 00:05:06,218
donc ça c'est dans <i>W</i>.

71
00:05:06,218 --> 00:05:08,238
Donc ça veut dire
que ce vecteur-là est orthogonal

72
00:05:08,238 --> 00:05:09,866
à ce vecteur-là.

73
00:05:09,866 --> 00:05:12,400
Donc je peux utiliser
le théorème de Pythagore.

74
00:05:13,690 --> 00:05:21,342
On a que <i>║x - y║<sup>2</sup></i> est égale à la somme des carrés

75
00:05:21,342 --> 00:05:23,582
de ces normes-là.

76
00:05:25,873 --> 00:05:26,708
Donc je répète :

77
00:05:26,708 --> 00:05:30,038
on peut faire ça
parce que ce vecteur-là est orthogonal

78
00:05:30,038 --> 00:05:31,571
à ce vecteur-là.

79
00:05:31,571 --> 00:05:37,460
Et puis maintenant, ça, 
c'est non négatif ;

80
00:05:38,220 --> 00:05:41,330
ça aussi, parce que
ce sont les carrés des normes,

81
00:05:41,330 --> 00:05:46,725
donc ceci est au moins aussi grand
que le premier terme, ici.

82
00:05:53,590 --> 00:05:57,527
Donc on a que le carré de la norme de <i>x - y</i>,

83
00:05:57,527 --> 00:06:01,431
est plus grand ou égal au carré
de la norme de <i>x - </i>proj<i><sub>W</sub>(x)</i>.

84
00:06:01,431 --> 00:06:04,058
Et puis maintenant,
on prend les racines carrées,

85
00:06:04,058 --> 00:06:07,564
ce qu'on peut faire, parce que
ces deux normes sont positives,

86
00:06:07,564 --> 00:06:09,528
- ça, c'est non négatif -

87
00:06:10,564 --> 00:06:11,988
et cette norme aussi,

88
00:06:15,438 --> 00:06:18,078
et ça c'est ce qui était dit
par la proposition.

89
00:06:18,294 --> 00:06:23,458
Donc la distance
entre <i>x</i> et n'importe quel vecteur dans <i>W</i>,

90
00:06:23,458 --> 00:06:27,302
est au moins aussi grande

91
00:06:27,302 --> 00:06:29,738
que la distance entre <i>x</i> et la projection de <i>x</i> sur <i>W</i>.

92
00:06:29,738 --> 00:06:33,446
Donc celui-là,
il est le plus près possible de <i>x</i>.

93
00:06:35,042 --> 00:06:37,061
Ça, c'est la fin de la preuve.

94
00:06:37,061 --> 00:06:39,738
Et maintenant, dans la prochaine vidéo,
je vais chercher

95
00:06:39,738 --> 00:06:43,790
une meilleure approximation
quadratique de certains vecteurs.
