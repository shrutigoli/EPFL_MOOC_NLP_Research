Now, the question is how do we get from absorption, that is, we are measuring a number of photons arriving at a detector--
<i>that</i> we can measure-- we can measure a number of photons that arrive in the tissues-- so, we can measure what goes in and what comes out.
But how do we construct an image based on that?
And this is what we are going to discuss now.
So, let's say, we have a tissue, here, with three different layers.
A position <i>y_0</i> of the first layer, and each layer, we'll say, has a thickness of <i>Î” y</i>.
Doesn't matter what the thickness is.
Centimeter, millimeter, micrometers-- doesn't matter-- we'll just say this is a certain thickness, and we have three different tissues, here.
We have at a certain position <i>y</i> an intensity of number of photons, I(y), that impact this tissue layer, here.
And we'll assume that they are the same for the entire thickness-- that there's a certain number of photons that comes in here.
So, we have a certain beam intensity-- it is now the number of photons at a given position, <i>y_0</i>.
And so, we can now calculate what is the intensity at <i>y_0 + Î” y</i>.
And this intensity is, obviously, given by the same equation we have discussed earlier, last week.
The intensity, at this position, here, is given by the intensity of the photons at this position-- that's the incoming photon beam times <i>e</i> to the minus <i>Î¼</i>-- the linear attenuation coefficient, at this position, times <i>Î” y</i>.
Here, we're assuming that across <i>Î” y</i> the linear attenuation coefficient does not change.
That's a fair assumption-- we can always choose <i>Î” y</i> sufficiently small, that this condition is fulfilled.
Now, I'm interested in calculating the intensity at this position, here.
We'll do that-- we'll apply this equation, here, recursively, to arrive at this expression.
This is what we are going to do now.
So, the intensity at <i>y_0 + 2 Î” y</i> is given by the intensity at <i>y_0 + Î” y</i>-- it's the intensity of the photons that arrive at this layer, here, times e to the <i>- Î¼</i> at this position, so, that's <i>y_0 + Î” y</i> times the thickness, <i>Î” y</i>, here.
So, that is just the same thing for this layer.
We have the incoming intensity-- corresponds to this one-- we have the absorption, the reduction, here, corresponds to this one.
Notice here, that we're taking the linear attenuation coefficient of this layer, now, obviously.
So we can now substitute this equation into this equation.
That's what we are doing here.
So, we have done this here-- now we have this expression, here.
And so, we will write here, that the position-- the intensity at this interface here is given by the intensity of the photons at this layer, here, times this expression, here.
So this is just taking these two terms, and they are being summed here, up here.
Now, can you see what kind of expression this leads us to?
Let's say, we will let <i>Î”_y</i> go to zero.
And instead of making <i>y_0 + 2 Î” y</i>, we are going to go for a summation over many <i>Î” y</i>-s.
So what are we getting?
Instead of a summation here, we have a summation over <i>2 Î” y</i>-s.
We can sum from the source to the detector of the linear attenuation coefficient and along <i>y</i>.
I'll put in here variable <i>y'</i>, d <i>y'</i>-- it's minus this-- this is what this sum here is.
So, the intensity-- detected intensity is equal to the impacting intensity, here, times this integral, here, e to the minus this integral, here, that gives us the detected intensity.
Now, let's consider a two-dimensional object.
Obviously, we're not interested in a one-dimensional image.
We're interested in two-dimensional objects.
So, we have the same object, here-- we have <i>y_0</i>.
We'll call this dimension, again, <i>y</i>, and we'll call this dimension, here, <i>x</i>.
So the intensity observed at a certain position x, here, is now given by the intensity impacting-- well, here we've assumed that all the photons have the same intensity-- that they all depend on x-- so, that's a normalization, here.
And then it's e to the minus this integral, again.
So, same integral, but now, we've introduced a variable x, here, to indicate that we also could have a variability along x.
Now, what does this function, here, mean?
So, we will now introduce a mathematical transform-- that's the Radon transform.
And the Radon transform is defined as the Radon transform g(x) of this function <i>Î¼</i>.
This gives you an integral from infinity to minus infinity of <i>Î¼ ( x, y ') d y'</i>, so, along one of those variables.
That is the Radon transform.
Now, unlike the Fourier transform, which has many useful mathematical properties, there are not that many easy mathematical properties for the Radon transform.
But I will make the case here, that the Radon transform-- to know it, and to recognize it in the image generation process is nonetheless useful because we can deduce some consequences from it.
So, what is the Radon transform of a point like homogeneous objects?
So, here's my object.
We'll look at the Radon transform here.
This basically means we're integrating-- we have all the intensity at where the object is-- we're getting this intensity, here.
If we take a rectangular object, then the Radon transform means, simply, we are integrating along this direction here.
So, that's this integral, here.
We're getting more intensity with this thicker and only along <i>x</i> where there is dimension of the object.
So, a Radon transform is, essentially, a projection of the object-- a summed projection of the object onto one of our axis here on the <i>x</i> axis.
Let's look at the Radon transform of a circular object.
Here's a circular object.
The Radon object or transform is here-- this is the integral, as we have seen.
And it's actually a projection of the object onto an axis.
And the question is, if we take a two-dimensional object, does each pixel in that object, does each picture element, each tiny element of the image, have a unique representation as we generate the data set.
And we're going to look here at the detector.
Here is a detector.
Here's our object-- it's got three holes in it.
Here's the detector.
And we're going to move this detector around the object.
And this is what we have seen in the first video of this week's lectures.
We've seen that there's something rotating inside the scanner.
And this is the detector that's being rotated around the subject.
This rotation-- the question now is if we do this rotation, or we record for each angle a different Radon transform where there is a different projection-- are we generating information that allows us to uniquely identify each pixel in the image?
If we can say yes to that question, then we can reconstruct an image.
And so, what we are looking at, here, now, is the angle <i>Î¦</i>, which is the angle of the detector plate, here, with respect to its rotation-- so, we're going to rotate it, that is, we're going to change <i>Î¦</i>.
This is on this axis here.
And we are going to look at our three holes.
Here are, for convenience, 
I have color coded them with different colors.
The small hole is the red one, the medium hole is the blue one, and the big hole is the green one.
And we are going to look what happens as we move the projection around.
We start in this projection, here.
The green and the blue are very close on top of each other.
So, they are, in this projection, they are very close to each other when they are being projected.
Whereas, the red one is fairly to the side.
And so, as I rotate the plate around, this object is stationary.
As we rotate around, and for each angle, we write down the projection-- we see that the position of the holes changes.
So, this is depending on their position.
Here, we obviously have an angle, <i>Î¦</i>, where the green is at the edge.
This would be this angle here.
And the blue is almost on the other side.
How far away they are from the center depends on all about which point we rotate.
And this defines the extent the lateralization of our object.
This object is pretty much in the middle when we have this orientation, so at this point, it should be around here.
So, let's verify that.
As we are at the extreme cases for blue and yellow, red is just in the middle.
So, as we are doing a rotation of zero to 180 degrees, we are seeing that the objects move in a sinusoidal pattern.
And we can actually verify if we take just a pointwise object-- that the trajectory of our point, and here, these three points, we can write in this form-- it's given by a <i>R</i>-- that's the maximum amplitude-- times <i>sin(Î¦ + Î¦ 0)</i>.
<i>Î¦ 0</i> is an offset that's characteristic for each of the points.
Now, you can think about it that each point in my image is represented by a max different R.
If they have the same <i>R</i>, then they will be differentiated by at which angle they have the maximum, that is where sin becomes maximal.
Î¤hat depends on when we are perpendicular to the position of that voxel.
So, this voxel has a maximum if the projection is here.
The red one has a maximum pretty much at this orientation.
So, the conclusion here is that each point in space is uniquely represented by the amplitude and the phase, Î¦ 0, of a sinusoidal trajectory in this plot here-- and this plot is called a sinogram.
So, nomen est omen, it is a sinusoidal function, so this depiction, here, is called a sinogram.
So, a position, a pixel in position <i>x</i> and <i>y</i> can be represented by a unique coordinate in <i>R</i> and <i>Î¦_0</i>.
So, the good news is we have independence of each pixel in the image.
They are uniquely represented.
Another question is: what if we do the simple matrix inversion?
Let's take an object that we have decomposed into a 2 by 2 matrix.
It's not very meaningful practically, but we can assume that we are-- we can do that.
And so we have four linear attenuation coefficients to consider.
We have four intensities, we have measured four projections, to here, to here.
And so, with these four measurements, since we have four linear attenuations to consider, we can calculate the intensity <i>I_1</i>, we can calculate the intensity I_2, I_3, I_4, so, we can do the logarithm of that, and then we obtain-- what do we obtain, here?
We obtain a set of four linear equations, with four unknowns.
If we set <i>Î” y = Î” x</i>, then we have a 2 by 2 inversion problem that links the <i>Î¼_k</i> to <i>I_k</i>, so, we have four unknowns, four equations-- that is something we can even imagine doing with paper and pencil.
So, we get from the intensities-- we can get to the linear attenuation coefficients.
Now, let's say we have a <i>n</i> by <i>n</i> matrix-- so, if we have an <i>n</i> squared matrix, say 128 pixels that we want to have in our image, so, it's 128 by 128 linear attenuation coefficients, and, in principle, such a problem can also be inverted-- such a matrix can be inverted.
The problem is this is very complex.
It is computationally intensive and also, on top of that, the matrix is-- inversion problem is unstable.
On top of this, we have to consider, nowadays, that computed tomography was introduced in 1970.
So, we have to be a bit more simpler in the mathematical tools that are being used.
We need a simple reconstruction algorithm.
