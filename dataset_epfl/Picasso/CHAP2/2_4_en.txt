We've shown that the error between f'(x0) and the forward finite difference formula is of order 1 in h,
This is the theorem that we just shown.
We'll now check numerically this prediction.
Let's choose a function f, for example the sinus function.
Also take x0 = 1 and let's write a program that computes (f(x0-h)-f(x0))/h and calculates the error, that is the difference with f'(x0)
We used that program for to get the error for some values of h.
So for h= 10^(-1) the error is
If I divide h by 10, the error is divided by 10.
If I divide again h by 10, the error is divided by 10 again, and so on until 10^(-7).
With h=10^(-7) the error is 4.3*10^(-8), so it has been divided by 
10 at each step.
But if I take h=10^(-9)
I observe that the error increases, goes from 4.3 to 5.3 times 10^(-8).
And for h=10^(-11) the error increases again.
What we observe here is the effect of the truncation error, the truncation in the Taylor expansion.
And what we observe is the effect of rounding errors.
We'll explain later where those rounding errors come from.
The thing to remember for now is that for h less than or equal to 10^(-7) the rounding error effect appears.
Let's now go back to a finite difference formula but not the forward one, but the backward one.
