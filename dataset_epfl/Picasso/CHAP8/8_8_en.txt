Let me now state theorem 8.4 from the book. this theorem allows to better understand Newton's method.
Let f from R to R be of class C2, twice continuously differentiable. 
Let x bar be a zero of f, x bar such that f(x bar) is equal to 0,
I assume that such a zero exists, and I also assume that f ' (x bar) is different from 0, c'est une quantitÃ© qui intervient au dÃ©nominateur.
The claim is that there exists an epsilon positive, such that for all x_0, the starting point for Newton's method, between x bar minus epsilon and x bar plus epsilon, in other words x_0 is sufficiently close to x bar, well in this case, the sequence defined by x_n+1
equal to x_n minus f (x_n) / f ' (x_n), converges towards x bar; this is in fact a consequence of theorem 8.3, the fixed point theorem.
There is some extra information, furthermore the convergence is quadratic, which means very fast, more precisely, there exists C such that for all n, at step n+1, x bar minus x_n+1 is smaller or equal than C times the error at step n,
(x bar minus x_n) squared. voilÃ  la fin du thÃ©orÃ¨me.
Before doing the proof of the second part of the theorem, we shall discuss about the quadratic convergence.
The theorem says that if x_0 sufficiently close to x bar, donc Ã§a c'est la condition : il existe un <i>Îµ</i> tel que pour tout <i>x0</i> minorÃ© par <i>x</i> barre - <i>Îµ</i> et majorÃ© par <i>x</i> barre + <i>Îµ</i>, then the convergence is fast. 
An example situation, to settle some ideas say that C=1, and x bar minus x_0 the initial error, donc l'erreur, je choisis un <i>x0</i>, the initial error is 0.1.
Now I compute x bar minus x_1, which is smaller than (x bar minus x_0) squared, thus 10^-2, the error at step 2, x bar minus x_2, is smaller than
C times the error at the previous step,
(x bar minus x_1) squared, thus less than 10^-4, the error at the third step, x bar minus x_3, is smaller than 10^-8, therefore in three iterations I have approximated the zero up to 10^-8.
The convergence is therefore very fast.
Now there exists cases where
Newton's method does not converge. 
For example, consider the following case.
I consider the function f given by x^3 minus x minus 1,
a java applet is available, to illustrate the calculations. 
From an initial guess x_0, here, you arrive very rapidly, by taking the tangent, here, you reach x bar very quickly.
On the other hand, from an x_0 here, by applying Newton's method, you take this tangent, x_1 will be here, next x_2 will be here, so you will either oscillate between two values, or even diverge. 
Therfore, we observe that the condition on x_0 being sufficiently close to x bar, qui est ici, this condition cannot be removed.
Now we can prove the result. 
Proof: 
Donc, j'ai tout Ã  l'heure calculÃ©,
I already said that Newton's method was a fixed point method, x_n+1 equals g( x_n ), with g(x) equal to x minus f(x) / f ' (x).
J'ai calculÃ©--
Let's note that is f' (x bar) is different from 0, it remains different from 0 in a neighborhood of x bar.
I already compute the derivative g ' (x) = 1 - ( f ' (x)^2 - f '' (x) ) / ( f ' (x)^2 ) divisÃ© par <i>(f'(x))Â²</i>, and I observed that g ' (x bar) was equal to 0, which is strictly smaller than 1.
Therefore, from theorem 8.3, there exists an epsilon positive such that, if my starting point x_0 is between x bar minus epsilon and x bar plus epsilon, then the sequence given by x_n+1 equal to g(x_n), wheer g(x_n) = x_n - f(x_n) / f ' (x_n), this sequence converges. 
We still need to prove the quadratic convergence, the second part of the result; how can we do?
I compute a Taylor expansion,
I compute f(x bar) equal to f(x_n) plus
(x bar - x_n) f ' (x_n), plus
(x bar - x_n)^2 * f '' (eta) divided by
2 factorial. fois <i>f''</i> en un point intermÃ©diaire <i>Î¾</i>.
Here is x bar the zero of f, here is x_n, here we have the interval x bar minus epsilon to x bar plus epsilon in which I placed the initial starting point x_0, et je sais que l'erreur diminue Ã  chaque itÃ©ration. eta is somewhere between x bar and x_n, but I also know that it is between x bar minus epsilon and x bar plus epsilon.
Now I can calculate x bar minus x_n+1 in absolute value. 
<i>x barre - xn</i>
<i>x barre - xn+1</i> en valeur absolue, pardon.
It is equal to (x bar - x_n)^2 divided by 2,
I have divided this relation, here, by f ' (x_n), and I still have f '' (eta) in absolute value, divided by f ' (x_n) in absolute value. 
Now, 
I must prove that there exists C such that for all n, thus C does not depend on n.
The candidate for C is half f '' (eta) times f ' (x_n), where eta is between x bar and x_n, but this quantity depends on x_n, thus n.
But I can bound this quantity by (x bar - x_n)^2 times 1/2, times the largest value on the interval x bar minus epsilon to x bar plus epsilon, and the denominator by the smallest value on the interval x bar minus epsilon to x bar plus epsilon, thus maximum of f '' (x) in absolute value, over the interval x bar minus epsilon to x bar plus epsilon, divided by the smallest value, hence the min of f ' (x) in absolute value, for x in 
[x bar minus epsilon, x bar plus epsilon], and this the C in the theorem,
C is equal to 1/2 times the maximum of the second derivatives divided by the minimum of the first derivatives on the interval x bar minus epsilon to x bar plus epsilon.
I have proven the theorem. 
