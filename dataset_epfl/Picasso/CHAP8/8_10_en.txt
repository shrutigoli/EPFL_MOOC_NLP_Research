Here is a short summary of chapter 8.
Firstly we considered a zero of a function f, x bar such that f (x bar ) = 0.
We wrote this zero as a fixed point, x bar, still the same x bar, is such that x bar = g(x bar), and we have used the fixed point method x_n+1 = g(x_n).
We have proven that this method converges provided |g'(x bar)|  is smaller than 1, and provided the initial guess x_0 is sufficiently close to x bar. 
We can't get rid of this second condition, it is restrictive since we do not know x bar, we only know that we must start sufficiently close to x bar, which is unknown. 
On the other hand, we can avoid the condition
|g'(x bar)| is smaller than one, using Newton's method: x_n+1 = x_n - f(x_n) / f ' (x_n). 
We have proven that Newton's method converges if the starting point x_0 is sufficiently close to x bar. cette condition reste.
Furthermore, we have proven that this method converges very quickly if the derivative f'(x bar) is different from 0.
We have then extended this method to nonlinear systems of equations.
<i>x barre vecteur</i> tel que
<i>f vecteur de x vecteur = 0 vecteur</i>
Newton's method can be written: the jacobian matrix at x^n, the matrix containing all the derivatives, times the vector x^n minus x^n+1, x^n+1 is unknown, equals f (x^n) which is known as soon as x^n is known. 
At each iteration, a linear system has to be solved, matrix times unknown vector equal a known vector, to obtain x^n+1 from x^n. 
To conclude, in order to solve a nonlinear system of equations, we need to solve many linear systems. 
