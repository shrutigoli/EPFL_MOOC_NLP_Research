Hello and welcome to chapter 4.
Today we'll discuss chapters 
4, 5, and 6 of the book: solving linear systems.
The problem we want to solve is the following:
Given N a positive integer supposed to be large,
N goes from 10 to 10^9, a billion, given a matrix A with N rows and N columns, we'll note the entries by aij, both i and j going from 1 to N,
I assume that this matrix is regular, regular is the numerical analysis term for invertible, that is
A^-1 exists
(we never compute A^-1), or the determinant of A is different from 0 and so on, here are other characterisations of a matrix being invertible, we're also given a vector b with N coefficients its entries are denoted bj j going from 1 to N.
Those are the data of the problem.
And we're looking for x a vector with N entries, denoted xj j going from 1 to N, such that Ax=b.
In the book, chapters 4, 5 and 6 are about this problem.
In this course we'll only present chapters 4 and 5.
Those are direct methods.
The keywords are : Gaussian elimination, it is a method you already used in the linear algebra course, we'll study again this
method and another one which is called: LU decomposition of a matrix A, thus A=LU, and finally the Choleski decomposition, that is  A=LLt with Lt the transpose of L and A is a symmetric positive definite matrix.
Why do we call those methods direct methods?
It's because the solution of Ax=b is obtained after a finite number of operations.
Counting the number of operations
is something important because solving a linear
system is costly, which means it requires a lot of operations, so we have to wait a long
 time to obtain the solution.
So, we must be able to answer the question: how many operations have to be done to obtain the solution of the linear system?
With direct methods x is obtained after a finite number of operations unlike the iterative methods, which is the goal of chapter 6 but we won't see this chapter in this course.
Shortly, what is an iterative method?
We want to solve Ax=b, we take a starting guess, vector x0, then from x0 we compute a first approximation x1 of x and so on. In general given xn we compute x(n+1) which should be a better approximation of x, the solution of Ax=b.
The natural question about iterative methods is:
Does xn when n goes to infinity converge to the solution x of the linear system Ax=b ?
The following example can be for instance considered.
I want to solve Ax=b, knowing xn, I can compute the residual b-A*xn.
If b-A*xn=0 then I found the solution of the linear system otherwise I'll computer x(n+1) by writing x(n+1)=xn+Î±*(b-A*xn), where Î± in â„� is a nonzero parameter.
Then the question is: for which values of Î± does the method converge, which means the limit of xn when n goes to the infinity is x and this for all right hand side b and for all starting point x0.
That is the focus of iterative methods, how many iterations are needed to obtain convergence?
We do not know whether the method will converge or not, therefore important theoretical questions must be answered when considering iterative methods.
In this course we'll focus on direct methods,
Gaussian elimination and LU decomposition.
